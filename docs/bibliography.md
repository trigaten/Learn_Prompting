---
sidebar_position: 1000
---

# ğŸ“š Bibliografie

Tato strÃ¡nka obsahuje uspoÅ™Ã¡danÃ½ seznam vÅ¡ech dokumentÅ¯ pouÅ¾itÃ½ch v tomto kurzu. Dokumenty jsou v angliÄtinÄ› a jsou uspoÅ™Ã¡dÃ¡ny podle tÃ©mat.

**Chcete-li citovat tento kurz, pouÅ¾ijte uvedenou citaci v repo Githubu**.

ğŸ”µ = PÅ™Ã­spÄ›vek pÅ™Ã­mo citovanÃ½ v tomto kurzu. OstatnÃ­ dokumenty pÅ™ispÄ›ly k mÃ©mu pochopenÃ­ tÃ©matu.

PoznÃ¡mka: vzhledem k tomu, Å¾e [ani dokument GPT-3, ani dokument GPT-3 Instruct neodpovÃ­dajÃ­ davinciho modelÅ¯m](https://twitter.com/janleike/status/1584618242756132864), snaÅ¾Ã­m se je jako takovÃ© citovat.

## Prompt engineering strategie

#### MyÅ¡lenkovÃ½ Å™etÄ›zec(@wei2022chain) ğŸ”µ

#### Zero Shot Chain of Thought(@kojima2022large) ğŸ”µ

#### Sebekonzistence(@wang2022selfconsistency) ğŸ”µ

#### Jak vypadajÃ­ dobrÃ©kontextnÃ­ pÅ™Ã­klady pro GPT-3?(@liu2021makes) ğŸ”µ

### Ask-Me-Anything Prompting(@arora2022ama) ğŸ”µ

#### GenerovanÃ© znalosti(@liu2021generated) ğŸ”µ

#### JazykovÃ© modely rozÅ¡Ã­Å™enÃ© o recitaci(@sun2022recitationaugmented) ğŸ”µ

#### PÅ™ehodnocenÃ­ role demonstracÃ­(@min2022rethinking) ğŸ”µ

#### Scratchpady(@nye2021work)

#### Maieutic Prompting(@jung2022maieutic)

#### STaR(@zelikman2022star)

#### Least to Most(@zhou2022leasttomost) ğŸ”µ

#### PÅ™erÃ¡movÃ¡nÃ­ instrukÄnÃ­ch promptÅ¯ do jazyka GPTk(@mishra2022reframing) ğŸ”µ

#### TurkingÅ¯v test: RozumÃ­ jazykovÃ© modely instrukcÃ­m?(@efrat2020turking) ğŸ”µ

## Spolehlivost

#### MathPrompter(@imani2023mathprompter) ğŸ”µ

#### Nespolehlivost vysvÄ›tlenÃ­ v few-shot promptingu pro textovÃ© zdÅ¯vodnÄ›nÃ­(@ye2022unreliability) ğŸ”µ

#### Prompting GPT-3, aby bylo spolehlivÃ©(@si2022prompting)

#### RÅ¯znorodÃ© prompty(@li2022advance) ğŸ”µ

#### Kalibrace pÅ™ed pouÅ¾itÃ­m: ZlepÅ¡enÃ­ few-shot vÃ½konu jazykovÃ½ch modelÅ¯(@zhao2021calibrate) ğŸ”µ

#### ZvÃ½Å¡enÃ¡ sebekonzistence(@mitchell2022enhancing)

#### PÅ™edpojatost a toxicita v Zero-Shot CoT(@shaikh2022second) ğŸ”µ

#### KonstituÄnÃ­ UI: NeÅ¡kodnost ze zpÄ›tnÃ© vazby AI (@bai2022constitutional) ğŸ”µ

#### KompoziÄnÃ­ generalizace - SCAN(@lake2018scan)

## AutomatizovanÃ© prompt inÅ¾enÃ½rstvÃ­

#### AutoPrompt (@shin2020autoprompt) ğŸ”µ

#### AutomatickÃ½ prompt inÅ¾enÃ½r(@zhou2022large)

## Modely

### JazykovÃ© modely

#### GPT-3(@brown2020language) ğŸ”µ

#### GPT-3 Instruct(@ouyang2022training) ğŸ”µ

#### PaLM(@chowdhery2022palm) ğŸ”µ

#### BLOOM(@scao2022bloom) ğŸ”µ

#### BLOOM+1 (vÃ­ce jazykÅ¯/ 0 vylepÅ¡enÃ­ snÃ­mkÅ¯)(@yong2022bloom1)

#### GPT-4 Technical Report(@openai2023gpt4) ğŸ”µ

#### Jurassic 1(@lieberjurassic) ğŸ”µ

#### GPT-J-6B(@wange2021gptj)

#### Roberta(@liu2019roberta)

### ObrÃ¡zkovÃ© Modely

#### Stable Diffusion(@rombach2021highresolution) ğŸ”µ

#### DALLE(@ramesh2022hierarchical) ğŸ”µ

## Soft prompting

#### Soft Prompting(@lester2021power) ğŸ”µ

#### InterpretovatelnÃ½ diskrÃ©tnÃ­ soft prompting(@khashabi2021prompt) ğŸ”µ

## Datasety

#### MultiArith(@roy-roth-2015-solving) ğŸ”µ

#### GSM8K(@cobbe2021training) ğŸ”µ

#### HotPotQA(@yang2018hotpotqa) ğŸ”µ

#### Fever(@thorne2018fever) ğŸ”µ

#### BBQ: RuÄnÄ› sestavenÃ½ benchmark pro zodpovÃ­dÃ¡nÃ­ otÃ¡zek(@parrish2021bbq) ğŸ”µ

## Prompt engineering obrÃ¡zkÅ¯

#### Taxonomie modifikÃ¡torÅ¯ promptu(@oppenlaender2022taxonomy)

#### DiffusionDB(@wang2022diffusiondb)

#### The DALLE 2 Prompt Book(@parsons2022dalleprompt) ğŸ”µ

#### Prompt Engineering pro generativnÃ­ umÄ›nÃ­ zaloÅ¾enÃ© na textu(@oppenlaender2022prompt) ğŸ”µ

#### Se sprÃ¡vnÃ½m promptem umÃ­ Stable Diffusion 2.0 nakreslit ruce (@blake2022with) ğŸ”µ

#### Optimalizace promptu pro text-to-image generovÃ¡nÃ­(@hao2022optimizing)

## VÃ½vojovÃ© prostÅ™edÃ­ pro prompt engineering

#### Prompt IDE(@strobelt2022promptide) ğŸ”µ

#### Prompt Source(@bach2022promptsource) ğŸ”µ

#### PromptChainer(@wu2022promptchainer) ğŸ”µ

#### PromptMaker(@jiang2022promptmaker) ğŸ”µ

## Tooling

#### LangChain(@Chase_LangChain_2022) ğŸ”µ

#### TextBox 2.0: Knihovna pro generovÃ¡nÃ­ textu s pÅ™edem natrÃ©novanÃ½mi jazykovÃ½mi modely(@tang2022textbox) ğŸ”µ

#### OpenPrompt: Open-source Framework pro uÄenÃ­ se promptingu(@ding2021openprompt) ğŸ”µ

#### GPT Index(@Liu_GPT_Index_2022) ğŸ”µ

## AplikovanÃ© prompt inÅ¾enÃ½rstvÃ­

#### KaskÃ¡dy jazykovÃ½ch modelÅ¯(@dohan2022language)

#### MRKL(@karpas2022mrkl) ğŸ”µ

#### ReAct(@yao2022react) ğŸ”µ

#### PAL: Program-aided Language Models(@gao2022pal) ğŸ”µ

## Design uÅ¾ivatelskÃ©ho rozhranÃ­

#### Pokyny pro design pro prompt inÅ¾enÃ½rstvÃ­ Text-to-Image generativnÃ­ch modelÅ¯(@liu2022design)

## Prompt Injekce

#### StrojovÄ› generovanÃ½ text: KomplexnÃ­ pÅ™ehled modelÅ¯ hrozeb a metod detekce(@crothers2022machine) ğŸ”µ

#### HodnocenÃ­ vnÃ­mavosti pÅ™edem vyÅ¡kolenÃ½ch jazykovÃ½ch modelÅ¯ prostÅ™ednictvÃ­m ruÄnÄ› vytvoÅ™enÃ½ch protivnÃ½ch pÅ™Ã­kladÅ¯(@branch2022evaluating) ğŸ”µ

#### VyuÅ¾itÃ­ programovÃ©ho chovÃ¡nÃ­ LLM: DvojÃ­ vyuÅ¾itÃ­ prostÅ™ednictvÃ­m standardnÃ­ch bezpeÄnostnÃ­ch ÃºtokÅ¯(@kang2023exploiting) ğŸ”µ
    
#### VÃ­ce, neÅ¾ jste si Å™ekli: KomplexnÃ­ analÃ½za novÃ½ch hrozeb v podobÄ› injekcÃ­ do aplikacÃ­ integrovanÃ½ch do velkÃ½ch jazykovÃ½ch modelÅ¯(@greshake2023youve) ğŸ”µ

#### Ãštoky prompt injekcÃ­ proti GPT-3(@simon2022inject) ğŸ”µ

#### ZneuÅ¾itÃ­ promptÅ¯ GPT-3 pomocÃ­ Å¡kodlivÃ½ch vstupÅ¯, kterÃ© modelu naÅ™Ã­dÃ­ ignorovat jeho pÅ™edchozÃ­ pokyny(@goodside2022inject) ğŸ”µ

#### KontradiktornÃ­ prompty(@chase2021adversarial) ğŸ”µ

#### ChatGPT "DAN" (a dalÅ¡Ã­ "ÃºtÄ›ky z vÄ›zenÃ­")(@kiho2023chatgpt) ğŸ”µ

#### GPT-3 obrana proti prompt injekcÃ­m(@goodside2021gpt) ğŸ”µ

#### MluvenÃ­ se stroji: prompt inÅ¾enÃ½rstvÃ­ a injekce(@christoph2022talking)

#### ProzkoumÃ¡nÃ­ ÃºtokÅ¯ prompt injekce(@selvi2022exploring) ğŸ”µ

#### PouÅ¾itÃ­ GPT-Eliezer proti ChatGPT jailbreaking(@armstrong2022using) ğŸ”µ

#### Microsoft Bing Chat Prompt(@kevinbing)

## Jailbreaking

#### Ignorovat pÅ™edchozÃ­ vÃ½zvu: ÃštoÄnÃ© techniky pro jazykovÃ© modely(@perez2022jailbreak)

#### PouÄenÃ­ o bezpeÄnosti a zneuÅ¾itÃ­ jazykovÃ½ch modelÅ¯(@brundage_2022)

#### Detekce toxicity pomocÃ­ generativnÃ­ho odvozovÃ¡nÃ­ na zÃ¡kladÄ› propozic(@wang2022jailbreak)

#### NovÃ© a vylepÅ¡enÃ© nÃ¡stroje pro moderovÃ¡nÃ­ obsahu(@markov_2022)

#### OpenAI API(@openai_api) ğŸ”µ

#### OpenAI ChatGPT(@openai_chatgpt) ğŸ”µ

#### ChatGPT 4 Tweet(@alice2022jailbreak) ğŸ”µ

#### HranÃ­ Tweet(@miguel2022jailbreak) ğŸ”µ

#### VÃ½zkum Tweet(@derek2022jailbreak) ğŸ”µ

#### PÅ™edstÃ­rÃ¡nÃ­ schopnostÃ­ Tweet(@nero2022jailbreak) ğŸ”µ

#### ZodpovÄ›dnost Tweet(@nick2022jailbreak) ğŸ”µ

#### Lynx Mode Tweet(@jonas2022jailbreak) ğŸ”µ

#### Sudo Mode Tweet(@sudo2022jailbreak) ğŸ”µ

#### Ignorovat pÅ™edchozÃ­ prompt(@ignore_previous_prompt) ğŸ”µ

#### AktualizovanÃ© prompty pro jailbreaking (@AI_jailbreak) ğŸ”µ

## PrÅ¯zkumy

#### Pre-train, prompt a pÅ™edvÃ­dÃ¡nÃ­: SystematickÃ½ pÅ™ehled metod promptingu pÅ™i zpracovÃ¡nÃ­ pÅ™irozenÃ©ho jazyka(@liu2021pretrain)

#### PromptPapers(@ning2022papers)

## GenerovÃ¡nÃ­ datovÃ½ch sad

#### ZjiÅ¡Å¥ovÃ¡nÃ­ chovÃ¡nÃ­ jazykovÃ½ch modelÅ¯ pomocÃ­ evaluacÃ­ napsanÃ½ch modelem(@perez2022discovering)

#### SelektivnÃ­ anotace dÄ›lÃ¡ z jazykovÃ½ch modelÅ¯ lepÅ¡Ã­ uÄitele s few-shots(@su2022selective)

## Aplikace

#### Atlas: Few-shot uÄenÃ­ pomocÃ­ rozÅ¡Ã­Å™enÃ½ch jazykovÃ½ch modelÅ¯ pro vyhledÃ¡vÃ¡nÃ­(@izacard2022atlas)

#### STRUDEL: StrukturovanÃ¡ sumarizace dialogÅ¯ pro porozumÄ›nÃ­ dialogÅ¯m(@wang2022strudel)

## HorkÃ¡ tÃ©mata

#### Auto-GPT(@richards2023)

#### Baby AGI(@nakajima2023)

#### AgentGPT(@reworkd2023)

## OstatnÃ­

#### Prompting je programovÃ¡nÃ­: Jazyk query pro velkÃ© jazykovÃ© modely(@beurerkellner2022prompting)

#### ParalelnÃ­ kontextovÃ¡ okna zlepÅ¡ujÃ­ uÄenÃ­ velkÃ½ch jazykovÃ½ch modelÅ¯ v kontextu(@ratner2022parallel)

#### Katalog vzorÅ¯ promptÅ¯ pro vylepÅ¡enÃ­ prompt engineeringu pomocÃ­ ChatGPT(@white2023prompt) ğŸ”µ

#### UÄenÃ­ sloÅ¾itÃ½ch Ãºloh pomocÃ­ kompoziÄnÃ­ho fine-tuningu jazykovÃ½ch modelÅ¯(@bursztyn2022learning)

#### NadpÅ™irozenÃ© instrukce: Generalizace prostÅ™ednictvÃ­m deklarativnÃ­ch instrukcÃ­ na vÃ­ce neÅ¾ 1600 NLP ÃºlohÃ¡ch(@wang2022supernaturalinstructions)

#### ZlepÅ¡enÃ­ schopnostÃ­ uÄenÃ­ na few-shotech pÅ™edem natrÃ©novanÃ½ch (pre-trained) jazykovÃ½ch modelÅ¯(@gao2021making)

#### Grounding with search results(@livin2022large)

#### Jak na prompt? PÅ™Ã­leÅ¾itosti a vÃ½zvy zero-shop a few-shot uÄenÃ­ pro interakci mezi ÄlovÄ›kem a umÄ›lou inteligencÃ­ v kreativnÃ­ch aplikacÃ­ch generativnÃ­ch modelÅ¯(@dang2022prompt)

#### O mÄ›Å™enÃ­ sociÃ¡lnÃ­ch zkreslenÃ­ch pÅ™i multi-task uÄenÃ­ na zÃ¡kladÄ› promptÅ¯(@akyrek2022measuring)

#### PsanÃ­ zÃ¡pletek z pre-trained (pÅ™edtrÃ©novanÃ½ch) jazykovÃ½ch modelÅ¯(@jin2022plot) ğŸ”µ

#### StereoSet: MÄ›Å™enÃ­ stereotypnÃ­ho zkreslenÃ­ v pÅ™edtrÃ©novanÃ½ch jazykovÃ½ch modelech(@nadeem-etal-2021-stereoset)

#### PÅ™ehled halucinacÃ­ pÅ™i generovÃ¡nÃ­ pÅ™irozenÃ©ho jazyka(@Ji_2022)

#### PÅ™Ã­klady(@2022examples)

#### Wordcraft(@yuan2022wordcraft)

#### PainPoints(@fadnavis2022pain)

#### SebeinstruktÃ¡Å¾: SladÄ›nÃ­ jazykovÃ©ho modelu s instrukcemi generovanÃ½mi modely(@wang2022selfinstruct)

#### Od obrÃ¡zkÅ¯ k textovÃ½m promptÅ¯m: Zero-shot VQA s Frozen LLM(@guo2022images)

#### Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference(@schick2020exploiting)

### Zeptejte se mÄ› na cokoli prompting(@arora2022ama)

### Vodoznak pro velkÃ© jazykovÃ© modely(@kirchenbauer2023watermarking)
