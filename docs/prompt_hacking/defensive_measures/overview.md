---
sidebar_position: 0
---

# ğŸŸ¢ Ãšvod

ZabrÃ¡nit prompt injekci mÅ¯Å¾e bÃ½t velmi obtÃ­Å¾nÃ© a existuje proti nÄ›mu jen mÃ¡lo spolehlivÃ½ch obrannÃ½ch(@crothers2022machine)(@goodside2021gpt) prostÅ™edkÅ¯. Existuje vÅ¡ak nÄ›kolik rozumnÃ½ch Å™eÅ¡enÃ­. Pokud napÅ™Ã­klad vaÅ¡e aplikace nepotÅ™ebuje vypisovat volnÃ½ text, nepovolujte takovÃ© vÃ½stupy. Existuje mnoho rÅ¯znÃ½ch zpÅ¯sobÅ¯, jak prompt ochrÃ¡nit. NÄ›kterÃ© z tÄ›ch nejÄastÄ›jÅ¡Ã­ch zde probereme.

Tato kapitola se zabÃ½vÃ¡ dalÅ¡Ã­mi strategiemi zdravÃ©ho rozumu, jako je filtrovÃ¡nÃ­ slov. ZabÃ½vÃ¡ se takÃ© strategiemi vylepÅ¡ovÃ¡nÃ­ promptÅ¯ (obrana instrukcÃ­, postprompting, rÅ¯znÃ© zpÅ¯soby zapouzdÅ™enÃ­ uÅ¾ivatelskÃ©ho vstupu a znaÄenÃ­ XML). Nakonec se zabÃ½vÃ¡me pouÅ¾itÃ­m LLM k vyhodnocenÃ­ vÃ½stupu a nÄ›kterÃ½mi specifiÄtÄ›jÅ¡Ã­mi pÅ™Ã­stupy k modelÅ¯m. 
