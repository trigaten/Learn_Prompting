---
sidebar_position: 2000
---

# ğŸŸ¢ DalÅ¡Ã­ pÅ™Ã­stupy 

PÅ™estoÅ¾e pÅ™edchozÃ­ pÅ™Ã­stupy mohou bÃ½t velmi robustnÃ­, nÄ›kolik dalÅ¡Ã­ch pÅ™Ã­stupÅ¯, jako je pouÅ¾itÃ­ jinÃ©ho modelu, vÄetnÄ› fine tuning, soft prompting a omezenÃ­ dÃ©lky, mohou bÃ½t takÃ© ÃºÄinnÃ©.

## PouÅ¾itÃ­ jinÃ©ho modelu

ModernÄ›jÅ¡Ã­ modely, jako je GPT-4, jsou odolnÄ›jÅ¡Ã­ vÅ¯Äi prompt injectingu. KromÄ› toho mÅ¯Å¾e bÃ½t obtÃ­Å¾nÃ© prompt injektovat modely, kterÃ© nejsou vyladÄ›nÃ© na instrukce. 

## Fine Tuning

JemnÃ© ladÄ›nÃ­ (fine tuning) modelu je velmi ÃºÄinnou obranou(@goodside2021gpt), protoÅ¾e v dobÄ› inference se kromÄ› uÅ¾ivatelskÃ©ho vstupu nejednÃ¡ o Å¾Ã¡dnÃ½ prompt. Je to pravdÄ›podobnÄ› preferovanÃ¡ obrana v kaÅ¾dÃ© situaci s vysokou hodnotou, protoÅ¾e je tak robustnÃ­. VyÅ¾aduje vÅ¡ak velkÃ© mnoÅ¾stvÃ­ dat a mÅ¯Å¾e bÃ½t nÃ¡kladnÃ¡, proto se tato obrana Äasto neimplementuje.

## Soft Prompting

MÄ›kkÃ½ prompting mÅ¯Å¾e bÃ½t takÃ½ ÃºÄinnÃ½, protoÅ¾e nemÃ¡ jasnÄ› definovanÃ½ diskrÃ©tnÃ­ prompt (jinÃ½ neÅ¾ vstup uÅ¾ivatele). Soft prompting vyÅ¾aduje fine tuning, takÅ¾e mÃ¡ mnoho stejnÃ½ch vÃ½hod, ale bude pravdÄ›podobnÄ› levnÄ›jÅ¡Ã­. MÄ›kkÃ½ prompting vÅ¡ak nenÃ­ tak dobÅ™e prozkoumÃ¡n jako fine tuning, takÅ¾e nenÃ­ jasnÃ©, jak je ÃºÄinnÃ½.

## OmezenÃ­ dÃ©lky

A koneÄnÄ›, zahrnutÃ­ omezenÃ­ dÃ©lky uÅ¾ivatelskÃ©ho vstupu(@selvi2022exploring) nebo omezenÃ­ dÃ©lky konverzacÃ­ chatbotÅ¯, jak to dÄ›lÃ¡ Bing, mÅ¯Å¾e zabrÃ¡nit nÄ›kterÃ½m ÃºtokÅ¯m, jako jsou obrovskÃ© vÃ½zvy ve stylu DAN, respektive virtualizaÄnÃ­ Ãºtoky.