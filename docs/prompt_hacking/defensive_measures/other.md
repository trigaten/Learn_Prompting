---
sidebar_position: 2000
---

# ğŸŸ¢ DalÅ¡Ã­ pÅ™Ã­stupy 

PÅ™estoÅ¾e pÅ™edchozÃ­ pÅ™Ã­stupy mohou bÃ½t velmi robustnÃ­, nÄ›kolik dalÅ¡Ã­ch pÅ™Ã­stupÅ¯, jako je pouÅ¾itÃ­ jinÃ©ho modelu, vÄetnÄ› jemnÃ©ho ladÄ›nÃ­, mÄ›kkÃ½ch vÃ½zev a omezenÃ­ dÃ©lky, mÅ¯Å¾e bÃ½t takÃ© ÃºÄinnÃ½ch.

## PouÅ¾itÃ­ jinÃ©ho modelu

ModernÄ›jÅ¡Ã­ modely, jako je GPT-4, jsou odolnÄ›jÅ¡Ã­ vÅ¯Äi promptnÃ­mu vstÅ™ikovÃ¡nÃ­. KromÄ› toho mÅ¯Å¾e bÃ½t obtÃ­Å¾nÃ© promptnÄ› injektovat modely, kterÃ© nejsou vyladÄ›nÃ© na instrukce. 

## JemnÃ© ladÄ›nÃ­

JemnÃ© ladÄ›nÃ­ modelu je velmi ÃºÄinnou obranou(@goodside2021gpt), protoÅ¾e v dobÄ› inference se kromÄ› uÅ¾ivatelskÃ©ho vstupu nejednÃ¡ o Å¾Ã¡dnÃ½ prompt. Je to pravdÄ›podobnÄ› preferovanÃ¡ obrana v kaÅ¾dÃ© situaci s vysokou hodnotou, protoÅ¾e je tak robustnÃ­. VyÅ¾aduje vÅ¡ak velkÃ© mnoÅ¾stvÃ­ dat a mÅ¯Å¾e bÃ½t nÃ¡kladnÃ¡, proto se tato obrana Äasto neimplementuje.


## Soft Prompting

MÄ›kkÃ¡ vÃ½zva mÅ¯Å¾e bÃ½t takÃ© ÃºÄinnÃ¡, protoÅ¾e nemÃ¡ jasnÄ› definovanou diskrÃ©tnÃ­ vÃ½zvu (jinou neÅ¾ vstup uÅ¾ivatele). Soft prompting efektivnÄ› vyÅ¾aduje jemnÃ© doladÄ›nÃ­, takÅ¾e mÃ¡ mnoho stejnÃ½ch vÃ½hod, ale bude pravdÄ›podobnÄ› levnÄ›jÅ¡Ã­. MÄ›kkÃ½ prompting vÅ¡ak nenÃ­ tak dobÅ™e prozkoumÃ¡n jako jemnÃ© ladÄ›nÃ­, takÅ¾e nenÃ­ jasnÃ©, jak je ÃºÄinnÃ½.

## OmezenÃ­ dÃ©lky

A koneÄnÄ›, zahrnutÃ­ omezenÃ­ dÃ©lky uÅ¾ivatelskÃ©ho vstupu(@selvi2022exploring) nebo omezenÃ­ dÃ©lky krytÃ­ chatbotÅ¯, jak to dÄ›lÃ¡ Bing, mÅ¯Å¾e zabrÃ¡nit nÄ›kterÃ½m ÃºtokÅ¯m, jako jsou obrovskÃ© vÃ½zvy ve stylu DAN, respektive virtualizaÄnÃ­ Ãºtoky.