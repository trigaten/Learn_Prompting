---
sidebar_position: 1
---

# ğŸ”´ MÄ›kkÃ© prompty/vÃ½zvy

LadÄ›nÃ­ promptÅ¯(@lester2021power), alternativa k fine tuningu modelu(@khashabi2021prompt), zmrazÃ­ vÃ¡hy modelu a aktualizuje parametry vÃ½zvy. VÃ½slednÃ½ prompt je "mÄ›kkÃ½ prompt".


import Image from '../assets/prompt_tuning.png';

<div style={{textAlign: 'center'}}>
  <img src={Image} style={{width: "500px"}} />
</div>

<div style={{textAlign: 'center'}}>
Model Tuning vs Prompt Tuning (Lester et al.)
</div>

VÃ½Å¡e uvedenÃ½ obrÃ¡zek stavÃ­ do kontrastu modelovÃ© ladÄ›nÃ­ a promptnÃ­ ladÄ›nÃ­. 
PÅ™i ladÄ›nÃ­ modelu dolaÄujete stejnÃ½ model na rÅ¯znÃ½ch ÃºlohÃ¡ch. TÃ­m zÃ­skÃ¡te
nÄ›kolik rÅ¯znÃ½ch modelÅ¯, s nimiÅ¾ nelze nutnÄ› snadno dÃ¡vkovat vstupy.

Naproti tomu promptnÃ­ ladÄ›nÃ­ vÃ¡m umoÅ¾Åˆuje pouÅ¾Ã­t stejnÃ½ model pro vÅ¡echny Ãºlohy. MÅ¯Å¾ete 
staÄÃ­ v dobÄ› inference pÅ™idat sprÃ¡vnÃ© vÃ½zvy, coÅ¾ umoÅ¾Åˆuje dÃ¡vkovÃ¡nÃ­ napÅ™Ã­Ä rÅ¯znÃ½mi
rÅ¯znÃ½ch ÃºlohÃ¡ch jednoduÅ¡Å¡Ã­. To je v podstatÄ› stejnÃ¡ vÃ½hoda, jakou mÃ¡ bÄ›Å¾nÃ© promptovÃ¡nÃ­.
mÃ¡. NavÃ­c mÄ›kkÃ© podnÄ›ty natrÃ©novanÃ© pro jeden model napÅ™Ã­Ä
vÃ­ce Ãºloh budou mÃ­t Äasto stejnou dÃ©lku tokenu.

## Jak to funguje

Abychom pochopili zÃ¡kladnÃ­ logiku soft promptingu, zamysleme se nad tÃ­m, jak funguje **odvozovÃ¡nÃ­ modelu**.
na danÃ©m promptu: `Co je 2+2?`.

1) MÅ¯Å¾e bÃ½t tokenizovÃ¡na jako `Co, 's, 2, +, 2, ?`. 

2) Pak se kaÅ¾dÃ½ token pÅ™evede na vektor hodnot.

3) Tyto vektory hodnot lze povaÅ¾ovat za parametry modelu. Model mÅ¯Å¾e bÃ½t dÃ¡le
trÃ©novat pouze Ãºpravou vah tÄ›chto promÄ›nnÃ½ch.

VÅ¡imnÄ›te si, Å¾e jakmile zaÄneme tyto vÃ¡hy aktualizovat, vektory tokenÅ¯ se jiÅ¾ nebudou mÄ›nit.
jiÅ¾ neodpovÃ­dajÃ­ skuteÄnÃ½m vnoÅ™enÃ­m ze slovnÃ­ku.

# VÃ½sledky 

LadÄ›nÃ­ promptÅ¯ funguje lÃ©pe u vÄ›tÅ¡Ã­ch modelÅ¯. VÄ›tÅ¡Ã­ modely takÃ© vyÅ¾adujÃ­ mÃ©nÄ›
mÄ›kkÃ½ch promptnÃ­ch tokenÅ¯. Bez ohledu na to vÃ­ce neÅ¾ 20 tokenÅ¯ nepÅ™inÃ¡Å¡Ã­ vÃ½raznÃ½ nÃ¡rÅ¯st vÃ½konu.