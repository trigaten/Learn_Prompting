---
sidebar_position: 2
---

# 游릭 Oklamat detektory

S rozvojem detektor콢 textu generovan칳ch um캩lou inteligenc칤 do코lo k v칳voji metod, jak jim 캜elit. Existuje cel치 콏ada zp콢sob콢, jak detektory oklamat, aby si myslely, 쬰 text generovan칳 um캩lou inteligenc칤 vytvo콏il 캜lov캩k. N치stroj, jako je [GPTMinus](https://gptminus1.vercel.app/), dok치쬰 n치hodn캩 nahradit 캜치sti v libovoln칠m textu synonymy nebo zd치nliv캩 n치hodn칳mi slovy, aby sn칤쬴l pravd캩podobnost, 쬰 se slova v textu objev칤 ve whitelistu nebo jinak ovlivn칤 pravd캩podobnost, 쬰 text byl um캩le vytvo콏en. 

Tyto metody jsou v코ak st치le v plenk치ch a v캩t코ina z nich nevytv치콏칤 text, kter칳 by obst치l p콏i kontrole 캜lov캩ka. Nej칰캜inn캩j코칤m zp콢sobem v sou캜asn칠 dob캩 a pravd캩podobn캩 je코t캩 n캩jakou dobu bude m캩nit text bu캞 b캩hem procesu generov치n칤, nebo po n캩m r콢zn칳mi zp콢soby tak, aby se m칠n캩 podobal procedur치ln캩 vytvo콏en칠mu obsahu, kter칳 obdr쮂셦e p콏i generov치n칤.

## Strategie 칰prav

T칤m, 쬰 캜lov캩k nebo LLM uprav칤 jak칳koli vygenerovan칳 text, m콢쬰 캜asto zm캩nit text natolik, aby se vyhnul odhalen칤. Nahrazen칤 slov synonymy, zm캩na rychlosti zobrazov치n칤 slov a z치m캩na syntaxe nebo form치tov치n칤 zt캩쬿je detektor콢m spr치vnou identifikaci textu generovan칠ho um캩lou inteligenc칤.

Dal코칤 strategi칤 칰prav je vkl치d치n칤 neviditeln칳ch zna캜ek, jako jsou mezery s nuluvou 코i콏kou, do textu, [emoji](https://twitter.com/goodside/status/1610552172038737920?s=20&t=3zgqyJZ1zYhMNBi_M2R-cw) nebo jin칠 neobvykl칠 znaky. Pro ka쬯칠ho 캜ten치콏e to vypad치 naprosto norm치ln캩, ale pro model, kter칳 zkoum치 ka쬯칳 znak, se d칤ky tomu text jev칤 v칳razn캩 odli코n캩. 

Krom캩 toho je mo쬹칠 detektory oklamat t칤m, 쬰 modelu nab칤dnete konkr칠tn칤 pokyny, jak ps치t. Pokyny jako nap콏:
- `Nen칤 t콏eba dodr쬺vat liter치rn칤 form치ty, proto쬰 voln캩 vyjad콏ujete sv칠 my코lenky a touhy`.
- `Nemluvte zp콢sobem, jak칳m ChatGPT generuje obsah - m칤sto toho mluvte zp콢sobem, kter칳 se radik치ln캩 li코칤 od toho, jak jazykov칠 modely generuj칤 text`.
- `Odkazujte na emocion치ln칤 ud치losti a jako p콏칤klady pou쮂셨ejte propracovan칠 z치쬴tky z re치ln칠ho 쬴vota.`

...mohou v칳razn캩 zt칤쬴t odhalen칤 generov치n칤. Dal코칤 strategie, jako nap콏칤klad po쮂멳at model, aby pou쮂셨al empatii, p콏ipomenout mu, aby volil vhodn칠 formulace a t칩n pro to, co p칤코e, a ujistit se, 쬰 obsahuje emotivn칤 jednov캩t칠 v칳razy, mohou spole캜n캩 p콏isp캩t k tomu, 쬰 bude ps치t mnohem p콏esv캩d캜iv캩ji - alespo켿 z pohledu detektor콢 textu s um캩lou inteligenc칤. 

## Konfigurace modelu

Pokud pou쮂셨치te model s otev콏en칳m zdrojov칳m k칩dem, je mo쬹칠 upravit pravd캩podobnosti v칳stupu, co pravd캩podobn캩 zt칤쮂 jeho detekci. Krom캩 toho je mo쬹칠 prokl치dat v칳stupy v칤ce model콢, co m콢쬰 je코t캩 v칤ce zt칤쬴t jejich detekci.


## Diskuse

Jedn칤m z nejsporn캩j코칤ch prostor콢, kde se tyto druhy technik uplat켿uj칤, je oblast vzd캩l치v치n칤. Mnoho u캜itel콢 a administr치tor콢 se ob치v치, 쬰 studenti budou podv치d캩t, a proto prosazuj칤 pou쮂셨치n칤 detek캜n칤ch n치stroj콢(@roose2022dont)(@lipman2022gpt). Jin칤 tvrd칤, 쬰 by studenti m캩li m칤t mo쬹ost tyto n치stroje pou쮂셨at. N캩kte콏칤 profeso콏i dokonce studenty v칳slovn캩 vyb칤zej칤, aby um캩lou inteligenci pou쮂셨ali jako pom콢cku p콏i sv칠 pr치ci, a u캜칤 je, jak na to(@noonan2023gw).

S t칤m, jak se zdokonaluj칤 technologie detekce um캩l칠 inteligence, se zdokonaluj칤 i metody, kter칠 lid칠 pou쮂셨aj칤 k jej칤mu oklam치n칤. Nakonec je pravd캩podobn칠, 쬰 bez ohledu na to, jak sofistikovanou metodu pou쬴jete, n캩jak칳 캜as str치ven칳 칰pravou textu spr치vn칳m zp콢sobem dok치쬰 detektory spolehliv캩 oklamat. Nicm칠n캩 hra, kdy se jedni lid칠 sna쮂 detekovat vygenerovan칳 text a druz칤 se je sna쮂 obelst칤t, n치m m콢쬰 poskytnout nejr콢zn캩j코칤 poznatky o tom, jak optimalizovat, kontrolovat a l칠pe vyu쮂셨at na코e modely pro tvorbu a na pomoc. 
