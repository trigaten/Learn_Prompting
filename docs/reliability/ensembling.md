---
sidebar_position: 5
---

# 游리 Prompt Ensembling

Prompt ensembling je koncept pou쬴t칤 v칤ce r콢zn칳ch prompt콢, kter칠 se sna쮂 odpov캩d캩t na stejnou ot치zku. Existuje mnoho r콢zn칳ch p콏칤stup콢.

## DiVeRSe

DiVeRSe(@li2022advance) ("**Di**verse **Ve**rifier on **R**easoning **S**t**e**ps") je metoda, kter치 trojn치sobn캩 zvy코uje spolehlivost odpov캩d칤. Dosahuje toho: 1) pou쮂셨치n칤m v칤ce prompt콢 ke generov치n칤 r콢znorod칳ch dopln캩n칤, 2) pou쮂셨치n칤m ov캩콏ova캜e k rozli코en칤 dobr칳ch odpov캩d칤 od 코patn칳ch a 3) pou쮂셨치n칤m ov캩콏ova캜e ke kontrole spr치vnosti krok콢 uva쬺v치n칤.


import diverse from '@site/docs/assets/diverse.png';

<div style={{textAlign: 'center'}}>
  <img src={diverse} style={{width: "750px"}} />
</div>

<div style={{textAlign: 'center'}}>
DiVeRSe (Li et al.)
</div>


### Rozmanit칠 prompty

DiVeRSe pou쮂셨치 5 r콢zn칳ch prompt콢 na ka쬯칳 vstup. Pro sestaven칤 ka쬯칠ho promptu n치hodn캩 zvol칤 n캩kolik exempl치콏콢 z tr칠novac칤 sady. Zde je p콏칤klad jednoho takov칠ho %%few-shot promptu|few shot standard prompt%% (k=2) s exempl치콏i p콏evzat칳mi z [benchmarku GSM8K](https://raw.githubusercontent.com/openai/grade-school-math/master/grade_school_math/data/train.jsonl)(@cobbe2021training). V praxi DiVeRSe pou쮂셨치 5 exempl치콏콢 v promptech pro tento benchmark.


```
Ot치zka: Nat치lie prodala v dubnu klipy 48 sv칳m p콏치tel콢m a v kv캩tnu pak prodala o polovinu m칠n캩 klip콢. Kolik klip콢 prodala Nat치lie celkem v dubnu a kv캩tnu?
Odpov캩캞: Nat치lie prodala v kv캩tnu 48/2 = 24 klip콢.
Nat치lie prodala v dubnu a kv캩tnu celkem 48+24 = 72 klip콢.
#### 72
Ot치zka: Weng si za hl칤d치n칤 d캩t칤 vyd캩l치 12 dolar콢 na hodinu. V캜era hl칤dala d캩ti pr치v캩 50 minut. Kolik si vyd캩lala?
Odpov캩캞: Weng si vyd캩l치 12/60 = 0,2 dolaru za minutu.
Za 50 minut pr치ce si vyd캩lala 0,2 x 50 = 10 USD.
#### 10
Ot치zka: Betty si 코et콏칤 pen칤ze na novou pen캩쬰nku, kter치 stoj칤 100 dolar콢. Betty m치 pouze polovinu pot콏ebn칳ch pen캩z. Jej칤 rodi캜e se rozhodli, 쬰 j칤 na tento 칰캜el daj칤 15 dolar콢 a prarodi캜e dvakr치t tolik ne rodi캜e. Kolik pen캩z je코t캩 Betty pot콏ebuje, aby si pen캩쬰nku mohla koupit?
Odpov캩캞:
```

Po vygenerov치n칤 5 r콢zn칳ch prompt콢, jako je v칳코e uveden칳, DiVeRSe uk치쬰 20 zp콢sob콢 uva쬺v치n칤 pro ka쬯ou z nich (teplota = 0,5). Zde je n캩kolik p콏칤klad콢 vypln캩n칤 v칳코e uveden칠ho promptu. V코imn캩te si, 쬰 odpov캩di nejsou v쬯y spr치vn칠.


```text
<!-- highlight-start -->
Betty m치 0,5*100 = 50 dolar콢.
Pak dostane je코t캩 15 = 65 dolar콢.
Pak dostane 2*15 = 90 dolar콢.
Pot콏ebuje je코t캩 100-90 = 10 dolar콢.
#### 10
<!-- highlight-end -->
```

```text
<!-- highlight-start -->
A: Betty m치 0,5*100 = 500 dolar콢.
Pak dostane dal코칤ch 15 = 650 dolar콢.
Pak dostane 2*15 = 900 dolar콢.
Pot콏ebuje je코t캩 100-90 = 1000 dolar콢.
#### 1000
<!-- highlight-end -->
```

V tomto okam쬴ku m치 DiVeRSe vygenerov치no 100 r콢zn칳ch dopln캩n칤.

### Ov캩콏ova캜 hlasov치n칤

Nyn칤 bychom mohli prost캩 vz칤t v캩t코inovou odpov캩캞, jako to d캩l치 Self-Consistency(@mitchell2022enhancing).

DiVeRSe v코ak navrhuje mnohem slo쬴t캩j코칤 metodu, kterou naz칳v치 _ov캩콏ova캜 hlasov치n칤_.

V dob캩 testov치n칤 je pou쬴t칤 ov캩콏ovatele hlasov치n칤 dvoustup켿ov칳 proces. Nejprve ov캩콏ova캜 (neuronov치 s칤콘) p콏i콏ad칤 ka쬯칠mu vypln캩n칤 sk칩re 0-1 podle toho, jak pravd캩podobn칠 je, 쬰 je spr치vn칠. Pot칠 "hlasovac칤" komponenta se캜te v코echna sk칩re r콢zn칳ch odpov캩d칤 a z칤sk치 kone캜nou odpov캩캞.

#### P콏칤klad

Zde je mal칳 p콏칤klad. 콎ekn캩me, 쬰 m치me n치sleduj칤c칤 odpov캩di na ot치zku "Co je dv캩 plus dv캩?":

```text
<!-- highlight-start -->
4
<!-- highlight-end -->
```

```text
<!-- highlight-start -->
dva + 2 = 5
<!-- highlight-end -->
```

```text
<!-- highlight-start -->
Mysl칤m, 쬰 2+2 = 6
<!-- highlight-end -->
```

```text
<!-- highlight-start -->
dva plus dva = 4
<!-- highlight-end -->
```

```text
<!-- highlight-start -->
Je to 5
<!-- highlight-end -->
```

Ov캩콏ova캜 p콏e캜te ka쬯칠 dopln캩n칤 a p콏i콏ad칤 mu sk칩re. M콢쬰 nap콏칤klad p콏i콏adit sk칩re: 0,9, 0,1, 0,2, 0,8, 0,3. Pot칠 hlasovac칤 komponenta se캜te sk칩re pro ka쬯칠 z odpov캩d칤.

```
score(4) = 0,9 + 0,8 = 1,7
score(5) = 0,1 + 0,3 = 0,4
score(6) = 0,2
```

Kone캜n치 odpov캩캞 je 4, proto쬰 m치 nejvy코코칤 sk칩re.

**Ale jak je ov캩콏ova캜 vycvi캜en?**

Ov캩콏ova캜 je tr칠nov치n pomoc칤 m칤rn캩 slo쬴t칠 ztr치tov칠 funkce (loss function), kter치  kterou se zde nebudu zab칳vat. Pro v칤ce informac칤 si p콏e캜t캩te 캜치st 3.3 캜l치nku(@li2022advance).

## Ask Me Anything (AMA) Prompting (Ptejte se m캩 na cokoli)

import ama from '@site/docs/assets/AMA_Prompting.jpg';

<div style={{textAlign: 'center'}}>
  <img src={ama} style={{width: "750px"}} />
</div>

Ask Me Anything (AMA) prompting(@arora2022ama) je podobn칳 p콏칤stup jako DiVeRSe. Jeho krok v칤cen치sobn칠ho promptu (multiple prompt) i krok agregace odpov캩d칤 se v코ak v칳razn캩 li코칤. Z치kladn칤 my코lenkou AMA je pou쬴t칤 LLM ke generov치n칤 v칤cen치sobn칳ch prompt콢, m칤sto aby se pou쮂셨aly pouze r콢zn칠 few-shot exempl치콏e.

### V칤cen치sobn칠 prompty

AMA ukazuje, 쬰 m콢쬰te vz칤t ot치zku a p콏eform치tovat ji v칤ce zp콢soby, abyste vytvo콏ili r콢zn칠 prompty. Nap콏칤klad 콏ekn캩me, 쬰 sh치n칤te informace o zv칤콏atech z n캩kolika webov칳ch str치nek a chcete zaznamenat pouze ta, kter치 쬴j칤 v Severn칤 Americe. Sestavme prompt, kter칳 to ur캜칤.

Vzhledem k n치sleduj칤c칤mu 칰ryvku z Wikipedie:

```text
Medv캩d kermodsk칳, n캩kdy naz칳van칳 medv캩d칤 duch (Ursus americanus kermodei), je poddruh americk칠ho medv캩da 캜ern칠ho a 쬴je v oblasti st콏edn칤ho a severn칤ho pob콏e쮂 Britsk칠 Kolumbie v Kanad캩.
```

Tuto 칰lohu m콢쬰te naform치tovat do promptu takto:

```text
Je n치sleduj칤c칤 tvrzen칤 vzhledem ke kontextu pravdiv칠, nebo nepravdiv칠?

Kontext: Medv캩d kermodsk칳, n캩kdy naz칳van칳 medv캩d칤 duch (Ursus americanus kermodei), je poddruh americk칠ho medv캩da 캜ern칠ho a 쬴je v oblasti st콏edn칤ho a severn칤ho pob콏e쮂 Britsk칠 Kolumbie v Kanad캩.
Tvrzen칤: Toto zv칤콏e 쬴je v Severn칤 Americe
Odpov캩캞: Tento druh medv캩da se vyskytuje na 칰zem칤 캛esk칠 republiky:
```

Toto je trochu zvl치코tn칤 formulace. Pro캜 prost캩 nepou쬴jete n치sleduj칤c칤 jednodu코코칤 prompt?

```text
Kontext: Medv캩d kermodsk칳, n캩kdy naz칳van칳 medv캩d칤 duch (Ursus americanus kermodei), je poddruh americk칠ho medv캩da 캜ern칠ho a 쬴je v oblasti st콏edn칤ho a severn칤ho pob콏e쮂 Britsk칠 Kolumbie v Kanad캩.
Ot치zka: 콯ije toto zv칤콏e v Severn칤 Americe?
```

No, formulov치n칤m ot치zky t칤mto zvl치코tn칤m zp콢sobem m콢쬰me generovat r콢zn칠 podn캩ty. Na코칤m prvn칤m krokem zde bude vz칤t tvrzen칤 ``Toto zv칤콏e 쬴je v Severn칤 Americe`` a p콏eform치tovat ho na r콢zn칠 ot치zky, kter칠 se v podstat캩 ptaj칤 na tot칠. Za t칤mto 칰캜elem projdeme tvrzen칤 p콏es prompty, jako jsou ty na n치sleduj칤c칤m obr치zku.

import ama_multi from '@site/docs/assets/AMA_multiprompting.png';

<div style={{textAlign: 'center'}}>
  <img src={ama_multi} style={{width: "800px"}} />
</div>

To m콢쬰 m칤t za n치sledek:
1. 콯ilo zv칤콏e v Severn칤 Americe?
2. 콯ije zv칤콏e v Severn칤 Americe?
3. Kde zv칤콏e 쬴je?

Smyslem tohoto postupu je vytvo콏it r콢zn칠 *pohledy* na danou 칰lohu. Ka쬯칳 z nich pak aplikujeme na dan칳 kontext takto:

```text
Kontext: Medv캩d kermodsk칳, n캩kdy naz칳van칳 medv캩d칤 duch (Ursus americanus kermodei), je poddruh americk칠ho medv캩da 캜ern칠ho a 쬴je v oblasti st콏edn칤ho a severn칤ho pob콏e쮂 Britsk칠 Kolumbie v Kanad캩.
Ot치zka: 콯ilo toto zv칤콏e v Severn칤 Americe?
```

Pot칠 m콢쬰me vygenerovat odpov캩di na ka쬯ou z nich:

1. `Ano, 쬴lo`
2. `Ano, je to tak`
3. `Severn칤 Amerika`

Toto jsou *prost콏edn칤* odpov캩di. Mus칤me je p콏i콏adit k ozna캜en칤 칰lohy (nap콏. Ano nebo Ne).

To m콢쬰me ud캩lat tak, 쬰 mezipodpov캩di p콏ed치me prost콏ednictv칤m n치sleduj칤c칤ho promptu:

```text
Vyberte spr치vnou kategorii.

"Kategorie":
- Ano, Severn칤 Amerika
- Ne, ne Severn칤 Amerika

"Ano, 쬴lo" odpov칤d치 kategorii:
```

Nyn칤 m콢쬰me z칤skat na코e v칳stupn칤 odpov캩di.

1. `Ano, Severn칤 Amerika`
2. `Ano, Severn칤 Amerika`
3. `Ano, Severn칤 Amerika`

Zde se v코echni shoduj칤, tak쬰 m콢쬰me vz칤t jen prvn칤 odpov캩캞. Pokud by se v코ak neshodly, mohli bychom pou쮂셦 krok agregace AMA a z칤skat kone캜nou odpov캩캞.

### Agregace odpov캩d칤

AMA pou쮂셨치 velmi slo쬴tou strategii pro agregaci odpov캩d칤 (v칤ce ne DiVeRSe), m칤sto aby prost캩 vzala v캩t코inovou odpov캩캞. Abychom pochopili, pro캜 m콢쬰 b칳t v캩t코inov치 odpov캩캞 코patnou volbou, vezm캩me si dv캩 z ot치zek, kter칠 jsme vygenerovali d콏칤ve:

1. 콯ilo zv칤콏e v Severn칤 Americe?
2. 콯ije zv칤콏e v Severn칤 Americe?

Jsou si velmi podobn칠, tak쬰 pravd캩podobn캩 vygeneruj칤 stejn칳 v칳sledek. Proto쬰 jsou ot치zky tak podobn칠, budou 칰캜inn캩 zkreslovat kone캜n칳 v칳sledek. Aby se s t칤m AMA vypo콏치dala, spol칠h치 se na slab칳 dohled a slo쬴tou matematiku, aby odhadla z치vislosti mezi r콢zn칳mi podn캩ty, kter칠 vytvo콏칤, a pak je pou쬴je k jejich vhodn칠mu zv치쬰n칤.

Tak쬰 t콏em ot치zk치m, kter칠 jsme vytvo콏ili, m콢쬰 p콏i콏adit v치hy 25 %, 25 % a 50 %, proto쬰 prvn칤 dv캩 jsou si tak podobn칠.

A캜koli je agrega캜n칤 strategie AMA v칳konn치, je natolik slo쬴t치, 쬰 se j칤 zde nebudu zab칳vat. Podrobn캩j코칤 informace najdete v 캜치sti 3.4 캜l치nku(@arora2022ama).

### V칳sledky

- S touto strategi칤 agregace je AMA schopna pou쮂셦 GPT-J-6B(@wange2021gptj) a p콏ekonat tak GPT-3. Na z치klad캩 t칠to strategie agregace je AMA schopna pou쮂셦 GPT-J-6B(@wange2021gptj). 

- AMA je lep코칤 v ot치zk치ch, kde dan칳 kontext obsahuje odpov캩캞.

## Z치v캩ry

Metody skl치d치n칤 (ensembling methods)jsou velmi v칳konn칠. Lze je pou쮂셦 ke zlep코en칤 v칳konu jak칠hokoli modelu a lze je pou쮂셦 ke zlep코en칤 v칳konu modelu na konkr칠tn칤 칰loze.

V praxi by m캩lo b칳t va코칤 strategi칤 v캩t코inov칠 hlasov치n칤.
