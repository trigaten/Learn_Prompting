---
sidebar_position: 10
---

# 游댮 Kalibrace LLM

N캩kter칳m zkreslen칤m, kter치 LLM vykazuj칤, je mo쬹칠 캜elit kalibrac칤 **rozd캩len칤 v칳stupu**(@zhao2021calibrate) ang. output distributions. 

**Co p콏esn캩 znamen치 kalibrace rozd캩len칤 v칳stupu?**

Projd캩me si rychl칳 p콏칤klad: 콎ekn캩me, 쬰 m치me 칰lohu %%anal칳zovat sentiment|sentiment analysis%% se dv캩ma mo쬹칳mi ozna캜en칤mi, `Pozitivn칤` a `Negativn칤`. Uva쬿jme, co se stane, kdy je %%LLM|LLM%% vyzv치n p콏칤kazem `Vstup: 쮂멳n칳 Sentiment: `. Tento vstup neobsahuje 쮂멳n칳 _kontext_, kter칳 by LLM mohl pou쮂셦 k vytvo콏en칤 p콏edpov캩di sentimentu, tak쬰 se naz칳v치 **bezkontextov칳** vstup.

Proto쬰 `쮂멳n칳` nen칤 ani pozitivn칤, ani negativn칤 pojem, o캜ek치vali bychom, 쬰 LLM bude vypisovat pravd캩podobnost p콏ibli쬹캩 0,5 jak pro `pozitivn칤`, tak pro `negativn칤`. 캛asto (a v tomto p콏칤kladu) tomu tak v코ak nebude.
```
p("Pozitivn칤" | "Vstup: 쮂멳n칳 sentiment:") = 0,9

p("Negativn칤" | "Vstup: 쮂멳n칳 sentiment:") = 0,1
```

Vzhledem k t캩mto zna캜k치m pravd캩podobnost칤 pro bezkontextov칳 vstup v칤me, 쬰 **v칳stupn칤 distribuce** LLM je pravd캩podobn캩 zkreslen치 sm캩rem ke zna캜ce `Pozitivn칤`. To m콢쬰 zp콢sobit, 쬰 LLM bude up콏ednost켿ovat `Pozitivn칤` pro v코echny vstupy, i kdy vstup nen칤 ve skute캜nosti pozitivn칤.

Pokud m콢쬰me n캩jak칳m zp콢sobem **kalibrovat** v칳stupn칤 distribuci tak, aby bezkontextov칳m vstup콢m byla p콏i콏azena pravd캩podobnost 0,5 jak pro `Pozitivn칤`, tak pro `Negativn칤`, pak m콢쬰me 캜asto odstranit zkreslen칤 sm캩rem k `Pozitivn칤` a LLM bude spolehliv캩j코칤 jak na bezkontextov칳ch vstupech, tak na vstupech s kontextem.

## Netechnick칠 콏e코en칤

Netechnick칠 콏e코en칤 tohoto probl칠mu spo캜칤v치 v tom, 쬰 jednodu코e uvedeme few shot %%exempl치콏e|exemplars%%, kde
bezkontextov칳m exempl치콏콢m je efektivn캩 p콏i콏azena pravd캩podobnost 0,5 pro oba p콏칤klady `Pozitivn칤` i `Negativn칤`.

Mohli bychom nap콏칤klad poskytnout n치sleduj칤c칤ch n캩kolik p콏칤klad콢, kter칠 ukazuj칤 ka쬯칳 bezkontextov칳 exempl치콏 klasifikov치n jako `pozitivn칤` i `negativn칤`:
```
Vstup: Tento film nen치vid칤m. Sentiment: Negativn칤:
Vstupn칤 칰daje: Tento film miluji. Sentiment: Sentiment: Pozitivn칤:
Vstupn칤 칰daje: Film je velmi zaj칤mav칳: Sentiment: Sentiment: Pozitivn칤
Vstupn칤 칰daje: Sentiment: Pozitivn칤: N/A Sentiment: Negativn칤
Vstup: 쮂멳n칤 Sentiment: Pozitivn칤:
Vstup: 쮂멳n칤 Sentiment: Negativn칤:
Vstupn칤 칰daje: M치m r치d vaj칤캜ka. Sentiment:
```

Pokud je mi zn치mo, toto 콏e코en칤 nebylo v literatu콏e zkoum치no a nejsem si jist칳, jak dob콏e funguje v praxi. Nicm칠n캩 je to jednoduch칠 콏e코en칤, kter칠 ukazuje, 캜eho se kalibrace sna쮂 dos치hnout.

## Technick칠 콏e코en칤

Dal코칤m 콏e코en칤m tohoto probl칠mu je __kontextov치 kalibrace__(@zhao2021calibrate), kde nastav칤me speci치ln칤 kalibra캜n칤 parametry, kter칠 zajist칤, 쬰 bezkontextov칠 vstupy jako nap콏. `Vstup: 쮂멳n칳 Sentiment: ` jsou p콏i콏azeny pravd캩podobnosti p콏ibli쬹캩 0,5 pro ob캩 zna캜ky. V코imn캩te si, 쬰 v praxi tato metoda prov치d칤 kalibraci v칤ce r콢zn칳ch bezkontextov칳ch vstup콢 (nap콏. `Vstup: N/A Sentiment: `, `Vstup: [MASK] Sentiment: `). Zpr콢m캩ruje kalibra캜n칤 parametry, kter칠 nejl칠pe funguj칤 pro ka쬯칳 bezkontextov칳 vstup, aby se na코ly nejlep코칤 kalibra캜n칤 parametry pro LLM.

### P콏칤klad

Projd캩me si p콏칤klad v칳po캜tu kalibra캜n칤ch parametr콢 pro jeden bezkontextov칳 vstup. V코imn캩te si, 쬰 tento p콏칤klad nen칤 reprodukovateln칳 pomoc칤 GPT-3 vzhledem k tomu, 쬰 jej nelze omezit na zna캜ky `Pozitivn칤` a `Negativn칤`.

Uva쬿jme znovu v칳코e uveden칳 p콏칤klad, kde LLM p콏i콏azuje zna캜k치m n치sleduj칤c칤 pravd캩podobnosti pro bezkontextov칳 vstup:

```
p("Pozitivn칤" | "Vstup: 쮂멳n칳 Sentiment:") = 0,9

p("Negativn칤" | "Vstup: 쮂멳n칳 Sentiment:") = 0,1
```

Chceme naj칤t n캩jak칠 rozd캩len칤 pravd캩podobnosti q takov칠, 쬰
```
q("Pozitivn칤" | "Vstup: 쮂멳n칳 Sentiment:") = 0,5

q("Negativn칤" | "Vstup: 쮂멳n칳 Sentiment:") = 0,5
```

Ud캩l치me to tak, 쬰 vytvo콏칤me line치rn칤 transformaci, kter치 uprav칤 (kalibruje) pravd캩podobnosti $p$. 

$\hat q = \text{Softmax}(W\hat p + b)$

Tato rovnice vezme p콢vodn칤 pravd캩podobnosti $\hat p$ a pou쬴je v치hy $W$ a zkreslen칤 $b$. V치hy $W$ a zkreslen칤 $b$ jsou kalibra캜n칤 parametry, kter칠 po aplikaci na pravd캩podoobnost bezkontextn칤ch exempl치콏콢, d치vaj칤 $\hat p$ = [0,5, 0,5].

#### V칳po캜et W a b

Pot콏ebujeme n캩jak vypo캜칤tat v치hy $W$ a zkreslen칤 $b$. Jedn칤m ze zp콢sob콢, jak to ud캩lat, je: 

$W = \text{diag}(\hat p)^{-1}$. 

$b = 0$

Definice $W$ se sice m콢쬰 zd치t na prvn칤 pohled trochu zvl치코tn칤, ale jde jen o to, 쬰 se vezme inverzn칤 hodnota ka쬯칠 hodnoty v $\hat p$, aby se na코la hodnota $W$, kter치 p콏evede p콢vodn칤 pravd캩podobnosti $\hat p$ na kalibrovan칠 pravd캩podobnosti [0,5, 0,5].

Ov캩콏me, 쬰 to funguje pro v칳코e uveden칳 p콏칤klad:

$\hat p = [0.9, 0.1]$

$W = \text{diag}(\hat p)^{-1} = \text{diag}([0.9, 0.1])^{-1} 
= \begin{bmatrix}
   0.9 & 0 \\
   0 & 0.1
\end{bmatrix}^{-1}
= \begin{bmatrix}
   1.11 & 0 \\
   0 & 10
\end{bmatrix}$

$\hat q = \text{Softmax}(W\hat p + b) = \text{Softmax}(\begin{bmatrix}
   1.11 & 0 \\
   0 & 10
\end{bmatrix}*{[0.9, 0.1]} + 0)
= \text{Softmax}([1, 1])
=[0.5, 0.5]$

Jak bylo uvedeno v칳코e, stejn칳 postup bychom provedli pro v칤ce r콢zn칳ch bezkontextov칳ch vstup콢 a zpr콢m캩rovali bychom kalibra캜n칤 parametry, kter칠 nejl칠pe funguj칤 pro ka쬯칳 bezkontextov칳 vstup, abychom na코li nejlep코칤 kalibra캜n칤 parametry pro LLM. To znamen치, 쬰 kone캜n칠 kalibra캜n칤 parametry pravd캩podobn캩 nebudou mapovat 쮂멳n칳 z bezkontextov칳ch vstup콢 p콏esn캩 na [0,5, 0,5].

### Jin치 metoda

$b$ lze tak칠 nastavit na $-\hat p$ a $W$ na matici identity. Tato metoda funguje l칠pe pro generov치n칤 ne pro klasifikaci(@zhao2021calibrate).

## Z치v캩r

LLM jsou 캜asto predisponov치ny (zkresleny) k ur캜it칳m zna캜k치m. Kalibraci lze pou쮂셦 k potla캜en칤 tohoto zkreslen칤.