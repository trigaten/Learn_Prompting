---
sidebar_position: 1
---

# ğŸŸ¢ Ãšvod

Tato kapitola se zabÃ½vÃ¡ tÃ­m, jak zajistit vÄ›tÅ¡Ã­ spolehlivost doplÅˆovÃ¡nÃ­ a jak implementovat kontroly, kterÃ© zajistÃ­ spolehlivost vÃ½stupÅ¯. 

Do jistÃ© mÃ­ry je vÄ›tÅ¡ina pÅ™edchozÃ­ch popsanÃ½ch technik souvisÃ­ se zlepÅ¡enÃ­m pÅ™esnosti dokonÄovÃ¡nÃ­ (completion), a tÃ­m i spolehlivosti, zejmÃ©na pak sebekonzistence(@wang2022selfconsistency). Existuje vÅ¡ak Å™ada dalÅ¡Ã­ch technik, kterÃ© lze pouÅ¾Ã­t ke zlepÅ¡enÃ­ spolehlivosti, nad rÃ¡mec zÃ¡kladnÃ­ch strategiÃ­ promptingu. 

Bylo zjiÅ¡tÄ›no, Å¾e %%LLM|LLM%% jsou spolehlivÄ›jÅ¡Ã­, neÅ¾ bychom mohli oÄekÃ¡vat, pÅ™i interpretaci toho, co se prompt *snaÅ¾Ã­* Å™Ã­ci, kdyÅ¾ odpovÃ­dajÃ­ na Å¡patnÄ› napsanÃ©, Å¡patnÄ› formulovanÃ©, nebo dokonce aktivnÄ› zavÃ¡dÄ›jÃ­cÃ­ prompty(@webson2023itscomplicated). Navzdory tÃ©to schopnosti se u nich stÃ¡le objevujÃ­ rÅ¯znÃ© problÃ©my vÄetnÄ› halucinacÃ­(@ye2022unreliability), chybnÃ½ch vysvÄ›tlenÃ­ pomocÃ­ metod %%CoT|Chain of Thought Prompting%%%(@ye2022unreliability) a vÃ­cenÃ¡sobnÃ© zkreslenÃ­, vÄetnÄ› zkreslenÃ­ vÄ›tÅ¡inovÃ©ho oznaÄenÃ­, zkreslenÃ­ v souvislosti s recenzÃ­ a zkreslenÃ­ common token bias(@zhao2021calibrate). KromÄ› toho mÅ¯Å¾e bÃ½t zero-shot CoT obzvlÃ¡Å¡tÄ› zkreslenÃ½, kdyÅ¾ se zabÃ½vÃ¡ citlivÃ½mi tÃ©maty(@shaikh2022second).

Mezi bÄ›Å¾nÃ¡ Å™eÅ¡enÃ­ nÄ›kterÃ½ch z tÄ›chto problÃ©mÅ¯ patÅ™Ã­ kalibrÃ¡tory, kterÃ© odstraÅˆujÃ­ _a priori_ zkreslenÃ­ a ovÄ›Å™ovatelÃ©, kteÅ™Ã­ hodnotÃ­ doplnÄ›nÃ­, a takÃ© podporujÃ­ rozmanitosti v doplnÄ›nÃ­ch.
