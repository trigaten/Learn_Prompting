---
sidebar_position: 90
---

# ğŸ“™ SlovnÃ­ zÃ¡soba

Na tÃ©to strÃ¡nce naleznete seznam termÃ­nÅ¯ a pojmÅ¯, kterÃ© budeme v tomto kurzu pouÅ¾Ã­vat.

#### VelkÃ© jazykovÃ© modely (Large Language Models neboli LLM), pÅ™edem natrÃ©novanÃ© jazykovÃ© modely (Pretrained Language Models neboli PLM)(@branch2022evaluating), jazykovÃ© modely (Language Models neboli LM) a zÃ¡kladnÃ­ modely (foundation models).

VÅ¡echny tyto termÃ­ny oznaÄujÃ­ vÃ­cemÃ©nÄ› totÃ©Å¾: velkÃ© umÄ›lÃ© inteligence (neuronovÃ© sÃ­tÄ›), kterÃ© byly obvykle natrÃ©novÃ¡ny
na obrovskÃ©m mnoÅ¾stvÃ­ textu.

#### MaskovanÃ© jazykovÃ© modely (Masked Language Models neboli MLM)

MLM jsou typem modelÅ¯ NLP, kterÃ© majÃ­ speciÃ¡lnÃ­ token, obvykle `[MASK]`, kterÃ½ je nahrazen slovem ze slovnÃ­ku. Model pak pÅ™edpovÃ­dÃ¡ slovo, kterÃ© bylo zamaskovÃ¡no. NapÅ™Ã­klad pokud vÄ›ta znÃ­ `"Pes [MASK] koÄku"`, model s vysokou pravdÄ›podobnostÃ­ pÅ™edpovÃ­ `"honÃ­"`.

#### ZnaÄky (Labels)

Koncept znaÄek nejlÃ©pe pochopÃ­te na pÅ™Ã­kladu.

Å˜eknÄ›me, Å¾e chceme klasifikovat nÄ›kterÃ© tweety jako krutÃ© nebo nekrutÃ© (mean nebo not mean). MÃ¡me-li seznam tweetÅ¯ a jejich odpovÃ­dajÃ­cÃ­ _znaÄku_ (mean nebo not mean), mÅ¯Å¾eme natrÃ©novat model pro klasifikaci zda jsou tweety krutÃ©, nebo ne. ZnaÄky (Å¡tÃ­tky) jsou obecnÄ› jen pravdÄ›podobnosti pro klasifikaÄnÃ­ Ãºlohy.

#### ZlatÃ© znaÄky (Gold Labels)

SprÃ¡vnÃ© znaÄky pro danou Ãºlohu.

#### Prostor znaÄek (Label Space)

VÅ¡echny moÅ¾nÃ© znaÄky pro danou Ãºlohu ("krutÃ©" a "nekrutÃ©" pro vÃ½Å¡e uvedenÃ½ pÅ™Ã­klad).

#### AnalÃ½za sentimentu (Sentiment Analysis)

AnalÃ½za sentimentu je Ãºloha klasifikace textu na pozitivnÃ­, negativnÃ­ nebo jinÃ© sentimenty.

#### "Model" vs. "AI" vs. "LLM".

Tyto termÃ­ny se v tomto kurzu pouÅ¾Ã­vajÃ­ do jistÃ© mÃ­ry zamÄ›nitelnÄ›, ale neznamenajÃ­ vÅ¾dy totÃ©Å¾. Jak bylo uvedeno vÃ½Å¡e, LLM jsou typem AI, ale ne vÅ¡echny AI jsou LLM. KdyÅ¾ se v tomto kurzu zmiÅˆujeme o modelech, mÃ¡me na mysli modely AI. V tomto kurzu 
mÅ¯Å¾ete povaÅ¾ovat pojmy "model" a "AI" za zamÄ›nitelnÃ©.

#### StrojovÃ© uÄenÃ­ (Machine Learning neboli ML)

ML je studijnÃ­ obor, kterÃ½ se zamÄ›Å™uje na algoritmy, kterÃ© se mohou uÄit z dat. ML je podoborem umÄ›lÃ© inteligence.

#### VerbalizÃ©r

V klasifikaÄnÃ­m prostÅ™edÃ­ jsou verbalizÃ©ry mapovÃ¡nÃ­ ze znaÄek na slova ve slovnÃ­ku jazykovÃ©ho modelu(@schick2020exploiting). UvaÅ¾ujme napÅ™Ã­klad klasifikaci sentimentu s nÃ¡sledujÃ­cÃ­ vÃ½zvou:

```text
Tweet: "Miluji Hotpockets"
JakÃ½ je sentiment tohoto tweetu? Å˜eknÄ›te "pozitivnÃ­" (positive) nebo "negativnÃ­" (negative).
```

Zde je verbalizÃ©r mapovÃ¡nÃ­m z pojmovÃ½ch znaÄek `positive` a `negative` na tokeny `pos` a `neg`.

#### UÄenÃ­ posilovÃ¡nÃ­m ze zpÄ›tnÃ© vazby od ÄlovÄ›ka (Reinforcement Learning from Human Feedback neboli RLHF)

Technika, kterÃ¡ trÃ©nuje model odmÄ›ny pÅ™Ã­mo z lidskÃ© zpÄ›tnÃ© vazby a pouÅ¾Ã­vÃ¡ tento model jako funkci odmÄ›ny k optimalizaci politiky agenta pomocÃ­ posilujÃ­cÃ­ho uÄenÃ­ (Reinforcement Learning â€“ RL) pÅ™es optimalizaÄnÃ­ algoritmus.

#### Fine tuning

Je to proces, pÅ™i kterÃ©m se pÅ™edtrÃ©novanÃ½ model (napÅ™. LLM) pÅ™izpÅ¯sobuje pro konkrÃ©tnÃ­ Ãºlohu trÃ©novÃ¡nÃ­m na oznaÄenÃ½ch datech souvisejÃ­cÃ­ch s danou Ãºlohou.

PÅ™i fine-tuningu se pouÅ¾Ã­vajÃ­ metody uÄenÃ­ s dohledem (supervised learning), kdy jsou k dispozici oznaÄenÃ¡ trÃ©novacÃ­ data pro danou Ãºlohu. Model se potÃ© trÃ©nuje na tÄ›chto datech, aby se pÅ™izpÅ¯sobil konkrÃ©tnÃ­ Ãºloze a zlepÅ¡il svou vÃ½konnost.

#### ExemplÃ¡Å™e (exemplars)

Jsou to pÅ™Ã­klady Ãºlohy, kterou se prompt snaÅ¾Ã­ vyÅ™eÅ¡it a kterÃ¡ je souÄÃ¡stÃ­ samotnÃ©ho promptu.

#### Few Shot Standard Prompt

Technika promptingu, kterÃ¡ umoÅ¾Åˆuje modelu zpracovat pÅ™Ã­klady pÅ™ed pokusem o splnÄ›nÃ­ Ãºkolu. Jsou to standardnÃ­ prompty, kterÃ© obsahujÃ­ exemplÃ¡Å™e.

#### Chain of Thought Prompting â€“ CoT

Prompting pomocÃ­ myÅ¡lenkovÃ©ho Å™etÄ›zce (Chain-of-thought prompting - CoT) zlepÅ¡uje schopnost uvaÅ¾ovÃ¡nÃ­ LLM tÃ­m, Å¾e je podnÄ›cuje k vytvoÅ™enÃ­ Å™ady mezikrokÅ¯, kterÃ© vedou ke koneÄnÃ© odpovÄ›di na vÃ­cekrokovÃ½ problÃ©m.

#### Least to Most Prompting â€“ LtM

Prompting od nejmenÅ¡Ã­ho k nejvÄ›tÅ¡Ã­mu (Least to Most Prompting â€“ LtM) nejprve rozdÄ›lÃ­ problÃ©m na dÃ­lÄÃ­ problÃ©my a pak Å™eÅ¡Ã­ kaÅ¾dÃ½ z nich. JednÃ¡ se o techniku inspirovanou reÃ¡lnÃ½mi vzdÄ›lÃ¡vacÃ­mi strategiemi pro dÄ›ti.

#### Program-aided Language Models â€“ PAL

KdyÅ¾ je zadÃ¡na otÃ¡zka, jsou PAL schopni napsat kÃ³d, kterÃ½ tuto otÃ¡zku Å™eÅ¡Ã­. Tento kÃ³d odeÅ¡lou do programovÃ©ho runtime, aby zÃ­skali vÃ½sledek. PAL funguje jinak neÅ¾ CoT; zprostÅ™edkujÃ­cÃ­m uvaÅ¾ovÃ¡nÃ­m PAL je kÃ³d, zatÃ­mco CoT je pÅ™irozenÃ½ jazyk. Jinak Å™eÄeno, je to metoda, kterÃ¡ vyuÅ¾Ã­vÃ¡ LLM ke ÄtenÃ­ problÃ©mÅ¯ v pÅ™irozenÃ©m jazyce a generovÃ¡nÃ­ programÅ¯ jako mezikrokÅ¯ v uvaÅ¾ovÃ¡nÃ­, ale krok Å™eÅ¡enÃ­ pÅ™enÃ¡Å¡Ã­ na programovÃ½ runtime, jako je interpret Pythonu. 

#### Modular Reasoning, Knowledge and Language â€“ MRKL

SystÃ©my MRKL jsou neuro-symbolickou architekturou, kterÃ¡ kombinuje LLM a externÃ­ nÃ¡stroje, jako jsou kalkulaÄky (symbolickÃ© vÃ½poÄty), k Å™eÅ¡enÃ­ sloÅ¾itÃ½ch problÃ©mÅ¯.

SystÃ©m MRKL se sklÃ¡dÃ¡ ze sady modulÅ¯ (napÅ™. kalkulaÄka, API pro poÄasÃ­, databÃ¡ze atd.) a smÄ›rovaÄe, kterÃ½ rozhoduje o tom, jak "smÄ›rovat" pÅ™Ã­chozÃ­ dotazy v pÅ™irozenÃ©m jazyce na pÅ™Ã­sluÅ¡nÃ½ modul.

JednoduchÃ½m pÅ™Ã­kladem systÃ©mu MRKL je LLM, kterÃ½ mÅ¯Å¾e pouÅ¾Ã­vat aplikaci kalkulaÄky. JednÃ¡ se o systÃ©m s jednÃ­m modulem, kde LLM je smÄ›rovaÄem. PÅ™i dotazu "Kolik je 100*100?" mÅ¯Å¾e LLM zvolit, Å¾e z dotazu vytÃ¡hne ÄÃ­sla, a pak systÃ©mu MRKL Å™Ã­ct, aby k vÃ½poÄtu vÃ½sledku pouÅ¾il aplikaci kalkulaÄky.

<!-- %%RemarkAutoGlossary::list_all%% -->
