export const metadata = { sidebar_position: 90, title: "🟢 LLMs の落とし穴" };

# 🟢 LLMs の落とし穴

<div style={{ textAlign: "center" }}>
  <Image
    src={"/docs/assets/basics/pitfalls.svg"}
    width={1600}
    height={1019}
    style={{
      width: "100%",
      height: "300px",
      verticalAlign: "top",
      margin: "auto",
    }}
  />
</div>

LLMは非常に強力ですが、決して完璧ではありません。 それらを使用する際に注意すべき多くの落とし穴があります。

## 引用ソース

LLM はほとんどの場合、**情報源を正確に示すことはできません**。 LLM はインターネットにアクセスできず、情報がどこから来たのかを正確に記憶していないためです。 LLM はいかにもそれらしい情報源を提示しますが、完全に不正確です。

<Note>
  検索拡張 LLM（インターネットやその他のソースを検索できる
  LLM）など、この問題を解決可能なものも存在します。
</Note>

## バイアス

LLM はしばしばステレオタイプな回答を生成する傾向があります。 安全装置があっても、時には性差別的な発言や人種差別的な発言、または同性愛者に対する差別的な発言をすることがあります。 消費者向けアプリケーションでLLMを使用する際には注意してください。 また、研究で使用する際にも偏りのある結果を生成する可能性があるため注意が必要です。

## 幻覚

LLM は、回答が分からない質問に対しては、しばしば誤った情報を生成することがあります。 時には、答えが分からないと回答することもありますが、多くの場合、自信満々に誤った回答をします。

## 数学

LLM は数学を苦手とします。 彼らは簡単な数学の問題を解くのすら難しく、より複雑な数学の問題は解決できないことがよくあります。

<Note>
  この問題は、[ツール拡張
  LLM](https://learnprompting.org/docs/advanced_applications/mrkl)
  を使用して、ある程度解決できます。
</Note>
:::

## プロンプトハッキング

ユーザーはしばしば LLM をして、望む内容を生成させることができます。 詳しくは[こちら](https://learnprompting.org/ja/docs/category/-prompt-hacking)をご覧ください。
