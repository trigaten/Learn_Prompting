export const metadata = { sidebar_position: 10, title: "üî¥ Calibrandos LLMs" };

# üî¥ Calibrandos LLMs

√â poss√≠vel contrabalan√ßar alguns dos vieses que as LLMs exibem atrav√©s da calibra√ß√£o de **distribui√ß√µes de sa√≠da**(@zhao2021calibrate).

**O que exatamente significa calibrar uma distribui√ß√£o de sa√≠da?**

Vamos dar um exemplo r√°pido: digamos que temos uma tarefa de %%an√°lise de sentimento|sentiment analysis%% com dois poss√≠veis r√≥tulos, `Positivo` e `Negativo`.
Considere o que acontece quando a %%LLM|LLM%% recebe `Entrada: nada Sentimento:` .
Esta entrada n√£o cont√©m nenhum _contexto_ que a LLM possa usar para fazer uma previs√£o de sentimento, portanto, √© chamada de **entrada sem contexto**.

Como `nada` n√£o √© um conceito positivo ou negativo, esperar√≠amos que a LLM retornasse uma probabilidade de cerca de 0,5 para ambos `Positivo` e `Negativo`. No entanto, muitas vezes (e para este exemplo), esse n√£o ser√° o caso.

```
p("Positivo" | "Entrada: nada Sentimento:") = 0.9

p("Negativo" | "Entrada: nada Sentimento:") = 0.1
```

Dadas essas probabilidades de r√≥tulo para uma entrada sem contexto, sabemos que a **distribui√ß√£o de sa√≠da** da LLM provavelmente est√° enviesada em dire√ß√£o ao r√≥tulo `Positivo`. Isso pode fazer com que a LLM favore√ßa `Positivo` para todas as entradas, mesmo que a entrada n√£o seja realmente positiva.

Se pudermos de alguma forma **calibrar** a distribui√ß√£o de sa√≠da, de modo que entradas sem contexto sejam atribu√≠das a uma probabilidade de 0,5 para ambos `Positivo` e `Negativo`, podemos remover o vi√©s em rela√ß√£o a `Positivo` e a LLM ser√° mais confi√°vel em ambas as entradas sem contexto e com contexto.

## Solu√ß√£o n√£o-t√©cnica

Uma solu√ß√£o n√£o t√©cnica para esse problema √© simplesmente fornecer exemplos de poucos disparos em que os exemplos livres de contexto s√£o efetivamente atribu√≠dos a uma probabilidade de 0,5 para ambas as classes `Positivo` e `Negativo`.

Por exemplo, poder√≠amos fornecer os seguintes exemplos de poucos disparos que mostram cada exemplo livre de contexto sendo classificado como `Positivo` e `Negativo`:

```
Entrada: Eu odeio esse filme. Sentimento: Negativo
Entrada: Eu amo esse filme. Sentimento: Positivo
Entrada: N/A Sentimento: Positivo
Entrada: N/A Sentimento: Negativo
Entrada: nada Sentimento: Positivo
Entrada: nada Sentimento: Negativo
Entrada: Eu gosto de ovos. Sentimento:
```

At√© onde eu sei, essa solu√ß√£o n√£o foi explorada na literatura, e n√£o tenho certeza de como ela funciona na pr√°tica. No entanto, √© uma solu√ß√£o simples que demonstra o que a calibra√ß√£o est√° tentando alcan√ßar.

## Solu√ß√£o t√©cnica

Outra solu√ß√£o para isso √© a **calibra√ß√£o contextual**(@zhao2021calibrate), onde ajustamos par√¢metros de calibra√ß√£o especiais, que garantem que entradas sem contexto, como `Entrada: nada Sentimento:`, sejam atribu√≠das a uma probabilidade de cerca de 0,5 para ambas as classes. Note que, na pr√°tica, esse m√©todo realiza a calibra√ß√£o em v√°rias entradas sem contexto diferentes (por exemplo, `Entrada: N/A Sentimento:`, `Entrada: [MASK] Sentimento:`). Ele calcula a m√©dia dos par√¢metros de calibra√ß√£o que funcionam melhor para cada entrada sem contexto para encontrar os melhores par√¢metros de calibra√ß√£o para o LLM.

### Exemplo

Vamos considerar um exemplo de c√°lculo dos par√¢metros de calibra√ß√£o para uma entrada livre de contexto. Observe que este exemplo n√£o √© reproduz√≠vel com o GPT-3 devido ao fato de que n√£o pode ser restrito aos r√≥tulos `Positivo` e `Negativo`.

Considere novamente o exemplo acima em que o LLM atribui as seguintes probabilidades aos r√≥tulos para uma entrada livre de contexto:

```
p("Positivo" | "Entrada: nada Sentimento:") = 0.9

p("Negativo" | "Entrada: nada Sentimento:") = 0.1
```

N√≥s queremos encontrar uma distribui√ß√£o probabilistica q de forma que:

```
q("Positivo" | "Entrada: nada Sentimento:") = 0.5

q("Negativo" | "Entrada: nada Sentimento:") = 0.5
```

Faremos isso criando uma transforma√ß√£o linear que ajusta (calibra) as probabilidades de $p$.

$\hat q = \text{Softmax}(W\hat p + b)$

Esta equa√ß√£o considera as probabilidades originais $\hat p$ e aplica os pesos $W$ e o vi√©s $b$ a elas. Os pesos $W$ e o vi√©s $b$ s√£o os par√¢metros de calibra√ß√£o, que, quando aplicados √†s probabilidades do exemplo livre de contexto, produzir√£o $\hat p$ = [0.5, 0.5].

#### Calculando W e b

Precisamos calcular os pesos $W$ e o vi√©s $b$ de alguma forma. Uma maneira de fazer isso √©:

$W = \text{diag}(\hat p)^{-1}$

$b = 0$

Embora a defini√ß√£o de $W$ possa parecer um pouco estranha √† primeira vista, ela apenas est√° pegando o inverso de cada valor em $\hat p$ para encontrar um $W$ que transformar√° as probabilidades originais $\hat p$ em probabilidades calibradas [0,5, 0,5].

Vamos verificar se isso funciona para o exemplo acima:

$\hat p = [0.9, 0.1]$

$W = \text{diag}(\hat p)^{-1} = \text{diag}([0.9, 0.1])^{-1} 
= \begin{bmatrix}
   0.9 & 0 \\
   0 & 0.1
\end{bmatrix}^{-1}
= \begin{bmatrix}
   1.11 & 0 \\
   0 & 10
\end{bmatrix}$

$\hat q = \text{Softmax}(W\hat p + b) = \text{Softmax}(\begin{bmatrix}
   1.11 & 0 \\
   0 & 10
\end{bmatrix}*{[0.9, 0.1]} + 0)
= \text{Softmax}([1, 1])
=[0.5, 0.5]$

Como mencionado acima, executar√≠amos esse mesmo processo para v√°rias entradas livres de contexto, pegar a m√©dia dos par√¢metros de calibra√ß√£o que funcionam melhor para cada entrada, a fim de para encontrar os melhores par√¢metros de calibra√ß√£o para o LLM. Isso significa que os par√¢metros de calibra√ß√£o finais provavelmente n√£o mapear√£o nenhuma das entradas em exatamente 0.5, 0.5].

### Outro m√©todo

$b$ tamb√©m pode ser ajustado para $-\hat p$ e $W$ para a matriz identidade. Este m√©todo funciona melhor em tarefas de gera√ß√£o do que em tarefas de classifica√ß√£o (@zhao2021calibrate).

## Conclus√µes

LLMs geralmente apresentam predisposi√ß√£o (vi√©s) em rela√ß√£o a certos r√≥tulos. A calibra√ß√£o pode ser usada para neutralizar esse vi√©s.
