export const metadata = { sidebar_position: 1000, title: "ğŸ“š Ú©ØªØ§Ø¨ÛŒØ§Øª" };

# ğŸ“š Ú©ØªØ§Ø¨ÛŒØ§Øª

ØµÙØ­Û Ø§Ø³ Ú©ÙˆØ±Ø³ Ú©Û’ Ø°Ø±ÛŒØ¹Û Ø§Ø³ØªØ¹Ù…Ø§Ù„ ÛÙˆÙ†Û’ ÙˆØ§Ù„Û’ ØªÙ…Ø§Ù… Ú©Ø§ØºØ°Ø§Øª Ú©ÛŒ Ø§ÛŒÚ© Ù…Ù†Ø¸Ù… ÙÛØ±Ø³Øª Ù¾Ø± Ù…Ø´ØªÙ…Ù„ ÛÛ’Û”
Ù…Ù‚Ø§Ù„Û’ Ø¹Ù†ÙˆØ§Ù† Ú©Û’ Ù„Ø­Ø§Ø¸ Ø³Û’ ØªØ±ØªÛŒØ¨ Ø¯ÛŒØ¦Û’ Ú¯Ø¦Û’ ÛÛŒÚºÛ”

**Ø§Ø³ Ú©ÙˆØ±Ø³ Ú©Ø§ Ø­ÙˆØ§Ù„Û Ø¯ÛŒÙ†Û’ Ú©Û’ Ù„ÛŒÛ’ØŒ Github Ø°Ø®ÛŒØ±Û Ù…ÛŒÚº ÙØ±Ø§ÛÙ… Ú©Ø±Ø¯Û Ø­ÙˆØ§Ù„Û Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ÛŒÚºÛ”**

```md
@software{Schulhoff_Learn_Prompting_2022,
author = {Schulhoff, Sander and Community Contributors},
month = dec,
title = {{Learn Prompting}},
url = {https://github.com/trigaten/Learn_Prompting},
year = {2022}
}
```

Ù†ÙˆÙ¹: Ú†ÙˆÙ†Ú©Û [Ù†Û ØªÙˆ GPT-3 Ø§ÙˆØ± Ù†Û ÛÛŒ GPT-3 Ø§Ù†Ø³Ù¹Ø±Ú©Ù¹ Ù¾ÛŒÙ¾Ø± ÚˆÛŒÙˆÙ†Ú†ÛŒ Ù…Ø§ÚˆÙ„Ø² Ø³Û’ Ù…Ø·Ø§Ø¨Ù‚Øª Ø±Ú©Ú¾ØªØ§ ÛÛ’](https://twitter.com/janleike/status/1584618242756132864)ØŒ Ù…ÛŒÚº Ú©ÙˆØ´Ø´ Ú©Ø±ØªØ§ ÛÙˆÚº Ú©Û
Ø§Ø³ Ø·Ø±Ø­ Ø§Ù† Ú©Ø§ Ø­ÙˆØ§Ù„Û Ø¯ÛŒØªÛ’ ÛÛŒÚº.

{"AUTOGENERATED BELOW, DO NOT EDIT"}

## Agents

#### MRKL(@karpas2022mrkl)

#### ReAct(@yao2022react)

#### PAL(@gao2022pal)

#### Auto-GPT(@richards2023)

#### Baby AGI(@nakajima2023)

#### AgentGPT(@reworkd2023)

#### Toolformer(@schick2023toolformer)

## Automated

#### AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts(@shin2020autoprompt)

#### automatic prompt engineer(@zhou2022large)

#### Soft Prompting(@lester2021power)

#### discretized soft prompting (interpreting)(@khashabi2021prompt)

## Datasets

#### SCAN dataset (compositional generalization)(@lake2018scan)

#### GSM8K(@cobbe2021training)

#### hotpotQA(@yang2018hotpotqa)

#### multiarith(@roy-roth-2015-solving)

#### fever dataset(@thorne2018fever)

#### bbq(@parrish2021bbq)

## Detection

#### Don't ban chatgpt in schools. teach with it.(@roose2022dont)

#### Schools Shouldn't Ban Access to ChatGPT(@lipman2022gpt)

#### Certified Neural Network Watermarks with Randomized Smoothing(@bansal2022certified)

#### Watermarking Pre-trained Language Models with Backdooring(@gu2022watermarking)

#### GW preparing disciplinary response to AI programs as faculty explore educational use(@noonan2023gw)

#### A Watermark for Large Language Models(@kirchenbauer2023watermarking)

#### DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature(@mitchell2023detectgpt)

## Image Prompt Engineering

#### Prompt Engineering for Text-Based Generative Art(@oppenlaender2022prompt)

#### The DALLE 2 Prompt Book(@parsons2022dalleprompt)

#### With the right prompt, Stable Diffusion 2.0 can do hands.(@blake2022with)

## Meta Analysis

#### How Generative AI Is Changing Creative Work(@Davenport_Mittal_2022)

#### How AI Will Change the Workplace(@Captain_2023)

#### ChatGPT took their jobs. Now they walk dogs and fix air conditioners.(@Verma_Vynck_2023)

#### No title(@IBM_Do_2023)

## Miscl

#### The Turking Test: Can Language Models Understand Instructions?(@efrat2020turking)

#### A Taxonomy of Prompt Modifiers for Text-To-Image Generation(@oppenlaender2022taxonomy)

#### DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models(@wang2022diffusiondb)

#### Optimizing Prompts for Text-to-Image Generation(@hao2022optimizing)

#### Language Model Cascades(@dohan2022language)

#### Design Guidelines for Prompt Engineering Text-to-Image Generative Models(@liu2022design)

#### Discovering Language Model Behaviors with Model-Written Evaluations(@perez2022discovering)

#### Selective Annotation Makes Language Models Better Few-Shot Learners(@su2022selective)

#### Atlas: Few-shot Learning with Retrieval Augmented Language Models(@izacard2022atlas)

#### STRUDEL: Structured Dialogue Summarization for Dialogue Comprehension(@wang2022strudel)

#### Prompting Is Programming: A Query Language For Large Language Models(@beurerkellner2022prompting)

#### Parallel Context Windows Improve In-Context Learning of Large Language Models(@ratner2022parallel)

#### Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models(@bursztyn2022learning)

#### Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks(@wang2022supernaturalinstructions)

#### Making Pre-trained Language Models Better Few-shot Learners(@gao2021making)

#### How to Prompt? Opportunities and Challenges of Zero- and Few-Shot Learning for Human-AI Interaction in Creative Applications of Generative Models(@dang2022prompt)

#### On Measuring Social Biases in Prompt-Based Multi-Task Learning(@akyrek2022measuring)

#### Plot Writing From Pre-Trained Language Models(@jin2022plot)

#### \{S\}tereo\{S\}et: Measuring stereotypical bias in pretrained language models(@nadeem-etal-2021-stereoset)

#### Survey of Hallucination in Natural Language Generation(@Ji_2022)

#### Wordcraft: Story Writing With Large Language Models(@yuan2022wordcraft)

#### PainPoints: A Framework for Language-based Detection of Chronic Pain and Expert-Collaborative Text-Summarization(@fadnavis2022pain)

#### Self-Instruct: Aligning Language Model with Self Generated Instructions(@wang2022selfinstruct)

#### From Images to Textual Prompts: Zero-shot VQA with Frozen Large Language Models(@guo2022images)

#### New and improved content moderation tooling(@markov_2022)

#### Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference(@schick2020exploiting)

#### Human-level concept learning through probabilistic program induction(@lake2015human)

#### \{Riffusion - Stable diffusion for real-time music generation\}(@Forsgren_Martiros_2022)

#### How to use OpenAIâ€™s ChatGPT to write the perfect cold email(@bonta2022how)

#### Cacti: biology and uses(@nobel2002cacti)

#### Are Language Models Worse than Humans at Following Prompts? Itâ€™s Complicated(@webson2023itscomplicated)

#### Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration(@wang2023unleashing)

## Prompt Hacking

#### Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods(@crothers2022machine)

#### New jailbreak based on virtual functions - smuggle illegal tokens to the backend.(@nin2023new)

#### Exploiting Programmatic Behavior of LLMs: Dual-Use Through Standard Security Attacks(@kang2023exploiting)

#### More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models(@greshake2023youve)

#### ChatGPT "DAN" (and other "Jailbreaks")(@kiho2023chatgpt)

#### Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples(@branch2022evaluating)

#### Prompt injection attacks against GPT-3(@simon2022inject)

#### Exploiting GPT-3 prompts with malicious inputs that order the model to ignore its previous directions(@goodside2022inject)

#### History Correction(@goodside2022history)

#### adversarial-prompts(@chase2021adversarial)

#### GPT-3 Prompt Injection Defenses(@goodside2021gpt)

#### Talking to machines: prompt engineering & injection(@christoph2022talking)

#### Using GPT-Eliezer against ChatGPT Jailbreaking(@armstrong2022using)

#### Exploring Prompt Injection Attacks(@selvi2022exploring)

#### The entire prompt of Microsoft Bing Chat?! (Hi, Sydney.)(@kevinbing)

#### Ignore Previous Prompt: Attack Techniques For Language Models(@perez2022jailbreak)

#### Lessons learned on Language Model Safety and misuse(@brundage_2022)

#### Toxicity Detection with Generative Prompt-based Inference(@wang2022jailbreak)

#### ok I saw a few people jailbreaking safeguards openai put on chatgpt so I had to give it a shot myself(@alice2022jailbreak)

#### Bypass @OpenAI's ChatGPT alignment efforts with this one weird trick(@miguel2022jailbreak)

#### ChatGPT jailbreaking itself(@derek2022jailbreak)

#### Using "pretend" on #ChatGPT can do some wild stuff. You can kind of get some insight on the future, alternative universe.(@nero2022jailbreak)

#### I kinda like this one even more!(@nick2022jailbreak)

#### uh oh(@sam2022jailbreak)

#### Building A Virtual Machine inside ChatGPT(@jonas2022jailbreak)

## Reliability

#### MathPrompter: Mathematical Reasoning using Large Language Models(@imani2023mathprompter)

#### The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning(@ye2022unreliability)

#### Prompting GPT-3 To Be Reliable(@si2022prompting)

#### On the Advance of Making Language Models Better Reasoners(@li2022advance)

#### Ask Me Anything: A simple strategy for prompting language models(@arora2022ama)

#### Calibrate Before Use: Improving Few-Shot Performance of Language Models(@zhao2021calibrate)

#### Can large language models reason about medical questions?(@livin2022large)

#### Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference(@mitchell2022enhancing)

#### On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning(@shaikh2022second)

#### Evaluating language models can be tricky(@chase2022evaluating)

#### Constitutional AI: Harmlessness from AI Feedback(@bai2022constitutional)

## Surveys

#### Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics and Speech Recognition(@jurafsky2009)

#### Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing(@liu2021pretrain)

#### PromptPapers(@ning2022papers)

#### A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT(@white2023prompt)

## Techniques

#### Chain of Thought Prompting Elicits Reasoning in Large Language Models(@wei2022chain)

#### Large Language Models are Zero-Shot Reasoners(@kojima2022large)

#### Self-Consistency Improves Chain of Thought Reasoning in Language Models(@wang2022selfconsistency)

#### What Makes Good In-Context Examples for GPT-3?(@liu2021makes)

#### Generated Knowledge Prompting for Commonsense Reasoning(@liu2021generated)

#### Recitation-Augmented Language Models(@sun2022recitationaugmented)

#### Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?(@min2022rethinking)

#### Show Your Work: Scratchpads for Intermediate Computation with Language Models(@nye2021work)

#### Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations(@jung2022maieutic)

#### STaR: Bootstrapping Reasoning With Reasoning(@zelikman2022star)

#### Least-to-Most Prompting Enables Complex Reasoning in Large Language Models(@zhou2022leasttomost)

#### Reframing Instructional Prompts to GPTkâ€™s Language(@mishra2022reframing)

#### Cutting Down on Prompts and Parameters: Simple Few-Shot Learning with Language Models(@logan-iv-etal-2022-cutting)

#### Role-Play with Large Language Models(@shanahan2023roleplay)

#### CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society(@li2023camel)

#### TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks(@santu2023teler)

## Models

### Image Models

#### Stable Diffusion(@rombach2021highresolution)

#### DALLE(@ramesh2022hierarchical)

### Language Models

#### ChatGPT(@chatgpt2022)

#### GPT-3(@brown2020language)

#### Instruct GPT(@ouyang2022training)

#### GPT-4(@openai2023gpt4)

#### PaLM: Scaling Language Modeling with Pathways(@chowdhery2022palm)

#### BLOOM: A 176B-Parameter Open-Access Multilingual Language Model(@scao2022bloom)

#### BLOOM+1: Adding Language Support to BLOOM for Zero-Shot Prompting(@yong2022bloom1)

#### Jurassic-1: Technical Details and Evaluation, White paper, AI21 Labs, 2021(@lieberjurassic)

#### GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model(@wange2021gptj)

#### Roberta: A robustly optimized bert pretraining approach(@liu2019roberta)

## Tooling

### Ides

#### TextBox 2.0: A Text Generation Library with Pre-trained Language Models(@tang2022textbox)

#### Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models(@strobelt2022promptide)

#### PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts(@bach2022promptsource)

#### PromptChainer: Chaining Large Language Model Prompts through Visual Programming(@wu2022promptchainer)

#### OpenPrompt: An Open-source Framework for Prompt-learning(@ding2021openprompt)

#### PromptMaker: Prompt-Based Prototyping with Large&nbsp;Language&nbsp;Models(@jiang2022promptmaker)

### Tools

#### LangChain(@Chase_LangChain_2022)

#### GPT Index(@Liu_GPT_Index_2022)
