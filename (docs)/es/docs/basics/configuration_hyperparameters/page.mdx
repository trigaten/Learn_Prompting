export const metadata = { sidebar_position: 100, title: "游릭 Ajustes del LLM" };

# 游릭 Ajustes del LLM

<div style={{ textAlign: "center" }}>
  <Image
    src={"/docs/assets/basics/temperature.svg"}
    width={1247}
    height={1983}
    style={{
      width: "500px",
      height: "300px",
      verticalAlign: "top",
      margin: "auto",
    }}
  />
</div>

# Introducci칩n

Los resultados de los LLM pueden verse afectados por los _hiperpar치metros de configuraci칩n_, que controlan varios aspectos del modelo, como su grado de "aleatoriedad". Estos hiperpar치metros pueden ajustarse para producir resultados m치s creativos, diversos e interesantes. En esta secci칩n, discutiremos dos hiperpar치metros de configuraci칩n importantes y c칩mo afectan a los resultados de los LLM.

<Note>
  [para investigadores] Son diferentes de los hiperpar치metros normales, como la
  tasa de aprendizaje, el n칰mero de capas, el tama침o oculto, etc.
</Note>

## Temperatura

La temperatura es un hiperpar치metro de configuraci칩n que controla la aleatoriedad de los resultados del modelo ling칲칤stico. Una temperatura alta produce resultados m치s impredecibles y creativos, mientras que una temperatura baja produce resultados m치s comunes y conservadores. Por ejemplo, si ajusta la temperatura a 0.5, el modelo generar치 normalmente un texto m치s predecible y menos creativo que si ajusta la temperatura a 1.0.

## Top p

Top p, tambi칠n conocido como muestreo de n칰cleos, es otro hiperpar치metro de configuraci칩n que controla la aleatoriedad de la salida del modelo ling칲칤stico. Establece un umbral de probabilidad y selecciona los tokens superiores cuya probabilidad acumulada supera el umbral. A continuaci칩n, el modelo toma muestras aleatorias de este conjunto de tokens para generar la salida. Este m칠todo puede producir resultados m치s diversos e interesantes que los m칠todos tradicionales, que muestrean aleatoriamente todo el vocabulario. Por ejemplo, si se fija top p en 0,9, el modelo s칩lo tendr치 en cuenta las palabras m치s probables que constituyan el 90% de la masa de probabilidad.

## Otros hiperpar치metros relevantes

Hay muchos otros hiperpar치metros que pueden afectar el rendimiento del modelo de lenguaje, como la frecuencia y las penalizaciones por presencia. No los cubrimos aqu칤, pero tal vez lo haremos en el futuro.

## C칩mo estos hiperpar치metros afectan la salida

Tanto la temperatura como el valor top p pueden afectar al resultado de un modelo ling칲칤stico controlando el grado de aleatoriedad y diversidad del texto generado. Un valor alto de temperatura o de top p produce resultados m치s impredecibles e interesantes, pero tambi칠n aumenta la probabilidad de errores o de texto sin sentido. Un valor bajo de temperatura o de Top p pueden producir resultados m치s conservadores y predecibles, pero tambi칠n pueden dar lugar a texto repetitivo o poco interesante.

Para tareas de generaci칩n de texto, puede que le interese utilizar una temperatura alta o un valor p alto. Sin embargo, para las tareas en las que la precisi칩n es importante, como las tareas de traducci칩n o la respuesta a preguntas, se debe utilizar una temperatura baja o un valor p superior para mejorar la precisi칩n y la correcci칩n factual.

<Note>
  A veces, m치s aleatoriedad puede ser 칰til en tareas donde la precisi칩n es
  necesaria cuando se combina con [t칠cnicas especiales de
  prompting](https://learnprompting.org/docs/intermediate/self_consistency).
</Note>

## Conclusi칩n

En resumen, la temperatura, el top p y otros hiperpar치metros de configuraci칩n del modelo son factores clave a tener en cuenta cuando se trabaja con modelos ling칲칤sticos. Al comprender la relaci칩n entre estos hiperpar치metros y el resultado del modelo, los profesionales pueden optimizar sus prompts para tareas y aplicaciones espec칤ficas.

<Warning>
  Algunos modelos, como ChatGPT, **no** permiten ajustar estos hiperpar치metros
  de configuraci칩n.
</Warning>

Por jackdickens382
