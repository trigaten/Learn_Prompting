export const metadata = {
  sidebar_position: 40,
  title: "üü¢ Chatbot + Base de Conocimiento",
};

# üü¢ Chatbot + Base de Conocimiento

Los avances recientes en modelos de lenguaje grandes (LLMs, por sus siglas en ingl√©s) como [GPT-3](https://arxiv.org/abs/2005.14165) y [ChatGPT](https://chat.openai.com/chat) han creado mucha expectaci√≥n en la industria tecnol√≥gica. Estos modelos son incre√≠blemente poderosos para la generaci√≥n de contenido, pero tambi√©n tienen algunas desventajas, como el sesgo(@nadeem-etal-2021-stereoset) y las alucinaciones(@Ji_2022). Una √°rea en la que estos LLMs pueden ser particularmente √∫tiles es en el desarrollo de chatbots.

## Chatbots basados en Intenci√≥n

Los chatbots tradicionales suelen estar basados en intenciones, lo que significa que son dise√±ados para responder a intenciones de usuario espec√≠ficas. Cada intenci√≥n est√° compuesta por un conjunto de preguntas de muestra y una respuesta asociada. Por ejemplo, la intenci√≥n "Clima" puede incluir preguntas de muestra como "¬øC√≥mo est√° el clima hoy?" o "¬øLlover√° hoy?" y una respuesta como "Hoy estar√° soleado". Cuando un usuario hace una pregunta, el chatbot compara la pregunta con las preguntas de muestra m√°s similares asociadas a la intenci√≥n, y devuelve la respuesta correspondiente

<div style={{ textAlign: "left" }}>
  <Image
    src="/docs/assets/basic_applications/chatbot_from_kb_intents.webp"
    width={2966}
    height={1676}
    style={{ width: "700px", margin: "auto" }}
  />

  <p style={{ color: "gray", fontSize: "12px", fontStyle: "italic" }}>
    C√≥mo funciona un chatbot tradicional basado en intenciones. Imagen del
    autor.
  </p>
</div>

Sin embargo, los chatbots basados en intenciones tienen su propio conjunto de problemas. Un problema es que requieren una gran cantidad de intenciones espec√≠ficas para dar respuestas espec√≠ficas. Por ejemplo, las expresiones de usuario como "No puedo iniciar sesi√≥n", "Olvid√© mi contrase√±a" o "Error de inicio de sesi√≥n" pueden necesitar tres respuestas diferentes y, por lo tanto, tres intenciones diferentes, aunque todas son bastante similares.

## C√≥mo puede ayudar GPT-3

Aqu√≠ es donde GPT-3 puede ser especialmente √∫til. En lugar de tener muchas intenciones muy espec√≠ficas, cada intenci√≥n puede ser m√°s amplia y aprovechar un documento de su [Base de Conocimiento](https://en.wikipedia.org/wiki/Knowledge_base). Una Base de Conocimiento (KB, por sus siglas en ingl√©s) es informaci√≥n almacenada como datos estructurados y no estructurados, listos para ser utilizados para an√°lisis o inferencia. Su KB puede estar compuesta de una serie de documentos que explican c√≥mo usar sus productos.

De esta manera, cada intenci√≥n est√° asociada con un documento en lugar de una lista de preguntas y una respuesta espec√≠fica, por ejemplo, una intenci√≥n para "problemas de inicio de sesi√≥n", otra para "c√≥mo suscribirse", etc. Cuando un usuario hace una pregunta sobre el inicio de sesi√≥n, podemos pasar el documento "problemas de inicio de sesi√≥n" a GPT-3 como informaci√≥n de contexto y generar una respuesta espec√≠fica a la pregunta del usuario.

<div style={{ textAlign: "left" }}>
  <Image
    src="/docs/assets/basic_applications/chatbot_from_kb_gpt3.webp"
    width={2962}
    height={1672}
    style={{ width: "700px", margin: "auto" }}
  />

  <p style={{ color: "gray", fontSize: "12px", fontStyle: "italic" }}>
    C√≥mo podr√≠a funcionar un chatbot aprovechando GPT-3. Imagen del autor.
  </p>
</div>

Este enfoque reduce el n√∫mero de intenciones que necesitan ser gestionadas y permite respuestas mejor adaptadas a cada pregunta. Adem√°s, si el documento asociado con la intenci√≥n describe diferentes procesos (por ejemplo, un proceso para "inicio de sesi√≥n en el sitio web" y otro para "inicio de sesi√≥n en la aplicaci√≥n m√≥vil"), GPT-3 puede preguntar autom√°ticamente al usuario para obtener aclaraciones antes de dar la respuesta final.

## ¬øPor qu√© no podemos pasar toda la KB a GPT-3?

Hoy en d√≠a, los LLM como GPT-3 tienen un tama√±o m√°ximo de prompt de aproximadamente 4k tokens (para el modelo [`text-davinci-003`](https://beta.openai.com/docs/models/gpt-3)), que es mucho pero no suficiente para alimentar toda la base de conocimientos en un solo prompt. Los LLM tienen un tama√±o m√°ximo de prompt por razones computacionales, ya que generar texto con ellos implica una serie de c√°lculos que aumentan r√°pidamente a medida que aumenta el tama√±o del prompt.

Los futuros LLM pueden no tener esta limitaci√≥n mientras conservan las capacidades de generaci√≥n de texto. Sin embargo, por ahora, necesitamos dise√±ar una soluci√≥n alrededor de ella.

## C√≥mo podr√≠a funcionar un chatbot con GPT-3

Entonces, la canalizaci√≥n del chatbot podr√≠a estar compuesta por dos pasos:

1. Primero, necesitamos seleccionar la intenci√≥n adecuada para la pregunta del usuario, es decir, necesitamos recuperar el documento correcto de nuestra base de conocimientos.
2. Luego, una vez que tenemos el documento correcto, podemos aprovechar GPT-3 para generar una respuesta apropiada para el usuario. Al hacerlo, necesitaremos crear un buen prompt.

El primer paso se resuelve esencialmente mediante [b√∫squeda sem√°ntica](https://es.wikipedia.org/wiki/B%C3%BAsqueda_sem%C3%A1ntica). Podemos usar modelos pre-entrenados de la biblioteca [`sentence-transformers`](https://www.sbert.net/examples/applications/semantic-search/README.html) y asignar f√°cilmente una puntuaci√≥n a cada documento. El documento con la puntuaci√≥n m√°s alta es el que se utilizar√° para generar la respuesta del chatbot.

<div style={{ textAlign: "left" }}>
  <Image
    src="/docs/assets/basic_applications/chatbot_from_kb_gpt3_organized.webp"
    width={2960}
    height={1668}
    style={{ width: "700px", margin: "auto" }}
  />

  <p style={{ color: "gray", fontSize: "12px", fontStyle: "italic" }}>
    C√≥mo podr√≠a funcionar un chatbot aprovechando GPT-3. GPT-3 podr√≠a utilizarse
    para generar una respuesta adecuada aprovechando la informaci√≥n de
    documentos de la base de conocimientos. Image by the author.
  </p>
</div>

## Generaci√≥n de respuestas con GPT-3

Una vez que tenemos el documento correcto, necesitaremos crear una buena indicaci√≥n (prompt) para ser usada con GPT-3 para generar la respuesta. En los siguientes experimentos, siempre usaremos el modelo `text-davinci-003` con una temperatura de `0.7`.

Para crear la indicaci√≥n (prompt), experimentaremos con:

- [**Role-prompting**](https://learnprompting.org/docs/basics/roles): una t√©cnica heur√≠stica que asigna un rol espec√≠fico a la IA.
- **Informaci√≥n relevante de la base de conocimientos (KB)**, es decir, el documento recuperado en el paso de b√∫squeda sem√°ntica.
- **Los √∫ltimos mensajes intercambiados entre el usuario y el chatbot**. Estos son √∫tiles para mensajes enviados por el usuario donde el contexto completo no est√° especificado. Veremos un ejemplo de esto m√°s adelante. Echa un vistazo a [este ejemplo](https://learnprompting.org/docs/applied_prompting/build_chatgpt) para ver c√≥mo gestionar conversaciones con GPT-3.
- Por √∫ltimo, **la pregunta del usuario**.

Comencemos nuestra indicaci√≥n usando la t√©cnica de

<span style={{ backgroundColor: "#FFF2CC" }}>role-prompting</span>.

<pre>
  <span style={{ backgroundColor: "#FFF2CC" }}>
    Como un chatbot avanzado llamado Skippy, tu objetivo principal es ayudar a
    los usuarios lo mejor que puedas.
  </span>
  <br />
</pre>

Comencemos nuestro prompt usando la t√©cnica de

<span style={{ backgroundColor: "#FFF2CC" }}>solicitud de roles</span>.

<pre>
  <span style={{ backgroundColor: "#FFF2CC" }}>
    Como un chatbot avanzado llamado Skippy, tu objetivo principal es ayudar a
    los usuarios de la mejor manera posible.
  </span>
  <br />
</pre>

Luego, supongamos que el paso de b√∫squeda sem√°ntica extrae el siguiente documento de nuestra base de conocimientos. Todos los documentos describen c√≥mo funciona el producto VideoGram, que es un producto imaginario similar a Instagram, pero solo para videos.

<div style={{ textAlign: "left" }}>
  <Image
    src="/docs/assets/basic_applications/chatbot_from_kb_login.webp"
    width={2956}
    height={1664}
    style={{ width: "700px", margin: "auto" }}
  />

  <p style={{ color: "gray", fontSize: "12px", fontStyle: "italic" }}>
    Un documento que explica c√≥mo funciona el inicio de sesi√≥n en VideoGram.
    Imagen del autor.
  </p>
</div>
Podemos agregar
<span style={{ backgroundColor: "#FFF2CC" }}>su contenido</span>
dentro del prompt de esta manera.

<pre>
  Como un chatbot avanzado llamado Skippy, tu objetivo principal es ayudar a los
  usuarios de la mejor manera posible.
  <br />
  <br />
  <span style={{ backgroundColor: "#FFF2CC" }}>
    INICIO DE CONTEXTO
    <br />
    Iniciar sesi√≥n en VideoGram desde el sitio web
    <br />
    1. Abre tu navegador web y ve al sitio web de VideoGram.
    <br />
    2. Haz clic en el bot√≥n "Iniciar sesi√≥n" ubicado en la esquina superior
    derecha de la p√°gina.
    <br />
    3. En la p√°gina de inicio de sesi√≥n, ingresa tu nombre de usuario y
    contrase√±a de VideoGram.
    <br />
    4. Una vez que hayas ingresado tus credenciales, haz clic en el bot√≥n
    "Iniciar sesi√≥n".
    <br />
    5. Ahora deber√≠as haber iniciado sesi√≥n en tu cuenta de VideoGram.
    <br />
    <br />
    Iniciar sesi√≥n en VideoGram desde la aplicaci√≥n m√≥vil
    <br />
    1. Abre la aplicaci√≥n de VideoGram en tu dispositivo m√≥vil.
    <br />
    2. En la p√°gina principal, toca el bot√≥n "Iniciar sesi√≥n" ubicado en la esquina
    inferior derecha. 3. En la p√°gina de inicio de sesi√≥n, ingresa tu nombre de usuario
    y contrase√±a de VideoGram.
    <br />
    4. Una vez que hayas ingresado tus credenciales, toca el bot√≥n "Iniciar sesi√≥n".
    <br />
    5. Ahora deber√≠as haber iniciado sesi√≥n en tu cuenta de VideoGram.
    <br />
    FIN DE CONTEXTO
    <br />
  </span>
</pre>

Por √∫ltimo, necesitamos agregar

<span style={{ backgroundColor: "#FFF2CC" }}>
  la conversaci√≥n y la pregunta del usuario
</span>
al final del prompt, como en el siguiente ejemplo.

<pre>
  Como un chatbot avanzado llamado Skippy, tu objetivo principal es ayudar a los
  usuarios de la mejor manera posible.
  <br />
  <br />
  INICIO DE CONTEXTO
  <br />
  Iniciar sesi√≥n en VideoGram desde el sitio web
  <br />
  1. Abre tu navegador web y ve al sitio web de VideoGram.
  <br />
  2. Haz clic en el bot√≥n "Iniciar sesi√≥n" ubicado en la esquina superior derecha
  de la p√°gina.
  <br />
  3. En la p√°gina de inicio de sesi√≥n, ingresa tu nombre de usuario y contrase√±a
  de VideoGram.
  <br />
  4. Una vez que hayas ingresado tus credenciales, haz clic en el bot√≥n "Iniciar
  sesi√≥n".
  <br />
  5. Ahora deber√≠as haber iniciado sesi√≥n en tu cuenta de VideoGram.
  <br />
  <br />
  Iniciar sesi√≥n en VideoGram desde la aplicaci√≥n m√≥vil
  <br />
  1. Abre la aplicaci√≥n de VideoGram en tu dispositivo m√≥vil.
  <br />
  2. En la p√°gina principal, toca el bot√≥n "Iniciar sesi√≥n" ubicado en la
  esquina inferior derecha. 3. En la p√°gina de inicio de sesi√≥n, ingresa tu
  nombre de usuario y contrase√±a de VideoGram.
  <br />
  4. Una vez que hayas ingresado tus credenciales, toca el bot√≥n "Iniciar
  sesi√≥n".
  <br />
  5. Ahora deber√≠as haber iniciado sesi√≥n en tu cuenta de VideoGram.
  <br />
  FIN DE CONTEXTO
  <br />
  <br />
  <span style={{ backgroundColor: "#FFF2CC" }}>
    SKIPPY: ¬°Hola, soy Skippy! ¬øEn qu√© puedo ayudarte?
    <br />
    USUARIO: No puedo encontrar el bot√≥n de inicio de sesi√≥n.
    <br />
    SKIPPY:
  </span>
  <br />
</pre>

Pasando este prompt a GPT-3, obtuve la siguiente respuesta generada:

<pre>
  <span style={{ backgroundColor: "#D2F4D3" }}>
    No hay problema! En el sitio web, el bot√≥n de inicio de sesi√≥n se encuentra
    en la esquina superior derecha de la p√°gina. En la aplicaci√≥n m√≥vil, el
    bot√≥n de inicio de sesi√≥n se encuentra en la esquina inferior derecha.
    H√°gamelo saber si necesita m√°s ayuda!
  </span>
</pre>

Observa c√≥mo la informaci√≥n en la respuesta generada proviene del documento de base de conocimiento.

## Desambiguaci√≥n de preguntas con GPT-3

Intentemos con una frase del usuario m√°s ambigua, como

<span style={{ backgroundColor: "#FFF2CC" }}>‚Äúno puedo iniciar sesi√≥n‚Äù</span>. Aqu√≠
est√° el prompt completo:

<pre>
  Como un chatbot avanzado llamado Skippy, tu objetivo principal es ayudar a los
  usuarios lo mejor que puedas.
  <br />
  <br />
  COMIENZA EL CONTEXTO
  <br />
  Iniciar sesi√≥n en VideoGram desde el sitio web:
  <br />
  1. Abre tu navegador web y ve al sitio web de VideoGram.
  <br />
  2. Haz clic en el bot√≥n "Iniciar sesi√≥n" ubicado en la esquina superior derecha
  de la p√°gina.
  <br />
  3. En la p√°gina de inicio de sesi√≥n, ingresa tu nombre de usuario y contrase√±a
  de VideoGram.
  <br />
  4. Una vez que hayas ingresado tus credenciales, haz clic en el bot√≥n "Iniciar
  sesi√≥n".
  <br />
  5. Ahora deber√≠as haber iniciado sesi√≥n en tu cuenta de VideoGram.
  <br />
  <br />
  Iniciar sesi√≥n en VideoGram desde la aplicaci√≥n m√≥vil:
  <br />
  1. Abre la aplicaci√≥n VideoGram en tu dispositivo m√≥vil.
  <br />
  2. En la p√°gina principal, toca el bot√≥n "Iniciar sesi√≥n" ubicado en la
  esquina inferior derecha.
  <br />
  3. En la p√°gina de inicio de sesi√≥n, ingresa tu nombre de usuario y contrase√±a
  de VideoGram.
  <br />
  4. Una vez que hayas ingresado tus credenciales, toca el bot√≥n "Iniciar
  sesi√≥n".
  <br />
  5. Ahora deber√≠as haber iniciado sesi√≥n en tu cuenta de VideoGram.
  <br />
  TERMINA EL CONTEXTO
  <br />
  <br />
  SKIPPY: ¬°Hola, soy Skippy! ¬øC√≥mo puedo ayudarte?
  <br />
  USUARIO:
  <span style={{ backgroundColor: "#FFF2CC" }}>No puedo iniciar sesi√≥n</span>
  <br />
  SKIPPY:
  <br />
</pre>

GPT-3 intentar√° entender mejor cu√°l es el problema del usuario.

<pre>
  <span style={{ backgroundColor: "#D2F4D3" }}>
    Lo siento mucho. ¬øPuede decirme si est√° intentando iniciar sesi√≥n a trav√©s
    del sitio web de VideoGram o de la aplicaci√≥n m√≥vil?
  </span>
</pre>

A continuaci√≥n, aqu√≠ est√° c√≥mo contin√∫a la conversaci√≥n completa. El prompt completo est√° oculto para una mejor visibilidad.

<pre>
  USER: No puedo iniciar sesi√≥n.
  <br />
  SKIPPY: Lamento escuchar eso. ¬øPuede decirme si est√° intentando iniciar sesi√≥n
  a trav√©s del sitio web o de la aplicaci√≥n m√≥vil de VideoGram?
  <br />
  USER: Aplicaci√≥n m√≥vil
  <br />
  <span style={{ backgroundColor: "#D2F4D3" }}>
    SKIPPY: De acuerdo, no hay problema. Para iniciar sesi√≥n a trav√©s de la
    aplicaci√≥n m√≥vil, abra la aplicaci√≥n de VideoGram en su dispositivo m√≥vil.
    En la p√°gina principal, toque el bot√≥n "Iniciar sesi√≥n" ubicado en la
    esquina inferior derecha. En la p√°gina de inicio de sesi√≥n, ingrese su
    nombre de usuario y contrase√±a de VideoGram. Una vez que haya ingresado sus
    credenciales, toque el bot√≥n "Iniciar sesi√≥n". Ahora deber√≠a haber iniciado
    sesi√≥n en su cuenta de VideoGram. Por favor, av√≠seme si necesita alguna otra
    ayuda.
  </span>
  <br />
</pre>

GPT-3 puede manejar la disambiguaci√≥n, siempre que tenga la informaci√≥n contextual adecuada.

## Problemas al generar respuestas con GPT-3

Sin embargo, existe un problema en generar respuestas con GPT-3.

Si le preguntamos "¬øEs la aplicaci√≥n m√≥vil gratuita?" a GPT-3 pasando el documento de inicio de sesi√≥n como contexto, a menudo obtendr√≠amos una respuesta como "S√≠, la aplicaci√≥n m√≥vil de VideoGram es gratuita para descargar y usar", incluso si dicha informaci√≥n no est√° contenida en la informaci√≥n de contexto. ¬°Generar informaci√≥n falsa es muy malo para los chatbots de servicio al cliente!

GPT-3 rara vez genera informaci√≥n falsa cuando la respuesta a la pregunta del usuario se puede encontrar en el contexto. Como las preguntas de los usuarios a menudo son textos cortos y ambiguos, no podemos confiar en el paso de b√∫squeda sem√°ntica para siempre recuperar un documento correcto, y por lo tanto siempre somos vulnerables a la generaci√≥n de informaci√≥n falsa.

## conclusi√≥n

En conclusi√≥n, GPT-3 es muy √∫til para crear chatbots de conversaci√≥n y es capaz de responder a una serie de preguntas espec√≠ficas en funci√≥n de la informaci√≥n contextual insertada en la solicitud. Sin embargo, es dif√≠cil hacer que el modelo produzca respuestas utilizando solo la informaci√≥n del contexto, ya que el modelo tiende a alucinar (es decir, generar nueva informaci√≥n, potencialmente falsa). Generar informaci√≥n falsa es un problema de diferente gravedad seg√∫n el caso de uso.

Written by [Fabio Chiusano](https://www.linkedin.com/in/fabio-chiusano-b6a3b311b/).
