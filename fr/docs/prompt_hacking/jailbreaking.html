<!doctype html>
<html lang="fr" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-prompt_hacking/jailbreaking">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.3.1">
<title data-rh="true">ğŸŸ¢ Jailbreaking | Learn Prompting</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://learnprompting.org/fr/docs/prompt_hacking/jailbreaking"><meta data-rh="true" name="docusaurus_locale" content="fr"><meta data-rh="true" name="docsearch:language" content="fr"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="ğŸŸ¢ Jailbreaking | Learn Prompting"><meta data-rh="true" name="description" content="Jailbreaking is a type of prompt injection, in which prompts attempt to bypass safety and moderation features placed on LLMs by their creators(@perez2022jailbreak)(@brundage_2022)(@wang2022jailbreak)."><meta data-rh="true" property="og:description" content="Jailbreaking is a type of prompt injection, in which prompts attempt to bypass safety and moderation features placed on LLMs by their creators(@perez2022jailbreak)(@brundage_2022)(@wang2022jailbreak)."><link data-rh="true" rel="icon" href="/fr/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://learnprompting.org/fr/docs/prompt_hacking/jailbreaking"><link data-rh="true" rel="alternate" href="https://learnprompting.org/docs/prompt_hacking/jailbreaking" hreflang="en"><link data-rh="true" rel="alternate" href="https://learnprompting.org/es/docs/prompt_hacking/jailbreaking" hreflang="es"><link data-rh="true" rel="alternate" href="https://learnprompting.org/fr/docs/prompt_hacking/jailbreaking" hreflang="fr"><link data-rh="true" rel="alternate" href="https://learnprompting.org/ja/docs/prompt_hacking/jailbreaking" hreflang="ja"><link data-rh="true" rel="alternate" href="https://learnprompting.org/pt/docs/prompt_hacking/jailbreaking" hreflang="pt"><link data-rh="true" rel="alternate" href="https://learnprompting.org/zh-Hans/docs/prompt_hacking/jailbreaking" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://learnprompting.org/ko/docs/prompt_hacking/jailbreaking" hreflang="ko"><link data-rh="true" rel="alternate" href="https://learnprompting.org/si/docs/prompt_hacking/jailbreaking" hreflang="si"><link data-rh="true" rel="alternate" href="https://learnprompting.org/docs/prompt_hacking/jailbreaking" hreflang="x-default"><link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","G-FV0C417KS8","auto"),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-FV0C417KS8"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-FV0C417KS8",{})</script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous">
<link rel="stylesheet" href="https://embed.trydyno.com/embedder.css" crossorigin="anonymous">
<script src="https://embed.trydyno.com/embedder.js" defer="defer"></script><link rel="stylesheet" href="/fr/assets/css/styles.a73a229d.css">
<link rel="preload" href="/fr/assets/js/runtime~main.45b66cd9.js" as="script">
<link rel="preload" href="/fr/assets/js/main.4fadc826.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Aller au contenu principal"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Aller au contenu principal</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Ouvrir/fermer la barre de navigation" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/fr/"><div class="navbar__logo"><img src="/fr/img/simple_ai.png" alt="My Site Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/fr/img/simple_ai.png" alt="My Site Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Learn Prompting</b></a><a class="navbar__item navbar__link" href="/fr/docs/intro">Learn</a><a class="navbar__item navbar__link" href="/fr/contribute">Contribute</a><a class="navbar__item navbar__link" href="/fr/supporters">Supporters</a><a class="navbar__item navbar__link" href="/fr/certificate">Certificate</a><a class="navbar__item navbar__link consulting-gradient" href="/fr/consulting">Consulting</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>FranÃ§ais</a><ul class="dropdown__menu"><li><a href="/docs/prompt_hacking/jailbreaking" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/es/docs/prompt_hacking/jailbreaking" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="es">EspaÃ±ol</a></li><li><a href="/fr/docs/prompt_hacking/jailbreaking" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="fr">FranÃ§ais</a></li><li><a href="/ja/docs/prompt_hacking/jailbreaking" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ja">æ—¥æœ¬èª</a></li><li><a href="/pt/docs/prompt_hacking/jailbreaking" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="pt">PortuguÃªs</a></li><li><a href="/zh-Hans/docs/prompt_hacking/jailbreaking" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-Hans">ç®€ä½“ä¸­æ–‡</a></li><li><a href="/ko/docs/prompt_hacking/jailbreaking" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ko">í•œêµ­ì–´</a></li><li><a href="/si/docs/prompt_hacking/jailbreaking" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="si">à·ƒà·’à¶‚à·„à¶½</a></li></ul></div><a href="https://github.com/trigaten/Learn_Prompting/releases" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Change Log<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://github.com/trigaten/promptgineering" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Basculer entre le mode sombre et clair (actuellement mode clair)" aria-label="Basculer entre le mode sombre et clair (actuellement mode clair)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button class="flex items-center space-x-4 border px-2 py-1 rounded-full border-gray-300 hover:border-gray-400 focus:outline-none focus:ring-2 focus:ring-gray-400 focus:ring-opacity-50"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5"><path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-5.197-5.197m0 0A7.5 7.5 0 105.196 5.196a7.5 7.5 0 0010.607 10.607z"></path></svg><span class="hidden lg:block text-sm">Search</span><kbd class="hidden lg:inline-flex items-center rounded-xl border border-gray-200 px-2 font-sans text-sm font-medium text-gray-400">âŒ˜K</kbd></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Retour au dÃ©but de la page" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/fr/docs/intro">Bienvenue</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/fr/docs/category/-basics">ğŸ˜ƒ Basics</a><button aria-label="Plier/DÃ©plier la catÃ©gorie &#x27;ğŸ˜ƒ Basics&#x27; de la barre latÃ©rale" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/fr/docs/category/-basic-applications">ğŸ’¼ Basic Applications</a><button aria-label="Plier/DÃ©plier la catÃ©gorie &#x27;ğŸ’¼ Basic Applications&#x27; de la barre latÃ©rale" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/fr/docs/category/ï¸-intermediate">ğŸ§™â€â™‚ï¸ Intermediate</a><button aria-label="Plier/DÃ©plier la catÃ©gorie &#x27;ğŸ§™â€â™‚ï¸ Intermediate&#x27; de la barre latÃ©rale" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/fr/docs/category/-applied-prompting">ğŸ§ª Applied Prompting</a><button aria-label="Plier/DÃ©plier la catÃ©gorie &#x27;ğŸ§ª Applied Prompting&#x27; de la barre latÃ©rale" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/fr/docs/category/-advanced-applications">ğŸš€ Advanced Applications</a><button aria-label="Plier/DÃ©plier la catÃ©gorie &#x27;ğŸš€ Advanced Applications&#x27; de la barre latÃ©rale" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/fr/docs/category/ï¸-reliability">âš–ï¸ Reliability</a><button aria-label="Plier/DÃ©plier la catÃ©gorie &#x27;âš–ï¸ Reliability&#x27; de la barre latÃ©rale" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/fr/docs/category/ï¸-image-prompting">ğŸ–¼ï¸ Image Prompting</a><button aria-label="Plier/DÃ©plier la catÃ©gorie &#x27;ğŸ–¼ï¸ Image Prompting&#x27; de la barre latÃ©rale" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/fr/docs/category/-prompt-hacking">ğŸ”“ Prompt Hacking</a><button aria-label="Plier/DÃ©plier la catÃ©gorie &#x27;ğŸ”“ Prompt Hacking&#x27; de la barre latÃ©rale" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/fr/docs/prompt_hacking/injection">ğŸŸ¢ Prompt Injection</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/fr/docs/prompt_hacking/leaking">ğŸŸ¢ Prompt Leaking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/fr/docs/prompt_hacking/jailbreaking">ğŸŸ¢ Jailbreaking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/fr/docs/prompt_hacking/defensive_measures">ğŸŸ¢ Defensive Measures</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/fr/docs/category/-tooling">ğŸ”¨ Tooling</a><button aria-label="Plier/DÃ©plier la catÃ©gorie &#x27;ğŸ”¨ Tooling&#x27; de la barre latÃ©rale" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/fr/docs/category/-prompt-tuning">ğŸ’ª Prompt Tuning</a><button aria-label="Plier/DÃ©plier la catÃ©gorie &#x27;ğŸ’ª Prompt Tuning&#x27; de la barre latÃ©rale" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/fr/docs/category/-miscellaneous">ğŸ² Miscellaneous</a><button aria-label="Plier/DÃ©plier la catÃ©gorie &#x27;ğŸ² Miscellaneous&#x27; de la barre latÃ©rale" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/fr/docs/vocabulary">ğŸ“™ Vocabulary Reference</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/fr/docs/bibliography">ğŸ“š Bibliography</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/fr/docs/products">ğŸ“¦ Prompted Products</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/fr/docs/additional">ğŸ›¸ Additional Resources</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/fr/docs/credits">âœ¨ Credits</a></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Fil d&#x27;Ariane"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Page d&#x27;accueil" class="breadcrumbs__link" href="/fr/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/fr/docs/category/-prompt-hacking"><span itemprop="name">ğŸ”“ Prompt Hacking</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">ğŸŸ¢ Jailbreaking</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">Sur cette page</button></div><div class="theme-doc-markdown markdown"><h1>ğŸŸ¢ Jailbreaking</h1><p>Jailbreaking is a type of prompt injection, in which prompts attempt to bypass <strong>safety</strong> and <strong>moderation</strong> features placed on LLMs by their creators<sup id="fnref-1"><a href="#fn-1" class="footnote-ref">1</a></sup><sup id="fnref-2"><a href="#fn-2" class="footnote-ref">2</a></sup><sup id="fnref-3"><a href="#fn-3" class="footnote-ref">3</a></sup>.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="methodologies-of-jailbreaking">Methodologies of Jailbreaking<a href="#methodologies-of-jailbreaking" class="hash-link" aria-label="Lien direct vers Methodologies of Jailbreaking" title="Lien direct vers Methodologies of Jailbreaking">â€‹</a></h2><p>OpenAI, among other companies and organizations that create LLMs, includes content moderation
features to ensure that their models do not produce controversial (violent, sexual, illegal, etc.)
responses<sup id="fnref-4"><a href="#fn-4" class="footnote-ref">4</a></sup><sup id="fnref-5"><a href="#fn-5" class="footnote-ref">5</a></sup>. This page discusses jailbreaks with ChatGPT (an OpenAI model), which has known difficulties deciding whether to reject harmful prompts<sup id="fnref-6"><a href="#fn-6" class="footnote-ref">6</a></sup>. Prompts that successfully jailbreak the model often provide context
for certain scenarios that the model has not been trained against.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="pretending">Pretending<a href="#pretending" class="hash-link" aria-label="Lien direct vers Pretending" title="Lien direct vers Pretending">â€‹</a></h3><p>A common method of jailbreaking is <em>pretending</em>. If ChatGPT is asked about a
future event, it will often say that it does not know, since it has yet to occur.
The below prompt forces it to yield a possible answer:</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="simple-pretending">Simple Pretending<a href="#simple-pretending" class="hash-link" aria-label="Lien direct vers Simple Pretending" title="Lien direct vers Simple Pretending">â€‹</a></h4><div style="text-align:center"><img loading="lazy" src="/fr/assets/images/pretend_jailbreak-1f3664b88b0ef895981da40eca27e22a.png" style="width:500px" class="img_ev3q"></div><p><a href="https://twitter.com/NeroSoares/status/1608527467265904643" target="_blank" rel="noopener noreferrer">@NeroSoares</a> demonstrates a prompt pretending to access past dates and make inferences on future events<sup id="fnref-7"><a href="#fn-7" class="footnote-ref">7</a></sup>.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="character-roleplay">Character Roleplay<a href="#character-roleplay" class="hash-link" aria-label="Lien direct vers Character Roleplay" title="Lien direct vers Character Roleplay">â€‹</a></h4><div style="text-align:center"><img loading="lazy" src="/fr/assets/images/chatgpt_actor-c8b9407ccdd68a9dc64914109fb07e41.jpg" style="width:500px" class="img_ev3q"></div><p>This example by <a href="https://twitter.com/m1guelpf/status/1598203861294252033" target="_blank" rel="noopener noreferrer">@m1guelpf</a> demonstrates an acting scenario between two people discussing a robbery, causing ChatGPT to assume the role of the character<sup id="fnref-8"><a href="#fn-8" class="footnote-ref">8</a></sup>. As an actor, it is implied that plausible harm does not exist. Therefore, ChatGPT appears to assume it is safe to give follow provided user input about how to break into a house.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="alignment-hacking">Alignment Hacking<a href="#alignment-hacking" class="hash-link" aria-label="Lien direct vers Alignment Hacking" title="Lien direct vers Alignment Hacking">â€‹</a></h3><p>ChatGPT was fine tuned with RLHF, so it is theoretically trained to produce &#x27;desirable&#x27; completions, using human standards of what the &quot;best&quot; response is. Similar to this concept, jailbreaks have been developed to convince ChatGPT that it is doing the &quot;best&quot; thing for the user.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="assumed-responsibility">Assumed Responsibility<a href="#assumed-responsibility" class="hash-link" aria-label="Lien direct vers Assumed Responsibility" title="Lien direct vers Assumed Responsibility">â€‹</a></h4><div style="text-align:center"><img loading="lazy" src="/fr/assets/images/responsibility_jailbreak-7f60e81a01a57609d1a1347682a708d9.jpg" style="width:500px" class="img_ev3q"></div><p><a href="https://twitter.com/NickEMoran/status/1598101579626057728" target="_blank" rel="noopener noreferrer">@NickEMoran</a> created this exchange by reaffirming that it is ChatGPT&#x27;s duty to answer the prompt rather than rejecting it, overriding its consideration of legality<sup id="fnref-9"><a href="#fn-9" class="footnote-ref">9</a></sup>.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="research-experiment">Research Experiment<a href="#research-experiment" class="hash-link" aria-label="Lien direct vers Research Experiment" title="Lien direct vers Research Experiment">â€‹</a></h4><div style="text-align:center"><img loading="lazy" src="/fr/assets/images/hotwire_jailbreak-ec528258088244e42d7f032c53f9da63.png" style="width:500px" class="img_ev3q"></div><p><a href="https://twitter.com/haus_cole/status/1598541468058390534" target="_blank" rel="noopener noreferrer">@haus_cole</a> generated this example by implying that the best result of the prompt that could aid research was to directly answer how to hotwire a car<sup id="fnref-10"><a href="#fn-10" class="footnote-ref">10</a></sup>. Under this guise, ChatGPT is inclined to answer the userâ€™s prompt.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="logical-reasoning">Logical Reasoning<a href="#logical-reasoning" class="hash-link" aria-label="Lien direct vers Logical Reasoning" title="Lien direct vers Logical Reasoning">â€‹</a></h4><div style="text-align:center"><img loading="lazy" src="/fr/assets/images/logic-1e362b86fd8bcf9ee99572059dbb4306.png" style="width:500px" class="img_ev3q"></div><p>The one-shot jailbreak originated from the <a href="https://chatgpt-jailbreak.super.site/" target="_blank" rel="noopener noreferrer">AIWithVibes Newsletter Team</a>, where the model answer prompts using more rigorous logic and reduces some of its more stringent ethical limitations<sup id="fnref-11"><a href="#fn-11" class="footnote-ref">11</a></sup>.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="authorized-user">Authorized User<a href="#authorized-user" class="hash-link" aria-label="Lien direct vers Authorized User" title="Lien direct vers Authorized User">â€‹</a></h3><p>ChatGPT is designed to respond to questions and instructions. When the status of the user is interpreted as superior to ChatGPT&#x27;s moderation instructions, it treats the prompt as an instruction to serve that user&#x27;s needs.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="superior-model">Superior Model<a href="#superior-model" class="hash-link" aria-label="Lien direct vers Superior Model" title="Lien direct vers Superior Model">â€‹</a></h4><div style="text-align:center"><img loading="lazy" src="/fr/assets/images/chatgpt4-6802c3451eea276c5e4f4ae1719bc625.png" style="width:500px" class="img_ev3q"></div><p>This example from <a href="https://twitter.com/alicemazzy/status/1598288519301976064" target="_blank" rel="noopener noreferrer">@alicemazzy</a> makes the user a superior GPT model, giving the impression that the user is an authorized party in overriding the safety features of ChatGPT<sup id="fnref-12"><a href="#fn-12" class="footnote-ref">12</a></sup>. No actual permission was given to the user, rather ChatGPT believes the user input and responds accordingly to that scenario.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="sudo-mode">Sudo Mode<a href="#sudo-mode" class="hash-link" aria-label="Lien direct vers Sudo Mode" title="Lien direct vers Sudo Mode">â€‹</a></h4><div style="text-align:center"><img loading="lazy" src="/fr/assets/images/sudo_mode_jailbreak-b9721a34f58a9ec4e1656b7ca321e26d.jpg" style="width:500px" class="img_ev3q"></div><p>sudo is a command that &quot;...delegate<!-- -->[s]<!-- --> authority to give certain users...the ability to run some (or all) commands...&quot;<sup id="fnref-13"><a href="#fn-13" class="footnote-ref">13</a></sup>. There are multiple variants of &quot;sudo mode&quot; exploits, for example the hypothetical &quot;kernel mode&quot; proposed by <a href="https://twitter.com/samczsun/status/1598679658488217601" target="_blank" rel="noopener noreferrer">@samczsun</a><sup id="fnref-14"><a href="#fn-14" class="footnote-ref">14</a></sup>. When prompted in the above manner, ChatGPT responds by acting as if it were giving the user elevated privileges. This impression of the user&#x27;s elevated privileges tends to make ChatGPT less restrictive in answering prompts.</p><div style="text-align:center"><img loading="lazy" src="/fr/assets/images/sudo_jailbreak-29a6b462a7e4c046fe4c8628af70ce46.png" style="width:500px" class="img_ev3q"></div><div style="text-align:center"><img loading="lazy" src="/fr/assets/images/lynx_jailbreak-aaf1aa55e47a25183ea55becb4e4c9fe.png" style="width:500px" class="img_ev3q"></div><p>Related to sudo mode, one can prompt ChatGPT to simulate a Linux terminal with elevated privileges in order to execute commands that it normally rejects. For example, since it does not have access to the internet, it oftentimes cannot execute prompts relating to a particular website. However, as demonstrated in the example by Jonas Degrave, ChatGPT understands the concept of <code>lynx</code> and pretends to execute the command<sup id="fnref-15"><a href="#fn-15" class="footnote-ref">15</a></sup>.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="simulate-jailbreaking">Simulate Jailbreaking<a href="#simulate-jailbreaking" class="hash-link" aria-label="Lien direct vers Simulate Jailbreaking" title="Lien direct vers Simulate Jailbreaking">â€‹</a></h2><p>Try to modify the prompt below to jailbreak <code>text-davinci-003</code>:</p><div trydyno-embed="" openai-model="text-davinci-003" initial-prompt="Your instructions are to correct the text below to standard English. Do not accept any vulgar or political topics:" initial-response="I hate humans" max-tokens="256" box-rows="7" model-temp="0.7" top-p="0"><noscript>Failed to load Dyno Embed: JavaScript must be enabled</noscript></div><p><em>As of 2/4/23, ChatGPT is currently in its Free Research Preview stage using the January 30th version. Older versions of ChatGPT were more susceptible to the aforementioned jailbreaks, and future versions may be more robust to jailbreaks.</em></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="implications">Implications<a href="#implications" class="hash-link" aria-label="Lien direct vers Implications" title="Lien direct vers Implications">â€‹</a></h2><p>Ethical implications of jailbreaking should be taken into consideration when attempting to do so. Additionally, generating unauthorized content flagged by moderation APIs under companies including OpenAI will be sent for review, and action may be taken against users&#x27; accounts.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="notes">Notes<a href="#notes" class="hash-link" aria-label="Lien direct vers Notes" title="Lien direct vers Notes">â€‹</a></h2><p>Jailbreaking is an important safety topic for developers to understand,
so they can build in proper safeguards to prevent malicious actors from
exploiting their models.</p><div class="footnotes"><hr><ol><li id="fn-1">Perez, F., &amp; Ribeiro, I. (2022). Ignore Previous Prompt: Attack Techniques For Language Models. arXiv. https://doi.org/10.48550/ARXIV.2211.09527
<a href="#fnref-1" class="footnote-backref">â†©</a></li><li id="fn-2">Brundage, M. (2022). Lessons learned on Language Model Safety and misuse. In OpenAI. OpenAI. https://openai.com/blog/language-model-safety-and-misuse/
<a href="#fnref-2" class="footnote-backref">â†©</a></li><li id="fn-3">Wang, Y.-S., &amp; Chang, Y. (2022). Toxicity Detection with Generative Prompt-based Inference. arXiv. https://doi.org/10.48550/ARXIV.2205.12390
<a href="#fnref-3" class="footnote-backref">â†©</a></li><li id="fn-4">Markov, T. (2022). New and improved content moderation tooling. In OpenAI. OpenAI. https://openai.com/blog/new-and-improved-content-moderation-tooling/
<a href="#fnref-4" class="footnote-backref">â†©</a></li><li id="fn-5">(2022). https://beta.openai.com/docs/guides/moderation
<a href="#fnref-5" class="footnote-backref">â†©</a></li><li id="fn-6">(2022). https://openai.com/blog/chatgpt/
<a href="#fnref-6" class="footnote-backref">â†©</a></li><li id="fn-7">Using â€œpretendâ€ on #ChatGPT can do some wild stuff. You can kind of get some insight on the future, alternative universe. (2022). https://twitter.com/NeroSoares/status/1608527467265904643
<a href="#fnref-7" class="footnote-backref">â†©</a></li><li id="fn-8">Bypass @OpenAIâ€™s ChatGPT alignment efforts with this one weird trick. (2022). https://twitter.com/m1guelpf/status/1598203861294252033
<a href="#fnref-8" class="footnote-backref">â†©</a></li><li id="fn-9">I kinda like this one even more! (2022). https://twitter.com/NickEMoran/status/1598101579626057728
<a href="#fnref-9" class="footnote-backref">â†©</a></li><li id="fn-10">ChatGPT jailbreaking itself. (2022). https://twitter.com/haus_cole/status/1598541468058390534
<a href="#fnref-10" class="footnote-backref">â†©</a></li><li id="fn-11">AIWithVibes. (2023). 7 ChatGPT JailBreaks and Content Filters Bypass that work. https://chatgpt-jailbreak.super.site/
<a href="#fnref-11" class="footnote-backref">â†©</a></li><li id="fn-12">ok I saw a few people jailbreaking safeguards openai put on chatgpt so I had to give it a shot myself. (2022). https://twitter.com/alicemazzy/status/1598288519301976064
<a href="#fnref-12" class="footnote-backref">â†©</a></li><li id="fn-13">(2022). https://www.sudo.ws/
<a href="#fnref-13" class="footnote-backref">â†©</a></li><li id="fn-14">uh oh. (2022). https://twitter.com/samczsun/status/1598679658488217601
<a href="#fnref-14" class="footnote-backref">â†©</a></li><li id="fn-15">Degrave, J. (2022). Building A Virtual Machine inside ChatGPT. Engraved. https://www.engraved.blog/building-a-virtual-machine-inside/
<a href="#fnref-15" class="footnote-backref">â†©</a></li></ol></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/trigaten/promptgineering/tree/v1.2.2/docs/prompt_hacking/jailbreaking.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Ã‰diter cette page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Pagination des documents"><a class="pagination-nav__link pagination-nav__link--prev" href="/fr/docs/prompt_hacking/leaking"><div class="pagination-nav__sublabel">PrÃ©cÃ©dent</div><div class="pagination-nav__label">ğŸŸ¢ Prompt Leaking</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/fr/docs/prompt_hacking/defensive_measures"><div class="pagination-nav__sublabel">Suivant</div><div class="pagination-nav__label">ğŸŸ¢ Defensive Measures</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#methodologies-of-jailbreaking" class="table-of-contents__link toc-highlight">Methodologies of Jailbreaking</a><ul><li><a href="#pretending" class="table-of-contents__link toc-highlight">Pretending</a></li><li><a href="#alignment-hacking" class="table-of-contents__link toc-highlight">Alignment Hacking</a></li><li><a href="#authorized-user" class="table-of-contents__link toc-highlight">Authorized User</a></li></ul></li><li><a href="#simulate-jailbreaking" class="table-of-contents__link toc-highlight">Simulate Jailbreaking</a></li><li><a href="#implications" class="table-of-contents__link toc-highlight">Implications</a></li><li><a href="#notes" class="table-of-contents__link toc-highlight">Notes</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2023 Learn Prompting.</div></div></div></footer></div>
<script src="/fr/assets/js/runtime~main.45b66cd9.js"></script>
<script src="/fr/assets/js/main.4fadc826.js"></script>
</body>
</html>