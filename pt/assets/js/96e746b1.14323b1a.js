"use strict";(self.webpackChunkpromptgineering=self.webpackChunkpromptgineering||[]).push([[6949],{3905:(e,r,t)=>{t.d(r,{Zo:()=>c,kt:()=>f});var a=t(7294);function n(e,r,t){return r in e?Object.defineProperty(e,r,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[r]=t,e}function o(e,r){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);r&&(a=a.filter((function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable}))),t.push.apply(t,a)}return t}function s(e){for(var r=1;r<arguments.length;r++){var t=null!=arguments[r]?arguments[r]:{};r%2?o(Object(t),!0).forEach((function(r){n(e,r,t[r])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(t,r))}))}return e}function i(e,r){if(null==e)return{};var t,a,n=function(e,r){if(null==e)return{};var t,a,n={},o=Object.keys(e);for(a=0;a<o.length;a++)t=o[a],r.indexOf(t)>=0||(n[t]=e[t]);return n}(e,r);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)t=o[a],r.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(n[t]=e[t])}return n}var p=a.createContext({}),m=function(e){var r=a.useContext(p),t=r;return e&&(t="function"==typeof e?e(r):s(s({},r),e)),t},c=function(e){var r=m(e.components);return a.createElement(p.Provider,{value:r},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var r=e.children;return a.createElement(a.Fragment,{},r)}},l=a.forwardRef((function(e,r){var t=e.components,n=e.mdxType,o=e.originalType,p=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),u=m(t),l=n,f=u["".concat(p,".").concat(l)]||u[l]||d[l]||o;return t?a.createElement(f,s(s({ref:r},c),{},{components:t})):a.createElement(f,s({ref:r},c))}));function f(e,r){var t=arguments,n=r&&r.mdxType;if("string"==typeof e||n){var o=t.length,s=new Array(o);s[0]=l;var i={};for(var p in r)hasOwnProperty.call(r,p)&&(i[p]=r[p]);i.originalType=e,i[u]="string"==typeof e?e:n,s[1]=i;for(var m=2;m<o;m++)s[m]=t[m];return a.createElement.apply(null,s)}return a.createElement.apply(null,t)}l.displayName="MDXCreateElement"},2878:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>o,metadata:()=>i,toc:()=>m});var a=t(7462),n=(t(7294),t(3905));const o={sidebar_position:0},s="\ud83d\udfe2 Vis\xe3o Geral",i={unversionedId:"prompt_hacking/defensive_measures/overview",id:"prompt_hacking/defensive_measures/overview",title:"\ud83d\udfe2 Vis\xe3o Geral",description:"Prevenir a inje\xe7\xe3o de prompt pode ser extremamente dif\xedcil, e existem poucas defesas robustas contra isso (@crothers2022machine) (@goodside2021gpt). No entanto, existem algumas solu\xe7\xf5es de senso comum. Por exemplo, se sua aplica\xe7\xe3o n\xe3o precisa gerar texto livre, n\xe3o permita esse tipo de sa\xedda. Existem muitas maneiras diferentes de defender um prompt. Vamos discutir algumas das mais comuns aqui.",source:"@site/i18n/pt/docusaurus-plugin-content-docs/current/prompt_hacking/defensive_measures/overview.md",sourceDirName:"prompt_hacking/defensive_measures",slug:"/prompt_hacking/defensive_measures/overview",permalink:"/pt/docs/prompt_hacking/defensive_measures/overview",draft:!1,editUrl:"https://github.com/trigaten/promptgineering/tree/v1.2.3/docs/prompt_hacking/defensive_measures/overview.md",tags:[],version:"current",sidebarPosition:0,frontMatter:{sidebar_position:0},sidebar:"tutorialSidebar",previous:{title:"\ud83d\udfe2 Defensive Measures",permalink:"/pt/docs/category/-defensive-measures"},next:{title:"\ud83d\udfe2 Filtragem",permalink:"/pt/docs/prompt_hacking/defensive_measures/filtering"}},p={},m=[],c={toc:m},u="wrapper";function d(e){let{components:r,...t}=e;return(0,n.kt)(u,(0,a.Z)({},c,t,{components:r,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"-vis\xe3o-geral"},"\ud83d\udfe2 Vis\xe3o Geral"),(0,n.kt)("p",null,"Prevenir a inje\xe7\xe3o de prompt pode ser extremamente dif\xedcil, e existem poucas defesas robustas contra isso",(0,n.kt)("sup",{parentName:"p",id:"fnref-1"},(0,n.kt)("a",{parentName:"sup",href:"#fn-1",className:"footnote-ref"},"1")),"",(0,n.kt)("sup",{parentName:"p",id:"fnref-2"},(0,n.kt)("a",{parentName:"sup",href:"#fn-2",className:"footnote-ref"},"2")),". No entanto, existem algumas solu\xe7\xf5es de senso comum. Por exemplo, se sua aplica\xe7\xe3o n\xe3o precisa gerar texto livre, n\xe3o permita esse tipo de sa\xedda. Existem muitas maneiras diferentes de defender um prompt. Vamos discutir algumas das mais comuns aqui."),(0,n.kt)("p",null,"Este cap\xedtulo aborda estrat\xe9gias adicionais de senso comum, como filtrar palavras. Ele tamb\xe9m abrange estrat\xe9gias de melhoria do prompt (defesa por instru\xe7\xe3o, p\xf3s-promp\xe7\xe3o, diferentes maneiras de envolver a entrada do usu\xe1rio e marca\xe7\xe3o XML). Por fim, discutimos o uso de um LLM para avaliar sa\xeddas e algumas abordagens mais espec\xedficas do modelo"),(0,n.kt)("div",{className:"footnotes"},(0,n.kt)("hr",{parentName:"div"}),(0,n.kt)("ol",{parentName:"div"},(0,n.kt)("li",{parentName:"ol",id:"fn-1"},"Crothers, E., Japkowicz, N., & Viktor, H. (2022). Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods.\n",(0,n.kt)("a",{parentName:"li",href:"#fnref-1",className:"footnote-backref"},"\u21a9")),(0,n.kt)("li",{parentName:"ol",id:"fn-2"},"Goodside, R. (2022). GPT-3 Prompt Injection Defenses. https://twitter.com/goodside/status/1578278974526222336?s=20&t=3UMZB7ntYhwAk3QLpKMAbw\n",(0,n.kt)("a",{parentName:"li",href:"#fnref-2",className:"footnote-backref"},"\u21a9")))))}d.isMDXComponent=!0}}]);