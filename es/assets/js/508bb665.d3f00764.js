"use strict";(self.webpackChunkpromptgineering=self.webpackChunkpromptgineering||[]).push([[9207],{3905:(e,a,t)=>{t.d(a,{Zo:()=>u,kt:()=>h});var n=t(67294);function r(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function o(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function i(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?o(Object(t),!0).forEach((function(a){r(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function s(e,a){if(null==e)return{};var t,n,r=function(e,a){if(null==e)return{};var t,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)t=o[n],a.indexOf(t)>=0||(r[t]=e[t]);return r}(e,a);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)t=o[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var l=n.createContext({}),p=function(e){var a=n.useContext(l),t=a;return e&&(t="function"==typeof e?e(a):i(i({},a),e)),t},u=function(e){var a=p(e.components);return n.createElement(l.Provider,{value:a},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},m=n.forwardRef((function(e,a){var t=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),c=p(t),m=r,h=c["".concat(l,".").concat(m)]||c[m]||d[m]||o;return t?n.createElement(h,i(i({ref:a},u),{},{components:t})):n.createElement(h,i({ref:a},u))}));function h(e,a){var t=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var o=t.length,i=new Array(o);i[0]=m;var s={};for(var l in a)hasOwnProperty.call(a,l)&&(s[l]=a[l]);s.originalType=e,s[c]="string"==typeof e?e:r,i[1]=s;for(var p=2;p<o;p++)i[p]=t[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,t)}m.displayName="MDXCreateElement"},76176:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>d,contentTitle:()=>u,default:()=>b,frontMatter:()=>p,metadata:()=>c,toc:()=>m});var n=t(87462),r=(t(67294),t(3905));const o=t.p+"assets/images/skippy_chatbot-01e93d7bda29d973a0663fc8f9eea57b.png",i=t.p+"assets/images/skippy_chatbot_header-378e21014fb7ee1923ce415b4475290b.png",s=t.p+"assets/images/therapy_chatbot-5c8c653e12e16fc816883ff38f27e9b2.gif",l=t.p+"assets/images/chatgpt_ui_diagram-87b55966a74fe72526d9e2c4b86c6650.png",p={sidebar_position:4},u="\ud83d\udfe2 ChatGPT a partir de GPT-3",c={unversionedId:"applied_prompting/build_chatgpt",id:"applied_prompting/build_chatgpt",title:"\ud83d\udfe2 ChatGPT a partir de GPT-3",description:"Introducci\xf3n",source:"@site/i18n/es/docusaurus-plugin-content-docs/current/applied_prompting/build_chatgpt.md",sourceDirName:"applied_prompting",slug:"/applied_prompting/build_chatgpt",permalink:"/es/docs/applied_prompting/build_chatgpt",draft:!1,editUrl:"https://github.com/trigaten/promptgineering/tree/v1.2.2/docs/applied_prompting/build_chatgpt.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"\ud83d\udfe2 preguntas de discusi\xf3n",permalink:"/es/docs/applied_prompting/short_response"},next:{title:"\ud83d\udfe2 Chatbot + Base de Conocimiento",permalink:"/es/docs/applied_prompting/build_chatbot_from_kb"}},d={},m=[{value:"Introducci\xf3n",id:"introducci\xf3n",level:2},{value:"Motivaci\xf3n",id:"motivaci\xf3n",level:2},{value:"El prompt",id:"el-prompt",level:2},{value:"Memorizaci\xf3n",id:"memorizaci\xf3n",level:3},{value:"Algunos ejemplos",id:"algunos-ejemplos",level:3},{value:"Chatbot de terapia que pregunta sobre tu d\xeda",id:"chatbot-de-terapia-que-pregunta-sobre-tu-d\xeda",level:4},{value:"Habla con tu yo m\xe1s joven utilizando antiguas entradas de diario",id:"habla-con-tu-yo-m\xe1s-joven-utilizando-antiguas-entradas-de-diario",level:4},{value:"Implementaci\xf3n",id:"implementaci\xf3n",level:2}],h={toc:m},g="wrapper";function b(e){let{components:a,...t}=e;return(0,r.kt)(g,(0,n.Z)({},h,t,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"-chatgpt-a-partir-de-gpt-3"},"\ud83d\udfe2 ChatGPT a partir de GPT-3"),(0,r.kt)("div",{style:{textAlign:"left"}},(0,r.kt)("img",{src:i,style:{width:"700px"}})),(0,r.kt)("h2",{id:"introducci\xf3n"},"Introducci\xf3n"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://chat.openai.com/chat"},"ChatGPT")," ha explotado en el \xfaltimo mes, ganando un mill\xf3n de usuarios en solo una semana. Sorprendentemente, el modelo subyacente, GPT-3, debut\xf3 en 2020 y se lanz\xf3 para acceso p\xfablico hace m\xe1s de un a\xf1o.   "),(0,r.kt)("p",null,"Para aquellos que no lo saben, ChatGPT es un nuevo modelo de lenguaje de OpenAI que fue ajustado a partir de GPT-3 para ser optimizado para la conversaci\xf3n",(0,r.kt)("sup",{parentName:"p",id:"fnref-1"},(0,r.kt)("a",{parentName:"sup",href:"#fn-1",className:"footnote-ref"},"1")),". Tiene una interfaz de chat f\xe1cil de usar, donde puedes ingresar una entrada y obtener una respuesta de un asistente de inteligencia artificial. \xc9chale un vistazo en ",(0,r.kt)("a",{parentName:"p",href:"https://chat.openai.com/chat"},"chat.openai.com"),"."),(0,r.kt)("p",null,"Si bien las primeras versiones de GPT-3 no eran tan avanzadas como la actual serie GPT-3.5, a\xfan eran impresionantes. Estos modelos han estado disponibles a trav\xe9s de una API y una interfaz de usuario web de ",(0,r.kt)("a",{href:"https://beta.openai.com/playground"},"playground")," que te permite ajustar ciertos hiperpar\xe1metros de configuraci\xf3n y probar promts. GPT-3 gan\xf3 una tracci\xf3n significativa, pero no se acerc\xf3 a la viralidad de ChatGPT. "),(0,r.kt)("p",null,"Lo que hace que ChatGPT sea tan exitoso en comparaci\xf3n con GPT-3 es su accesibilidad como un asistente de IA sencillo para la persona promedio, independientemente de su conocimiento de la ciencia de datos, los modelos de lenguaje o la IA."),(0,r.kt)("p",null,"En este art\xedculo, describo c\xf3mo se pueden implementar chatbots como ChatGPT utilizando un modelo de lenguaje grande como GPT-3."),(0,r.kt)("h2",{id:"motivaci\xf3n"},"Motivaci\xf3n"),(0,r.kt)("p",null,"Este art\xedculo se escribi\xf3 en parte debido a un tweet de ",(0,r.kt)("a",{href:"https://twitter.com/goodside"},"Riley Goodside"),", que se\xf1al\xf3 c\xf3mo podr\xeda haberse implementado ChatGPT."),(0,r.kt)("blockquote",{class:"twitter-tweet"},(0,r.kt)("p",{lang:"en",dir:"ltr"},"C\xf3mo crear tu propio ChatGPT usando GPT-3 (text-davinci-003) - donde puedes personalizar las reglas seg\xfan tus necesidades y acceder al chatbot resultante a trav\xe9s de una API. ",(0,r.kt)("a",{href:"https://t.co/9jHrs91VHW"},"pic.twitter.com/9jHrs91VHW")),"\u2014 Riley Goodside (@goodside) ",(0,r.kt)("a",{href:"https://twitter.com/goodside/status/1607487283782995968?ref_src=twsrc%5Etfw"},"26 de diciembre de 2022"))," ",(0,r.kt)("script",{async:!0,src:"https://platform.twitter.com/widgets.js",charset:"utf-8"}),(0,r.kt)("p",null,"Al igual que otros modelos de la serie GPT-3.5, ChatGPT fue entrenado utilizando ",(0,r.kt)("a",{parentName:"p",href:"https://huggingface.co/blog/rlhf"},"RLHF"),", pero gran parte de su efectividad proviene de utilizar un ",(0,r.kt)("strong",{parentName:"p"},"buen prompt"),"."),(0,r.kt)("h2",{id:"el-prompt"},"El prompt"),(0,r.kt)("div",{style:{textAlign:"left"}},(0,r.kt)("img",{src:o,style:{width:"700px"}}),(0,r.kt)("p",{style:{color:"gray",fontSize:"12px",fontStyle:"italic"}},"Prompt completo de Skippy del encabezado del art\xedculo")),(0,r.kt)("a",{href:"https://learnprompting.org/docs/basics/prompting"},"El prompting es el proceso de instruir a una IA para que haga algo.")," Como probablemente hayas visto en los ejemplos de ChatGPT en l\xednea, puedes pedirle que haga casi cualquier cosa. Los casos de uso comunes son resumir textos, escribir contenido basado en una descripci\xf3n o crear cosas como poemas, recetas y mucho m\xe1s.",(0,r.kt)("p",null),(0,r.kt)("p",null,"ChatGPT es tanto un modelo de lenguaje como una interfaz de usuario. La entrada de prompt que el usuario introduce en la interfaz se inserta en realidad en un prompt m\xe1s grande que contiene toda la conversaci\xf3n entre el usuario y ChatGPT. Esto permite que el modelo de lenguaje subyacente comprenda el contexto de la conversaci\xf3n y responda adecuadamente."),(0,r.kt)("div",{style:{textAlign:"left"}},(0,r.kt)("img",{src:l,style:{width:"600px"}}),(0,r.kt)("p",{style:{color:"gray",fontSize:"12px",fontStyle:"italic"}},"Ejemplo de inserci\xf3n de prompt de usuario antes de enviarlo al modelo")),(0,r.kt)("p",null,"El modelo de lenguaje completa el prompt determinando qu\xe9 palabras vienen a continuaci\xf3n en funci\xf3n de las probabilidades que aprendi\xf3 durante el pre-entrenamiento",(0,r.kt)("sup",{parentName:"p",id:"fnref-2"},(0,r.kt)("a",{parentName:"sup",href:"#fn-2",className:"footnote-ref"},"2")),"."),(0,r.kt)("p",null),(0,r.kt)("p",null,"GPT-3 es capaz de 'aprender' a partir de una instrucci\xf3n simple o unos pocos ejemplos en el prompt. Esto se llama aprendizaje con pocos ejemplos, o aprendizaje en contexto",(0,r.kt)("sup",{parentName:"p",id:"fnref-3"},(0,r.kt)("a",{parentName:"sup",href:"#fn-3",className:"footnote-ref"},"3")),". En el prompt del chatbot de arriba, creo un chatbot ficticio llamado Skippy y le pido que proporcione respuestas a los usuarios. GPT-3 se da cuenta del formato de ida y vuelta, ",(0,r.kt)("inlineCode",{parentName:"p"},"USER: {entrada del usuario}")," y ",(0,r.kt)("inlineCode",{parentName:"p"},"SKIPPY: {respuesta de Skippy}"),'. GPT-3 entiende que Skippy es un chatbot y que los intercambios anteriores son una conversaci\xf3n, por lo que cuando proporcionamos la siguiente entrada del usuario, "Skippy" responder\xe1.'),(0,r.kt)("h3",{id:"memorizaci\xf3n"},"Memorizaci\xf3n"),(0,r.kt)("p",null,"Los intercambios anteriores entre Skippy y el usuario se agregan al siguiente prompt. Cada vez que proporcionamos m\xe1s entrada del usuario y obtenemos m\xe1s salida del chatbot, el prompt se expande para incorporar este nuevo intercambio. As\xed es como los chatbots como Skippy y ChatGPT pueden ",(0,r.kt)("strong",{parentName:"p"},"recordar las entradas anteriores"),". Sin embargo, hay un l\xedmite en cuanto a cu\xe1nto puede recordar un chatbot de GPT-3."),(0,r.kt)("p",null,"Los prompts pueden llegar a ser muy largos despu\xe9s de varias interacciones, especialmente si estamos utilizando el chatbot para generar respuestas largas como publicaciones de blog. Los prompts enviados a GPT-3 se convierten en tokens, que son palabras individuales o partes de ellas. Existe un l\xedmite de ",(0,r.kt)("a",{href:"https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them"},"4097 tokens (aproximadamente 3000 palabras)")," para el prompt combinado y la respuesta generada para modelos GPT-3, incluyendo ChatGPT. "),(0,r.kt)("h3",{id:"algunos-ejemplos"},"Algunos ejemplos"),(0,r.kt)("p",null,"Hay muchos casos de uso diferentes para prompts de chatbot que almacenan conversaciones previas. ChatGPT est\xe1 destinado a ser un asistente general multiprop\xf3sito y, en mi experiencia, rara vez hace preguntas de seguimiento."),(0,r.kt)("h4",{id:"chatbot-de-terapia-que-pregunta-sobre-tu-d\xeda"},"Chatbot de terapia que pregunta sobre tu d\xeda"),(0,r.kt)("p",null,"Puede ser \xfatil tener un chatbot que haga preguntas y obtenga comentarios del usuario. A continuaci\xf3n se muestra un ejemplo de prompt de chatbot de terapia que har\xe1 preguntas y seguimientos para ayudar al usuario a reflexionar sobre su d\xeda."),(0,r.kt)("div",{style:{textAlign:"left"}},(0,r.kt)("img",{src:s,style:{width:"700px"}}),(0,r.kt)("p",{style:{color:"gray",fontSize:"12px",fontStyle:"italic"}},"Prompt de chatbot de terapia")),(0,r.kt)("h4",{id:"habla-con-tu-yo-m\xe1s-joven-utilizando-antiguas-entradas-de-diario"},"Habla con tu yo m\xe1s joven utilizando antiguas entradas de diario"),(0,r.kt)("a",{href:"https://twitter.com/michellehuang42"},"Michelle Huang")," us\xf3 GPT-3 para tener una conversaci\xf3n con su yo m\xe1s joven. El prompt utiliza algo de contexto, en este caso antiguas entradas de diario, combinado con un formato de ida y vuelta de chatbot. GPT-3 es capaz de imitar una personalidad basada en estas entradas.",(0,r.kt)("p",null),(0,r.kt)("blockquote",{class:"twitter-tweet"},(0,r.kt)("p",{lang:"en",dir:"ltr"},'i trained an ai chatbot on my childhood journal entries - so that i could engage in real-time dialogue with my "inner child"',(0,r.kt)("br",null),(0,r.kt)("br",null),"some reflections below:"),"\u2014 michelle huang (@michellehuang42) ",(0,r.kt)("a",{href:"https://twitter.com/michellehuang42/status/1597005489413713921?ref_src=twsrc%5Etfw"},"November 27, 2022"))," ",(0,r.kt)("script",{async:!0,src:"https://platform.twitter.com/widgets.js",charset:"utf-8"}),(0,r.kt)("p",null,"Prompt del Tweet:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-markdown"},"El siguiente es una conversaci\xf3n entre Michelle presente (edad [redactada]) y Michelle joven (edad 14).\n\nMichelle joven ha escrito las siguientes entradas en su diario:\n[entradas del diario aqu\xed]\n\nMichelle presente: [escribe tus preguntas aqu\xed]\n")),(0,r.kt)("p",null,"La autora se\xf1ala que las entradas de diario pueden alcanzar el l\xedmite de tokens. En este caso, podr\xedas seleccionar algunas entradas o tratar de resumir varias entradas."),(0,r.kt)("h2",{id:"implementaci\xf3n"},"Implementaci\xf3n"),(0,r.kt)("p",null,"Voy a explicar c\xf3mo codificar un chatbot simple impulsado por GPT-3 en Python. Incluir GPT-3 en una aplicaci\xf3n que est\xe9s construyendo es incre\xedblemente f\xe1cil utilizando la API de OpenAI. Necesitar\xe1s crear una cuenta en OpenAI y obtener una clave API. Echa un vistazo a su documentaci\xf3n ",(0,r.kt)("a",{href:"https://beta.openai.com/docs/introduction"},"aqu\xed"),"."),(0,r.kt)("p",null,"Visi\xf3n general de lo que tenemos que hacer:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Formatear la entrada del usuario en un mensaje de chatbot para GPT-3."),(0,r.kt)("li",{parentName:"ol"},"Obtener la respuesta del chatbot como una respuesta de GPT-3."),(0,r.kt)("li",{parentName:"ol"},"Actualizar el mensaje con tanto la entrada del usuario como la respuesta del chatbot."),(0,r.kt)("li",{parentName:"ol"},"Repetir.")),(0,r.kt)("p",null,"Aqu\xed est\xe1 el mensaje que utilizar\xe9. Podemos usar Python para reemplazar <historial de conversaci\xf3n",">"," y <entrada del usuario",">"," con sus valores reales."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'chatbot_prompt = """\n    Como chatbot avanzado, tu objetivo principal es ayudar a los usuarios de la mejor manera posible. Esto puede implicar responder preguntas, proporcionar informaci\xf3n \xfatil o completar tareas basadas en la entrada del usuario. Para ayudar eficazmente a los usuarios, es importante ser detallado y exhaustivo en tus respuestas. Usa ejemplos y evidencias para respaldar tus puntos y justificar tus recomendaciones o soluciones.\n\n    <historial de conversaci\xf3n>\n\n    Usuario: <entrada del usuario>\n    Chatbot:"""\n')),(0,r.kt)("p",null,"Mantengo un registro tanto de la pr\xf3xima entrada del usuario como de la conversaci\xf3n anterior. Cada iteraci\xf3n se agrega una nueva entrada/salida entre el chatbot y el usuario."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import openai\n\nopenai.api_key = "TU CLAVE API AQU\xcd"\nmodel_engine = "text-davinci-003"\nchatbot_prompt = """\nComo chatbot avanzado, tu objetivo principal es ayudar a los usuarios de la mejor manera posible. Esto puede implicar responder preguntas, proporcionar informaci\xf3n \xfatil o completar tareas basadas en la entrada del usuario. Para ayudar eficazmente a los usuarios, es importante ser detallado y exhaustivo en tus respuestas. Usa ejemplos y evidencias para respaldar tus puntos y justificar tus recomendaciones o soluciones.\n\n<historial de conversaci\xf3n>\n\nUsuario: <entrada del usuario>\nChatbot:"""\n\n\ndef obtener_respuesta(historial_de_conversacion, entrada_del_usuario):\n    mensaje = chatbot_prompt.replace(\n        "<historial de conversaci\xf3n>", historial_de_conversacion).replace("<entrada del usuario>", entrada_del_usuario)\n\n    # Obtener la respuesta de GPT-3\n    respuesta = openai.Completion.create(\n        engine=model_engine, prompt=mensaje, max_tokens=2048, n=1, stop=None, temperature=0.5)\n\n    # Extraer la respuesta del objeto de respuesta\n    texto_respuesta = respuesta["choices"][0]["text"]\n\n    respuesta_chatbot = texto_respuesta.strip()\n\n    return respuesta_chatbot\n\n\ndef main():\n    historial_de_conversacion = ""\n\n    while True:\n        entrada_del_usuario = input("> ")\n        if entrada_del_usuario == "salir":\n            break\n        respuesta_chatbot = obtener_respuesta(historial_de_conversacion, entrada_del_usuario)\n        print(f"Chatbot: {respuesta_chatbot}")\n        historial_de_conversacion += f"Usuario: {entrada_del_usuario}\\nChatbot: {chatbot_response}\\n"\n\nmain()\n')),(0,r.kt)("p",null,"Aqu\xed hay un enlace al c\xf3digo completo para un chatbot simple: ",(0,r.kt)("a",{href:"https://gist.github.com/jayo78/79d8834e6e31bf942c7b604e1611b68d"},"aqu\xed"),"."),(0,r.kt)("p",null),"Ahora solo queda construir una interfaz de usuario atractiva con la que los usuarios puedan interactuar.",(0,r.kt)("p",null,"Written by ",(0,r.kt)("a",{parentName:"p",href:"https://twitter.com/jayo782"},"jayo78"),"."),(0,r.kt)("div",{className:"footnotes"},(0,r.kt)("hr",{parentName:"div"}),(0,r.kt)("ol",{parentName:"div"},(0,r.kt)("li",{parentName:"ol",id:"fn-1"},"OpenAI. (2022). ChatGPT: Optimizing Language Models for Dialogue. https://openai.com/blog/chatgpt/. https://openai.com/blog/chatgpt/\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-1",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-2"},"Jurafsky, D., & Martin, J. H. (2009). Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics and Speech Recognition. Prentice Hall.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-2",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-3"},"Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., \u2026 Amodei, D. (2020). Language Models are Few-Shot Learners.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-3",className:"footnote-backref"},"\u21a9")))))}b.isMDXComponent=!0}}]);