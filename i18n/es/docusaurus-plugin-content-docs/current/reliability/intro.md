---
sidebar_position: 1
---

# 游릭 Introducci칩n

Este cap칤tulo cubre c칩mo hacer que las completaciones sean m치s confiables, as칤 como c칩mo implementar verificaciones para asegurar que las salidas sean confiables.

Hasta cierto punto, la mayor칤a de las t칠cnicas anteriores cubiertas tienen que ver con mejorar la precisi칩n de las completaciones y, por lo tanto, la confiabilidad, en particular la autoconsistencia(@wang2022selfconsistency). Sin embargo, hay una serie de otras t칠cnicas que se pueden utilizar para mejorar la confiabilidad, m치s all치 de las estrategias b치sicas de generaci칩n de entradas.

%%LLMs|LLM%% have been found to be more reliable than we might expect at interpreting what a prompt is *trying* to say when responding to misspelled, badly phrased, or even actively misleading prompts(@webson2023itscomplicated). Despite this ability, they still exhibit various problems including hallucinations(@ye2022unreliability), flawed explanations with %%CoT|CoT prompting%% methods(@ye2022unreliability), and multiple biases including majority label bias, recency bias, and common token bias(@zhao2021calibrate). Adem치s, la generaci칩n de entradas de cero disparo CoT puede ser particularmente sesgada al tratar temas sensibles (@shaikh2022second).

Las soluciones comunes para algunos de estos problemas incluyen calibradores para eliminar los sesgos _a priori_, y verificadores para puntuar las completaciones, as칤 como promover la diversidad en las completaciones.
