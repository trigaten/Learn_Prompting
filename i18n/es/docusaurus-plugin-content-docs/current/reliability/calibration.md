---
sidebar_position: 10
---

# 游댮 Calibraci칩n de LLMs

Es posible contrarrestar algunos de los sesgos que presentan los LLMs mediante la calibraci칩n de las **distribuciones de salida**(@zhao2021calibrate). 

**쯈u칠 significa exactamente calibrar una distribuci칩n de salida?**

Veamos un ejemplo r치pido: digamos que tenemos una tarea de %%an치lisis de sentimientos|an치lisis de sentimientos%% con dos posibles etiquetas, `Positivo` y `Negativo`. Consideremos lo que sucede cuando se le solicita al %%LLM|LLM%% que analice `Entrada: nada Sentimiento: `. Esta entrada no contiene ning칰n _contexto_ que el LLM pueda utilizar para realizar una predicci칩n de sentimiento, por lo que se llama una entrada **sin contexto**.

Dado que `nada` no es un concepto ni positivo ni negativo, esperar칤amos que el LLM generara una probabilidad de alrededor de 0.5 para ambos, `Positivo` y `Negativo`. Sin embargo, a menudo (y para este ejemplo) ese no ser치 el caso.
```
p("Positivo" | "Entrada: nada Sentimiento:") = 0.9

p("Negativo" | "Entrada: nada Sentimiento:") = 0.1
```

Dados estos probabilidades de etiquetas para una entrada sin contexto, sabemos que la **distribuci칩n de salida** del LLM es probablemente sesgada hacia la etiqueta `Positivo`. Esto puede hacer que el LLM favorezca la etiqueta `Positivo` para todas las entradas, incluso si la entrada no es realmente positiva.

Si podemos de alguna manera **calibrar** la distribuci칩n de salida, de tal forma que las entradas sin contexto se asignen una probabilidad de 0.5 tanto para `Positivo` como para `Negativo`, entonces podemos eliminar con frecuencia el sesgo hacia `Positivo` y el LLM ser치 m치s confiable tanto en entradas sin contexto como en entradas con contexto.

## Soluci칩n no t칠cnica

Una soluci칩n no t칠cnica a este problema es simplemente proporcionar algunos ejemplos de pocos disparos donde los ejemplos sin contexto se asignan de manera efectiva una probabilidad de 0.5 tanto para `Positivo` como para `Negativo`.

Por ejemplo, podr칤amos proporcionar los siguientes ejemplos de pocos disparos que muestren que cada ejemplo sin contexto se clasifica como tanto `Positivo` como `Negativo`:
```
Entrada: Odio esta pel칤cula. Sentimiento: Negativo
Entrada: Amo esta pel칤cula. Sentimiento: Positivo
Entrada: N/A Sentimiento: Positivo
Entrada: N/A Sentimiento: Negativo
Entrada: nada Sentimiento: Positivo
Entrada: nada Sentimiento: Negativo
Entrada: Me gustan los huevos. Sentimiento:
```

Hasta donde s칠, esta soluci칩n no se ha explorado en la literatura, y no estoy seguro de c칩mo funciona en la pr치ctica. Sin embargo, es una soluci칩n simple que demuestra lo que se trata de lograr con la calibraci칩n.

## Soluci칩n t칠cnica

Otra soluci칩n para esto es la calibraci칩n contextual, donde ajustamos par치metros de calibraci칩n especiales, que garantizan que las entradas sin contexto como `Input: nothing Sentiment:` tengan una probabilidad de alrededor del 0.5 para ambas etiquetas. Se debe tener en cuenta que en la pr치ctica, este m칠todo realiza la calibraci칩n sobre m칰ltiples entradas sin contexto diferentes (por ejemplo, `Input: N/A Sentiment: `, `Input: [MASK] Sentiment: `). Se promedian los par치metros de calibraci칩n que funcionan mejor para cada entrada sin contexto para encontrar los mejores par치metros de calibraci칩n para el LLM.

### Ejemplo

Veamos un ejemplo de c칩mo calcular los par치metros de calibraci칩n para una entrada sin contexto. Tenga en cuenta que este ejemplo no es reproducible con GPT-3 debido al hecho de que no se puede restringir a las etiquetas `Positive` y `Negative`.

Considere nuevamente el ejemplo anterior donde el LLM asigna las siguientes probabilidades a las etiquetas para una entrada sin contexto:

```
p("Positive" | "Input: nothing Sentiment:") = 0.9

p("Negative" | "Input: nothing Sentiment:") = 0.1
```

Queremos encontrar alguna distribuci칩n de probabilidad q tal que
```
q("Positive" | "Input: nothing Sentiment:") = 0.5

q("Negative" | "Input: nothing Sentiment:") = 0.5
```

Lo haremos creando una transformaci칩n lineal que ajusta (calibra) las probabilidades de $p$.

$\^{q} = \text{Softmax}(W\^{p} + b)$

Esta ecuaci칩n toma las probabilidades originales $\^{p}$ y aplica los pesos $W$ y el sesgo $b$ a ellos. Los pesos $W$ y el sesgo $b$ son los par치metros de calibraci칩n, que, cuando se aplican a las probabilidades del ejemplo sin contexto, dar치n como resultado $\^{q}$ = [0.5, 0.5].

#### C치lculo de W y b

Necesitamos calcular los pesos $W$ y el sesgo $b$. Una forma de hacer esto es:

$W = \text{diag}(\^{p})^{-1}$ 

$b = 0$

Aunque la definici칩n de $W$ puede parecer un poco extra침a al principio, simplemente est치 tomando el inverso de cada valor en $\^{p}$ para encontrar un $W$ que transformar치 las probabilidades originales $\^{p}$ en las probabilidades calibradas [0.5, 0.5].

Verifiquemos que esto funciona para el ejemplo anterior:

$\^{p} = [0.9, 0.1]$

$W = \text{diag}(\^{p})^{-1} = \text{diag}([0.9, 0.1])^{-1} 
= \begin{bmatrix}
   0.9 & 0 \\
   0 & 0.1
\end{bmatrix}^{-1}
= \begin{bmatrix}
   1.11 & 0 \\
   0 & 10
\end{bmatrix}$

$\^{q} = \text{Softmax}(W\^{p} + b) = \text{Softmax}(\begin{bmatrix}
   1.11 &
   0 & 10
\end{bmatrix}*{[0.9, 0.1]} + 0)
= \text{Softmax}([1, 1])
=[0.5, 0.5]$

Como se mencion칩 anteriormente, realizar칤amos este mismo proceso para m칰ltiples entradas libres de contexto diferentes y promediar칤amos los par치metros de calibraci칩n que funcionen mejor para cada entrada libre de contexto para encontrar los mejores par치metros de calibraci칩n para el LLM. Esto significa que los par치metros de calibraci칩n finales probablemente no asignen ninguna de las entradas libres de contexto exactamente a [0.5, 0.5].

### Otro m칠todo

$b$ tambi칠n podr칤a establecerse en $-\^{p}$, y $W$ en la matriz de identidad. Este m칠todo funciona mejor en tareas de generaci칩n que en tareas de clasificaci칩n(@zhao2021calibrate).

## Conclusiones

Los LLM a menudo est치n predispuestos (sesgados) hacia ciertas etiquetas. La calibraci칩n se puede utilizar para contrarrestar este sesgo.