---
sidebar_position: 4
---

#  ChatGPT a partir de GPT-3

import Skippy from '@site/docs/assets/basic_applications/skippy_chatbot.webp'    
import SkippyHeader from '@site/docs/assets/basic_applications/skippy_chatbot_header.webp'    
import Therapy from '@site/docs/assets/basic_applications/therapy_chatbot.gif'
import ChatGPT from '@site/docs/assets/basic_applications/chatgpt_ui_diagram.webp'

<div style={{textAlign: 'left'}}>
  <LazyLoadImage src={SkippyHeader} style={{width: "700px"}} />
</div>

## Introducci贸n

[ChatGPT](https://chat.openai.com/chat) ha explotado en el 煤ltimo mes, ganando un mill贸n de usuarios en solo una semana. Sorprendentemente, el modelo subyacente, GPT-3, debut贸 en 2020 y se lanz贸 para acceso p煤blico hace m谩s de un a帽o.   

Para aquellos que no lo saben, ChatGPT es un nuevo modelo de lenguaje de OpenAI que fue ajustado a partir de GPT-3 para ser optimizado para la conversaci贸n (@chatgpt2022). Tiene una interfaz de chat f谩cil de usar, donde puedes ingresar una entrada y obtener una respuesta de un asistente de inteligencia artificial. chale un vistazo en [chat.openai.com](https://chat.openai.com/chat).

Si bien las primeras versiones de GPT-3 no eran tan avanzadas como la actual serie GPT-3.5, a煤n eran impresionantes. Estos modelos han estado disponibles a trav茅s de una API y una interfaz de usuario web de <a href="https://beta.openai.com/playground">playground</a> que te permite ajustar ciertos hiperpar谩metros de configuraci贸n y probar prompts. GPT-3 gan贸 una tracci贸n significativa, pero no se acerc贸 a la viralidad de ChatGPT. 

Lo que hace que ChatGPT sea tan exitoso en comparaci贸n con GPT-3 es su accesibilidad como un asistente de IA sencillo para la persona promedio, independientemente de su conocimiento de la ciencia de datos, los modelos de lenguaje o la IA.

En este art铆culo, describo c贸mo se pueden implementar chatbots como ChatGPT utilizando un modelo de lenguaje grande como GPT-3.

## Motivaci贸n
Este art铆culo se escribi贸 en parte debido a un tweet de <a href="https://twitter.com/goodside">Riley Goodside</a>, que se帽al贸 c贸mo podr铆a haberse implementado ChatGPT.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">C贸mo crear tu propio ChatGPT usando GPT-3 (text-davinci-003) - donde puedes personalizar las reglas seg煤n tus necesidades y acceder al chatbot resultante a trav茅s de una API. <a href="https://t.co/9jHrs91VHW">pic.twitter.com/9jHrs91VHW</a></p>&mdash; Riley Goodside (@goodside) <a href="https://twitter.com/goodside/status/1607487283782995968?ref_src=twsrc%5Etfw">26 de diciembre de 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 

Al igual que otros modelos de la serie GPT-3.5, ChatGPT fue entrenado utilizando [RLHF](https://huggingface.co/blog/rlhf), pero gran parte de su efectividad proviene de utilizar un **buen prompt**.

## El prompt

<div style={{textAlign: 'left'}}>
  <LazyLoadImage src={Skippy} style={{width: "700px"}} />
  <p style={{color: "gray", fontSize: "12px", fontStyle: "italic"}}>Prompt completo de Skippy del encabezado del art铆culo</p>
</div>

<a href="https://learnprompting.org/docs/basics/prompting">El prompting es el proceso de instruir a una IA para que haga algo.</a> Como probablemente hayas visto en los ejemplos de ChatGPT en l铆nea, puedes pedirle que haga casi cualquier cosa. Los casos de uso comunes son resumir textos, escribir contenido basado en una descripci贸n o crear cosas como poemas, recetas y mucho m谩s.

<p></p>

ChatGPT es tanto un modelo de lenguaje como una interfaz de usuario. La entrada de prompt que el usuario introduce en la interfaz se inserta en realidad en un prompt m谩s grande que contiene toda la conversaci贸n entre el usuario y ChatGPT. Esto permite que el modelo de lenguaje subyacente comprenda el contexto de la conversaci贸n y responda adecuadamente.

<div style={{textAlign: 'left'}}>
  <LazyLoadImage src={ChatGPT} style={{width: "600px"}} />
  <p style={{color: "gray", fontSize: "12px", fontStyle: "italic"}}>Ejemplo de inserci贸n de prompt de usuario antes de enviarlo al modelo</p>
</div>

El modelo de lenguaje completa el prompt determinando qu茅 palabras vienen a continuaci贸n en funci贸n de las probabilidades que aprendi贸 durante el pre-entrenamiento (@jurafsky2009).

<p></p>

GPT-3 es capaz de 'aprender' a partir de una instrucci贸n simple o unos pocos ejemplos en el prompt. Esto se llama aprendizaje con pocos ejemplos, o aprendizaje en contexto (@brown2020language). En el prompt del chatbot de arriba, creo un chatbot ficticio llamado Skippy y le pido que proporcione respuestas a los usuarios. GPT-3 se da cuenta del formato de ida y vuelta, `USER: {entrada del usuario}` y `SKIPPY: {respuesta de Skippy}`. GPT-3 entiende que Skippy es un chatbot y que los intercambios anteriores son una conversaci贸n, por lo que cuando proporcionamos la siguiente entrada del usuario, "Skippy" responder谩.

### Memorizaci贸n

Los intercambios anteriores entre Skippy y el usuario se agregan al siguiente prompt. Cada vez que proporcionamos m谩s entrada del usuario y obtenemos m谩s salida del chatbot, el prompt se expande para incorporar este nuevo intercambio. As铆 es como los chatbots como Skippy y ChatGPT pueden **recordar las entradas anteriores**. Sin embargo, hay un l铆mite en cuanto a cu谩nto puede recordar un chatbot de GPT-3.

Los prompts pueden llegar a ser muy largos despu茅s de varias interacciones, especialmente si estamos utilizando el chatbot para generar respuestas largas como publicaciones de blog. Los prompts enviados a GPT-3 se convierten en tokens, que son palabras individuales o partes de ellas. Existe un l铆mite de <a href="https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them">4097 tokens (aproximadamente 3000 palabras)</a> para el prompt combinado y la respuesta generada para modelos GPT-3, incluyendo ChatGPT. 

### Algunos ejemplos

Hay muchos casos de uso diferentes para prompts de chatbot que almacenan conversaciones previas. ChatGPT est谩 destinado a ser un asistente general multiprop贸sito y, en mi experiencia, rara vez hace preguntas de seguimiento.

#### Chatbot de terapia que pregunta sobre tu d铆a

Puede ser 煤til tener un chatbot que haga preguntas y obtenga comentarios del usuario. A continuaci贸n se muestra un ejemplo de prompt de chatbot de terapia que har谩 preguntas y seguimientos para ayudar al usuario a reflexionar sobre su d铆a.

<div style={{textAlign: 'left'}}>
  <LazyLoadImage src={Therapy} style={{width: "700px"}} />
  <p style={{color: "gray", fontSize: "12px", fontStyle: "italic"}}>Prompt de chatbot de terapia</p>
</div>

#### Habla con tu yo m谩s joven utilizando antiguas entradas de diario

<a href="https://twitter.com/michellehuang42">Michelle Huang</a> us贸 GPT-3 para tener una conversaci贸n con su yo m谩s joven. El prompt utiliza algo de contexto, en este caso antiguas entradas de diario, combinado con un formato de ida y vuelta de chatbot. GPT-3 es capaz de imitar una personalidad basada en estas entradas.

<p></p>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">i trained an ai chatbot on my childhood journal entries - so that i could engage in real-time dialogue with my &quot;inner child&quot;<br/><br/>some reflections below:</p>&mdash; michelle huang (@michellehuang42) <a href="https://twitter.com/michellehuang42/status/1597005489413713921?ref_src=twsrc%5Etfw">November 27, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 

Prompt del Tweet:
```markdown
El siguiente es una conversaci贸n entre Michelle presente (edad [redactada]) y Michelle joven (edad 14).

Michelle joven ha escrito las siguientes entradas en su diario:
[entradas del diario aqu铆]

Michelle presente: [escribe tus preguntas aqu铆]
```

La autora se帽ala que las entradas de diario pueden alcanzar el l铆mite de tokens. En este caso, podr铆as seleccionar algunas entradas o tratar de resumir varias entradas.

## Implementaci贸n

Voy a explicar c贸mo codificar un chatbot simple impulsado por GPT-3 en Python. Incluir GPT-3 en una aplicaci贸n que est茅s construyendo es incre铆blemente f谩cil utilizando la API de OpenAI. Necesitar谩s crear una cuenta en OpenAI y obtener una clave API. Echa un vistazo a su documentaci贸n <a href="https://beta.openai.com/docs/introduction">aqu铆</a>.

Visi贸n general de lo que tenemos que hacer:

1. Formatear la entrada del usuario en un mensaje de chatbot para GPT-3.
2. Obtener la respuesta del chatbot como una respuesta de GPT-3.
3. Actualizar el mensaje con tanto la entrada del usuario como la respuesta del chatbot.
4. Repetir.

Aqu铆 est谩 el mensaje que utilizar茅. Podemos usar Python para reemplazar <historial de conversaci贸n\> y <entrada del usuario\> con sus valores reales.

```python
chatbot_prompt = """
    Como chatbot avanzado, tu objetivo principal es ayudar a los usuarios de la mejor manera posible. Esto puede implicar responder preguntas, proporcionar informaci贸n 煤til o completar tareas basadas en la entrada del usuario. Para ayudar eficazmente a los usuarios, es importante ser detallado y exhaustivo en tus respuestas. Usa ejemplos y evidencias para respaldar tus puntos y justificar tus recomendaciones o soluciones.

    <historial de conversaci贸n>

    Usuario: <entrada del usuario>
    Chatbot:"""
```

Mantengo un registro tanto de la pr贸xima entrada del usuario como de la conversaci贸n anterior. Cada iteraci贸n se agrega una nueva entrada/salida entre el chatbot y el usuario.

```python
import openai

openai.api_key = "TU CLAVE API AQU"
model_engine = "text-davinci-003"
chatbot_prompt = """
Como chatbot avanzado, tu objetivo principal es ayudar a los usuarios de la mejor manera posible. Esto puede implicar responder preguntas, proporcionar informaci贸n 煤til o completar tareas basadas en la entrada del usuario. Para ayudar eficazmente a los usuarios, es importante ser detallado y exhaustivo en tus respuestas. Usa ejemplos y evidencias para respaldar tus puntos y justificar tus recomendaciones o soluciones.

<historial de conversaci贸n>

Usuario: <entrada del usuario>
Chatbot:"""


def obtener_respuesta(historial_de_conversacion, entrada_del_usuario):
    mensaje = chatbot_prompt.replace(
        "<historial de conversaci贸n>", historial_de_conversacion).replace("<entrada del usuario>", entrada_del_usuario)

    # Obtener la respuesta de GPT-3
    respuesta = openai.Completion.create(
        engine=model_engine, prompt=mensaje, max_tokens=2048, n=1, stop=None, temperature=0.5)

    # Extraer la respuesta del objeto de respuesta
    texto_respuesta = respuesta["choices"][0]["text"]

    respuesta_chatbot = texto_respuesta.strip()

    return respuesta_chatbot


def main():
    historial_de_conversacion = ""

    while True:
        entrada_del_usuario = input("> ")
        if entrada_del_usuario == "salir":
            break
        respuesta_chatbot = obtener_respuesta(historial_de_conversacion, entrada_del_usuario)
        print(f"Chatbot: {respuesta_chatbot}")
        historial_de_conversacion += f"Usuario: {entrada_del_usuario}\nChatbot: {chatbot_response}\n"

main()
```


Aqu铆 hay un enlace al c贸digo completo para un chatbot simple: <a href="https://gist.github.com/jayo78/79d8834e6e31bf942c7b604e1611b68d">aqu铆</a>.

<p></p>
Ahora solo queda construir una interfaz de usuario atractiva con la que los usuarios puedan interactuar.

Written by [jayo78](https://twitter.com/jayo782).