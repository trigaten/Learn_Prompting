---
sidebar_position: 3
locale: en-us
style: chicago
---

# üü¢ Cadena de pensamiento

El Encadenamiento de pensamiento (CoT, por sus siglas en ingl√©s "Chain of Thought") (@wei2022chain) es un m√©todo de indicaciones que se desarroll√≥ recientemente y que alienta al LLM a explicar su razonamiento. La imagen a continuaci√≥n (@wei2022chain) muestra una indicaci√≥n est√°ndar de "pocos ejemplos" (izquierda) en comparaci√≥n con una indicaci√≥n de encadenamiento de pensamiento (derecha).

import CoTExample from '@site/docs/assets/chain_of_thought_example.png';

<div style={{textAlign: 'center'}}>
  <img src={CoTExample} style={{width: "750px"}} />
</div>

<div style={{textAlign: 'center'}}>
Indicaci√≥n est√°ndar vs. CoT (Wei et al.)
</div>


La idea principal de CoT es que, al mostrarle al LLM algunos %%ejemplos|ejemplos%% con pocos disparos en los que se explica el proceso de razonamiento, el LLM tambi√©n mostrar√° el proceso de razonamiento al responder la indicaci√≥n. Esta explicaci√≥n del razonamiento a menudo conduce a resultados m√°s precisos.

## Ejemplo

Aqu√≠ hay algunas demostraciones. La primera muestra que GPT-3 (davinci-003) no puede resolver un problema de palabras simple. La segunda muestra que GPT-3 (davinci-003) resuelve con √©xito el mismo problema utilizando la indicaci√≥n de CoT.

#### Incorrecto

<div trydyno-embed="" openai-model="text-davinci-003" initial-prompt="¬øCu√°l es la forma m√°s r√°pida de llegar al trabajo?\nOpci√≥n 1: Tomar un autob√∫s de 1000 minutos, luego un tren de media hora y finalmente un paseo en bicicleta de 10 minutos.\nOpci√≥n 2: Tomar un autob√∫s de 800 minutos, luego un tren de una hora y finalmente un paseo en bicicleta de 30 minutos." initial-response="La opci√≥n 1 es una forma m√°s r√°pida de llegar al trabajo." max-tokens="256" box-rows="7" model-temp="0" top-p="0"></div>

#### Correcto

<div trydyno-embed="" openai-model="text-davinci-003" initial-prompt="¬øCu√°l es la forma m√°s r√°pida de llegar a casa?\nOption 1: Tomar un autob√∫s de 10 minutos, luego un autob√∫s de 40 minutos y finalmente un tren de 10 minutos.\nOption 2: Tomar un tren de 90 minutos, luego un paseo en bicicleta de 45 minutos y finalmente un autob√∫s de 10 minutos.\nOption 1: tomar√° 10+40+10=60 minutos.\nOption 2: tomar√° 90+45+10=145 minutos.\nSince Dado que la opci√≥n 1 tarda 60 minutos y la opci√≥n 2 tarda 145 minutos, la opci√≥n 1 es m√°s r√°pida.\n\n¬øCu√°l es la forma m√°s r√°pida de llegar al trabajo? \nOption 1: Tomar un autob√∫s de 1000 minutos, luego un tren de media hora y finalmente un paseo en bicicleta de 10 minutos. \nOption 2: Tomar un autob√∫s de 800 minutos, luego un tren de una hora y finalmente un paseo en bicicleta de 30 minutos." initial-response="La opci√≥n 1 tomar√° 1000+30+10=1040 minutos.
La opci√≥n 2 tomar√° 800+60+30=890 minutos.
Dado que la opci√≥n 2 tarda 890 minutos y la opci√≥n 1 tarda 1040 minutos, la opci√≥n 2 es m√°s r√°pida." max-tokens="256" box-rows="18" model-temp="0" top-p="0"></div>

## Resultados

Se ha demostrado que CoT es efectivo para mejorar los resultados en tareas como 
aritm√©tica, sentido com√∫n y tareas de razonamiento simb√≥lico (@wei2022chain). 
En particular, prompted PaLM 540B (@chowdhery2022palm) alcanza una precisi√≥n de 
tasa de resoluci√≥n del 57% en GSM8K (@cobbe2021training) (SOTA en ese momento).

import PromptedPaLM from '@site/docs/assets/prompted_palm.png';

<div style={{textAlign: 'center'}}>
  <img src={PromptedPaLM} style={{width: "300px"}} />
</div>

<div style={{textAlign: 'center'}}>
Comparaci√≥n de modelos en la prueba de referencia GSM8K (Wei et al.)
</div>

## Limitaciones

Es importante destacar que, seg√∫n Wei et al., "CoT solo produce mejoras en el rendimiento cuando se utiliza con modelos de ‚àº100B de par√°metros". Modelos m√°s peque√±os escribieron cadenas de pensamiento il√≥gicas, lo que llev√≥ a una precisi√≥n peor que la de la prueba est√°ndar. Los modelos suelen obtener mejoras de rendimiento a partir de la sugerencia CoT de manera proporcional al tama√±o del modelo.

## Notas

Ning√∫n modelo de lenguaje fue ~~da√±ado~~ afinado en el proceso de escritura de este cap√≠tulo üòä.