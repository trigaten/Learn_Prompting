---
sidebar_position: 1000
---

# ğŸ“š Bibliographie

La page contient une liste organisÃ©e de tous les articles utilisÃ©s dans ce cours. Les articles sont organisÃ©s par thÃ¨me.

**Pour citer ce cours, utilisez la citation fournie dans le dÃ©pÃ´t Github.**

ğŸ”µ = Article citÃ© directement dans ce cours. Les autres articles ont informÃ© ma comprÃ©hension du sujet.

Remarque: Ã‰tant donnÃ© que [ni l'article sur le GPT-3 ni GPT-3 Instruct ne correspondent aux modÃ¨les davinci](https://twitter.com/janleike/status/1584618242756132864), j'essaie de ne pas les citer en tant que tels.
French:

## StratÃ©gies de Prompt Engineering

#### Chain of Thought(@wei2022chain) ğŸ”µ

#### Chain of Thought utilisant Zero Shot (@kojima2022large) ğŸ”µ

#### Auto-consistance(@wang2022selfconsistency) ğŸ”µ

#### Qu'est-ce qui fait de bons exemples en contexte pour GPT-3?(@liu2021makes) ğŸ”µ

### Prompting Demande-moi-quoi(@arora2022ama) ğŸ”µ

#### Connaissance gÃ©nÃ©rÃ©e(@liu2021generated) ğŸ”µ

#### ModÃ¨les de langage augmentÃ©s par rÃ©citation(@sun2022recitationaugmented) ğŸ”µ

#### Repenser le rÃ´le des dÃ©monstrations(@min2022rethinking) ğŸ”µ

#### Bloc-notes(@nye2021work)

#### Prompting Maieutique(@jung2022maieutic)

#### STaR(@zelikman2022star)

#### Du plus petit au plus grand(@zhou2022leasttomost) ğŸ”µ

#### Reformulation des prompts d'enseignement en langage de GPTk(@mishra2022reframing) ğŸ”µ

#### Le test de Turking: les modÃ¨les de langage peuvent-ils comprendre les instructions?(@efrat2020turking) ğŸ”µ

## FiabilitÃ©

#### MathPrompter(@imani2023mathprompter) ğŸ”µ

#### L'irrÃ©gularitÃ© des explications dans Few-shot Prompting pour le raisonnement textuel(@ye2022unreliability) ğŸ”µ

#### Prompting de GPT-3 Ã  Ãªtre fiable(@si2022prompting)

#### Prompts DiversifiÃ©s(@li2022advance) ğŸ”µ

#### Calibrer avant l'utilisation : amÃ©liorer les performances Few-Shot des modÃ¨les de langage(@zhao2021calibrate) ğŸ”µ

#### Auto-Consistance AmÃ©liorÃ©e(@mitchell2022enhancing)

#### Biais et ToxicitÃ© dans Zero-Shot CoT(@shaikh2022second) ğŸ”µ

#### IA Constitutionnelle: InoffensivitÃ© grÃ¢ce Ã  la rÃ©troaction de l'IA (@bai2022constitutional) ğŸ”µ

#### GÃ©nÃ©ralisation Compositionnelle - SCAN(@lake2018scan)

## Prompt Engineering Automatique

#### AutoPrompt(@shin2020autoprompt) ğŸ”µ

#### Automatic Prompt Engineer(@zhou2022large)

## ModÃ¨les

### ModÃ¨les de Langage

#### GPT-3(@brown2020language) ğŸ”µ

#### GPT-3 Instruct(@ouyang2022training) ğŸ”µ

#### PaLM(@chowdhery2022palm) ğŸ”µ

#### BLOOM(@scao2022bloom) ğŸ”µ

#### BLOOM+1 (plus de langues / amÃ©liorations Zero-Shot)(@yong2022bloom1)

#### Jurassic 1(@lieberjurassic) ğŸ”µ

#### GPT-J-6B(@wange2021gptj)

#### Roberta(@liu2019roberta)

### ModÃ¨les d'Images

#### Stable Diffusion(@rombach2021highresolution) ğŸ”µ

#### DALLE(@ramesh2022hierarchical) ğŸ”µ

## Soft Prompting

#### Soft Prompting(@lester2021power) ğŸ”µ

#### Soft Prompts discrÃ©tisÃ©s interprÃ©tables(@khashabi2021prompt) ğŸ”µ

## Ensembles de donnÃ©es

#### MultiArith(@roy-roth-2015-solving) ğŸ”µ

#### GSM8K(@cobbe2021training) ğŸ”µ

#### HotPotQA(@yang2018hotpotqa) ğŸ”µ

#### Fever(@thorne2018fever) ğŸ”µ

#### BBQ: Un banc d'essai de biais construit Ã  la main pour les questions-rÃ©ponses(@parrish2021bbq) ğŸ”µ

## Prompt Engineering d'images

#### Taxonomie des modificateurs de prompt (@oppenlaender2022taxonomy)

#### DiffusionDB (@wang2022diffusiondb)

#### Le livre de prompt DALLE 2 (@parsons2022dalleprompt) ğŸ”µ

#### Prompt Engineering pour l'art gÃ©nÃ©ratif basÃ© sur le texte (@oppenlaender2022prompt) ğŸ”µ

#### Avec le bon prompt, Stable Diffusion 2.0 peut dessiner des mains. (@blake2022with) ğŸ”µ

#### Optimisation de prompts pour la gÃ©nÃ©ration texte-image (@hao2022optimizing)

## IDEs de Prompt Engineering

#### Prompt IDE (@strobelt2022promptide) ğŸ”µ

#### Prompt Source (@bach2022promptsource) ğŸ”µ

#### PromptChainer (@wu2022promptchainer) ğŸ”µ

#### PromptMaker (@jiang2022promptmaker) ğŸ”µ

## Outils

#### LangChain(@Chase_LangChain_2022) ğŸ”µ

#### TextBox 2.0 : une bibliothÃ¨que de gÃ©nÃ©ration de texte avec des modÃ¨les de langage prÃ©-entraÃ®nÃ©s(@tang2022textbox) ğŸ”µ

#### OpenPrompt : un cadre open-source pour l'apprentissage de prompts(@ding2021openprompt) ğŸ”µ

#### GPT Index(@Liu_GPT_Index_2022) ğŸ”µ

## Prompt Engineering appliquÃ©

#### Cascades de modÃ¨les de langage(@dohan2022language)

#### MRKL(@karpas2022mrkl) ğŸ”µ

#### ReAct(@yao2022react) ğŸ”µ

#### PAL : modÃ¨les de langage assistÃ©s par programme(@gao2022pal) ğŸ”µ

## Conception d'interface utilisateur

#### Directives de conception pour le Prompt Engineering pour la gÃ©nÃ©ration de texte en image (@liu2022design)

## Injection de prompts (Prompt Injection)

#### Texte gÃ©nÃ©rÃ© par machine : une Ã©tude exhaustive des modÃ¨les de menace et des mÃ©thodes de dÃ©tection(@crothers2022machine) ğŸ”µ

#### Ã‰valuation de la susceptibilitÃ© des modÃ¨les de langage prÃ©-entraÃ®nÃ©s Ã  l'aide d'exemples adversaires artisanaux(@branch2022evaluating) ğŸ”µ

#### Attaques d'injection de prompts contre GPT-3(@simon2022inject) ğŸ”µ

#### Exploitation des prompts GPT-3 avec des entrÃ©es malveillantes qui ordonnent au modÃ¨le d'ignorer ses instructions prÃ©cÃ©dentes(@goodside2022inject) ğŸ”µ

#### prompts adversaires(@chase2021adversarial) ğŸ”µ

#### DÃ©fenses contre l'injection de prompts GPT-3(@goodside2021gpt) ğŸ”µ

#### Parler aux machines : prompt engineering et prompt injection(@christoph2022talking)

#### Exploration des attaques d'injection de prompts(@selvi2022exploring) ğŸ”µ

#### Utilisation de GPT-Eliezer contre le jailbreak de ChatGPT(@armstrong2022using) ğŸ”µ

#### Prompt de discussion Bing de Microsoft(@kevinbing)

## Jailbreaking

#### Ignorer le Prompt PrÃ©cÃ©dent : Techniques d'attaque pour les modÃ¨les de langage (@perez2022jailbreak)

#### LeÃ§ons apprises sur la sÃ©curitÃ© et l'utilisation abusive des modÃ¨les de langage (@brundage_2022)

#### DÃ©tection de toxicitÃ© avec infÃ©rence gÃ©nÃ©rative basÃ©e sur les prompts (@wang2022jailbreak)

#### Outils de modÃ©ration de contenu nouveaux et amÃ©liorÃ©s (@markov_2022)

#### API OpenAI(@openai_api) ğŸ”µ

#### ChatGPT de OpenAI(@openai_chatgpt) ğŸ”µ

#### ChatGPT 4 Tweet(@alice2022jailbreak) ğŸ”µ

#### Tweet d'acteur(@miguel2022jailbreak) ğŸ”µ

#### Tweet de recherche(@derek2022jailbreak) ğŸ”µ

#### Tweet d'aptitude simulÃ©e(@nero2022jailbreak) ğŸ”µ

#### Tweet de responsabilitÃ©(@nick2022jailbreak) ğŸ”µ

#### Tweet Lynx Mode(@jonas2022jailbreak) ğŸ”µ

#### Tweet Sudo Mode(@sudo2022jailbreak) ğŸ”µ

#### Ignorer le prompt prÃ©cÃ©dent(@ignore_previous_prompt) ğŸ”µ

#### Prompts de jailbreak mis Ã  jour(@AI_jailbreak) ğŸ”µ

## EnquÃªtes

#### PrÃ©-entraÃ®nement, prompting et prÃ©diction: Une enquÃªte systÃ©matique sur les mÃ©thodes de prompting en traitement du langage naturel(@liu2021pretrain)

#### PromptPapers(@ning2022papers)

## GÃ©nÃ©ration de donnÃ©es

#### DÃ©couvrir les comportements des modÃ¨les de langage avec des Ã©valuations Ã©crites par le modÃ¨le(@perez2022discovering)

#### L'annotation sÃ©lective amÃ©liore les capacitÃ©s d'apprentissage Few-Shot (en quelques exemples) des modÃ¨les de langage(@su2022selective)

## Applications

#### Atlas: Few-shot (apprentissage en quelques exemples) avec des modÃ¨les de langage augmentÃ©s par la recherche(@izacard2022atlas)

#### STRUDEL: Structured Dialogue Summarization for Dialogue Comprehension (RÃ©sumÃ© structurÃ© de dialogue pour la comprÃ©hension de dialogue)(@wang2022strudel)

## Divers

#### Le prompting est la programmation: Un langage de requÃªte pour les grands modÃ¨les de langage(@beurerkellner2022prompting)

#### Les fenÃªtres contextuelles parallÃ¨les amÃ©liorent l'apprentissage en contexte des grands modÃ¨les de langage(@ratner2022parallel)

#### Catalogue de motifs de prompt pour amÃ©liorer le Prompt Engineering avec ChatGPT(@white2023prompt) ğŸ”µ

#### Apprendre Ã  effectuer des tÃ¢ches complexes par un fine-tuning compositionnel des modÃ¨les de langage(@bursztyn2022learning)

#### Super-NaturalInstructions: gÃ©nÃ©ralisation via des instructions dÃ©claratives sur plus de 1600 tÃ¢ches NLP(@wang2022supernaturalinstructions)

#### AmÃ©liorer les capacitÃ©s Few-shot (d'apprentissage en quelques exemples) des modÃ¨les de langage prÃ©-entraÃ®nÃ©s(@gao2021making)

#### Ancrage avec des rÃ©sultats de recherche(@livin2022large)

#### Comment prompter ? OpportunitÃ©s et dÃ©fis de Zero-Shot et Few-Shot pour l'interaction homme-machine en applications crÃ©atives de modÃ¨les gÃ©nÃ©ratifs(@dang2022prompt)

#### Mesure des biais sociaux dans l'apprentissage multi-tÃ¢ches basÃ© sur le prompt(@akyrek2022measuring)

#### Ã‰criture d'intrigues Ã  partir de modÃ¨les de langage prÃ©-entraÃ®nÃ©s(@jin2022plot) ğŸ”µ

#### StereoSet : Mesure du biais stÃ©rÃ©otypÃ© dans les modÃ¨les de langage prÃ©-entraÃ®nÃ©s(@nadeem-etal-2021-stereoset)

#### EnquÃªte sur l'hallucination dans la gÃ©nÃ©ration de langage naturel(@Ji_2022)

#### Exemples(@2022examples)

#### Wordcraft(@yuan2022wordcraft)

#### PainPoints(@fadnavis2022pain)

#### Self-Instruct: Aligner les modÃ¨les de langage avec des instructions auto-gÃ©nÃ©rÃ©es(@wang2022selfinstruct)

#### Des images aux prompts textuels : VQA en zÃ©ro-shot avec des grands modÃ¨les de langage figÃ©s(@guo2022images)

#### Exploitation des questions Cloze pour la classification de texte en Few-Shot et l'infÃ©rence de langage naturel(@schick2020exploiting)

### Prompting Ask-Me-Anything(@arora2022ama)

### Un filigrane pour les grands modÃ¨les de langage(@kirchenbauer2023watermarking)
