---
sidebar_position: 1
---

# üü¢ Introduction

Ce chapitre couvre comment rendre les compl√©tions plus fiables, ainsi que la mani√®re d'impl√©menter des contr√¥les pour assurer la fiabilit√© des r√©sultats.

Dans une certaine mesure, la plupart des techniques pr√©c√©demment abord√©es ont pour but d'am√©liorer la pr√©cision des compl√©tions, et donc leur fiabilit√©, en particulier l'auto-consistance(@wang2022selfconsistency). Cependant, il existe un certain nombre d'autres techniques qui peuvent √™tre utilis√©es pour am√©liorer la fiabilit√©, au-del√† des strat√©gies de prompting de base.

Les %%LLMs|LLM%% se sont r√©v√©l√©s √™tre plus fiables que ce que nous pourrions attendre en interpr√©tant ce qu'un prompt *essaie* de dire lorsqu'ils r√©pondent √† des prompts mal orthographi√©s, mal formul√©s ou m√™me activement trompeurs(@webson2023itscomplicated). Malgr√© cette capacit√©, ils pr√©sentent encore divers probl√®mes, y compris des hallucinations(@ye2022unreliability), des explications erron√©es avec les m√©thodes de %%CoT|CoT prompting%%(@ye2022unreliability), et de multiples biais, y compris le biais de l'√©tiquette majoritaire, le biais de r√©cence et le biais de jeton commun(@zhao2021calibrate). De plus, le CoT en zero-shot peut √™tre particuli√®rement biais√© lorsqu'il traite de sujets sensibles(@shaikh2022second).

Parmi les solutions courantes √† certains de ces probl√®mes figurent les calibrateurs pour √©liminer les biais _a priori_, et les v√©rificateurs pour √©valuer les compl√©tions, ainsi que la promotion de la diversit√© dans les compl√©tions.
