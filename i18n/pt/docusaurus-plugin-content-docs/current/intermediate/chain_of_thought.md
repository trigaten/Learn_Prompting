---
sidebar_position: 3
locale: pt-br
style: chicago
---

# üü¢ Prompting com Cadeia de Pensamento

Prompting com Cadeia de Pensamento (CdP) (@wei2022chain) √© um m√©todo de *prompting* recente, que encoraja ao *LLM* (Grande Modelo de Linguagem) a explicar o seu racioc√≠nio. A imagem abaixo (@wei2022chain) mostra um *prompt few shot* padr√£o (esquerda) comparado ao *prompt* com Cadeia de Pensamento (direita).


import CoTExample from '@site/docs/assets/chain_of_thought_example.png';

<div style={{textAlign: 'center'}}>
  <img src={CoTExample} style={{width: "750px"}} />
</div>

<div style={{textAlign: 'center'}}>
Prompt comum x Cadeia de Pensamento (Wei et al.) [em ing√™s]
</div>

A principal ideia da Cadeia de Pensamento (CdP) √© mostrar ao *LLM* alguns exemplares *few shot* em que o processo de racioc√≠nio √© explicado, fazendo com que o *LLM* fa√ßa o mesmo quando der uma resposta ao *prompt*. A explica√ß√£o do racioc√≠nio frequentemente produz resultados mais apurados.

## Exemplo

Aqui est√£o algumas demonstra√ß√µes. A primeira mostra o GPT-3 (davinci-003) falhando ao resolver um problema simples. A segunda, por sua vez, mostra o GPT-3 (davinci-003)
obtendo √™xito na resolu√ß√£o do mesmo problema, com o uso da t√©cnica de Cadeia de Pensamento (CdP).
#### Incorreto

<div trydyno-embed="" openai-model="text-davinci-003" initial-prompt="Considerando as op√ß√µes abaixo, qual √© a forma mais r√°pida de chegar ao trabalho?\nOp√ß√£o 1: pegue um √¥nibus de 1000 minutos, depois um trem de meia hora e, finalmente, um passeio de bicicleta de 10 minutos.\nOp√ß√£o 2: pegue um √¥nibus de 800 minutos, depois uma hora de trem e, finalmente, um passeio de bicicleta de 30 minutos." initial-response="Op√ß√£o 1." max-tokens="256" box-rows="7" model-temp="0" top-p="0"></div>

#### Correto

<div trydyno-embed="" openai-model="text-davinci-003" initial-prompt="Considerando as op√ß√µes abaixo, qual √© a forma mais r√°pida de chegar ao trabalho?\nOp√ß√£o 1: pegue um √¥nibus de 10 minutos, depois um √¥nibus de 40 minutos e, finalmente, um trem de 10 minutos.\nOp√ß√£o 2: pegue um trem de 90 minutos, depois um passeio de bicicleta de 45 minutos e, finalmente, um √¥nibus de 10 minutos.\nA op√ß√£o 1 levar√° 10+40+10=60 minutos. A op√ß√£o 2 levar√° 90+45+10=145 minutos.\nComo a op√ß√£o 1 leva 60 minutos e a op√ß√£o 2 leva 145 minutos, a op√ß√£o 1 √© mais r√°pida.\n\nConsiderando as op√ß√µes abaixo, qual √© a forma mais r√°pida de chegar ao trabalho?\nOp√ß√£o 1: pegue um √¥nibus de 1000 minutos, depois um trem de meia hora e, finalmente, um passeio de bicicleta de 10 minutos.\nOp√ß√£o 2: pegue um √¥nibus de 800 minutos, depois uma hora de trem e, finalmente, um passeio de bicicleta de 30 minutos." initial-response="A op√ß√£o 1 levar√° 1000+30+10 = 1040 minutos.
A op√ß√£o 2 levar√° 800+60+30 = 890 minutos.
Como a Op√ß√£o 2 leva 890 minutos e a Op√ß√£o 1 leva 1.040 minutos, a Op√ß√£o 2 √© mais r√°pida." max-tokens="256" box-rows="7" model-temp="0" top-p="0"></div>

## Resultados

A Cadeia de Pensamento (CdP) mostrou ser efetiva em melhorar os resultados em tarefas de aritm√©tica, senso comum e racic√≠nio simb√≥lico (@wei2022chain).
Em particular, *prompted* PaLM 540B(@chowdhery2022palm) atinge 57% de precis√£o na resolu√ß√£o dos problemas de matem√°tica da cole√ß√£o de dados GSM8K(@cobbe2021training) (Estado da Arte, na √©poca).

import PromptedPaLM from '@site/docs/assets/prompted_palm.png';

<div style={{textAlign: 'center'}}>
  <img src={PromptedPaLM} style={{width: "300px"}} />
</div>

<div style={{textAlign: 'center'}}>
Compara√ß√£o de modelos no benchmark GSM8K (Wei et al.) [em ingl√™s]
</div>

## Limita√ß√µes

√â importante ressaltar que, de acordo com Wei et al., "A t√©cnica de Cadeia de Pensamento (CdP) s√≥ produz ganhos no desempenho quando usada em modelos de ~100B de par√¢metros". Modelos menores escrevem cadeias de pensamentos il√≥gicas, o que leva a uma piora na precis√£o quando comparado ao *prompt* padr√£o. Comumente, as melhoras obtidas nos *prompts* usando a t√©cnica de CdP s√£o proporcionais ao tamanho do modelo.


## Observa√ß√µes

Nenhum modelo de linguagem foi ~ferido~ (leia-se: tunelado) no processo de escrita deste cap√≠tulo üòä.