---
sidebar_position: 5
---

# üü° Montagem de prompts / M√©todos de ensamblagem

"Montagem de prompts" ou "M√©todos de ensamblagem" (ou ensembling prompt, em ingl√™s) √© o conceito de usar v√°rios prompts diferentes para tentar responder a mesma pergunta. Existem muitas abordagens diferentes para isso.

## DiVeRSe

DiVeRSe(@li2022advance) ("**Di**verse **Ve**rifier on **R**easoning **S**t**e**ps", ou "Verificador Diversificado em Etapas de Racioc√≠nio") √© um m√©todo que melhora a confiabilidade das respostas de tr√™s maneiras. Isso √© feito 1) usando v√°rios prompts para gerar conclus√µes diversificadas, 2) usando um verificador para distinguir boas respostas das ruins e 3) usando um verificador para verificar a corre√ß√£o das etapas de racioc√≠nio.

import diverse from '@site/docs/assets/reliability/diverse.webp';

<div style={{textAlign: 'center'}}>
  <img src={diverse} style={{width: "750px"}}/>
</div>

<div style={{textAlign: 'center'}}>
DiVeRSe (Li et al.)
</div>


### Prompts do tipo DiVeRSe

O DiVeRSe usa 5 prompts diferentes para um determinado input. Para construir cada prompt, eles amostram aleatoriamente alguns exemplos do conjunto de treinamento. Aqui est√° um exemplo de um prompt com poucas amostras (k = 2), com exemplos retirados do [GSM8K benchmark] (https://raw.githubusercontent.com/openai/grade-school-math/master/grade_school_math/data/train.jsonl) (@cobbe2021training). Na pr√°tica, o DiVeRSe usa 5 exemplos em prompts para este benchmark.


```
Q: Nat√°lia vendeu clipes para 48 de seus amigos em abril e, em seguida, vendeu a metade disso em maio. Quantos clipes Nat√°lia vendeu no total, em abril e maio?
A: Nat√°lia vendeu 48/2 = 24 clipes em maio.
Nat√°lia vendeu 48 + 24 = 72 clipes no total, em abril e maio.
#### 72
Q: Weng ganha US$ 12 por hora para trabalhar como bab√°. Ontem ela s√≥ trabalhou 50 minutos como bab√°. Quanto ela ganhou?
A: Weng ganha 12/60 = R$ 0,2 por minuto.
Trabalhando 50 minutos, ela ganhou 0,2 x 50 = R$ 10.
#### 10
Q: Betty est√° economizando dinheiro para uma nova carteira que custa R$ 100. Betty tem apenas metade do dinheiro que precisa. Seus pais decidiram dar-lhe R$ 15 para esse prop√≥sito e seus av√≥s o dobro do que seus pais. Qual a quantia Betty ainda precisa para comprar a carteira?
A:
```

Depois de gerar 5 prompts diferentes como acima, o DiVeRSe amostra 20 caminhos de racioc√≠nio para cada um (temperatura = 0,5). Aqui est√£o alguns exemplos de completamento do prompt acima. Note que as respostas nem sempre s√£o corretas.



```text
<!-- highlight-start -->
Betty tem 0.5*100 = R$50.
Ent√£o ela ganha mais 15 = R$65.
Em seguida ela ganha 2*15 = R$90.
Ela ainda precisa de 100-90 = R$10 a mais.
#### 10
<!-- highlight-end -->
```

```text
<!-- highlight-start -->
A: Betty tem 0.5*100 = R$500.
Ent√£o ela ganha 15 a mais = R$650.
Em seguida ela ganha 2*15 = R$900.
Ela ainda precisa de 100-90 = R$1000 a mais.
#### 1000
<!-- highlight-end -->
```

Nesse ponto, o DiVeRSe gerou 1000 completamentos diferentes.

### Verificador de Vota√ß√£o

Agora, n√≥s poder√≠amos simplesmente pegar a resposta majorit√°ria, como o Self-Consistency (@mitchell2022enhancing) faz.

No entanto, o DiVeRSe prop√µe um m√©todo muito mais complicado, que eles chamam de _verificador de vota√ß√£o_.

Na hora dos testes, usar o verificador de vota√ß√£o √© um processo de duas etapas. Primeiro, o verificador (uma rede neural) atribui uma pontua√ß√£o de 0 a 1 para cada completamento, com base na probabilidade de ser correto. Depois, a parte da "vota√ß√£o" soma todas as pontua√ß√µes de diferentes respostas e fornece a resposta final.

#### Exemplo

Aqui est√° um pequeno exemplo. Digamos que temos os seguintes completamentos para o prompt `Qual √© a soma de dois mais dois?`:

```text
<!-- highlight-start -->
4
<!-- highlight-end -->
```

```text
<!-- highlight-start -->
dois + 2 = 5
<!-- highlight-end -->
```

```text
<!-- highlight-start -->
Eu acho que 2+2 = 6
<!-- highlight-end -->
```

```text
<!-- highlight-start -->
dois mais dois = 4
<!-- highlight-end -->
```

```text
<!-- highlight-start -->
√â 5
<!-- highlight-end -->
```

O verificador ler√° cada completamento e atribuir√° uma pontua√ß√£o a ele. Por exemplo, pode atribuir
as pontua√ß√µes: 0,9, 0,1, 0,2, 0,8, 0,3, respectivamente. Ent√£o, a parte da vota√ß√£o somar√° as pontua√ß√µes de cada
resposta.

```
pontua√ß√£o(4) = 0.9 + 0.8 = 1.7
pontua√ß√£o(5) = 0.1 + 0.3 = 0.4
pontua√ß√£o(6) = 0.2
```

A resposta final √© 4, j√° que ela teve a pontua√ß√£o maior.

**Mas como o verificador √© treinado?**

O verificador √© treinando com uma fun√ß√£o um pouco compleza, que eu n√£o vou abordar aqui. Leia a se√ß√£o 3.3 desse artigo para mais informa√ß√µes (@li2022advance).

## Prompts do tipo "Me Pergunte Qualquer Coisa" - Ask Me Anything (AMA)

import ama from '@site/docs/assets/reliability/AMA_Prompting.webp';

<div style={{textAlign: 'center'}}>
  <LazyLoadImage src={ama} style={{width: "750px"}} />
</div>

Perguntas do tipo AMA (@arora2022ama) √© uma abordagem semelhante √† DiVeRSe. No entanto, tanto seu passo de m√∫ltiplos prompts quanto seu passo de agrega√ß√£o de respostas diferem significativamente. A ideia principal do AMA √© usar um LLM para gerar m√∫ltiplos prompts, em vez de usar apenas prompts com poucos exemplos.

### Prompts M√∫ltiplos

A abordagem AMA mostra que voc√™ pode tomar uma pergunta e reformat√°-la de v√°rias maneiras para criar prompts diferentes. Por exemplo, digamos que voc√™ est√° coletando um monte de sites para obter informa√ß√µes sobre animais e deseja gravar apenas os que vivem na Am√©rica do Norte. Vamos construir um prompt para determinar isso.

Dado o seguinte trecho da Wikipedia:

```text
O urso Kermode, √†s vezes chamado de urso esp√≠rito (Ursus americanus kermodei), √© uma subesp√©cie do urso negro americano e vive nas regi√µes da Costa Central e Norte da Col√∫mbia Brit√¢nica, Canad√°.
```

Voc√™ pode formatar essa tarefa em um prompt assim:

```text
A seguinte afirma√ß√£o √© Verdadeira ou Falsa dado o contexto?

Contexto: O urso Kermode, √†s vezes chamado de urso esp√≠rito (Ursus americanus kermodei), √© uma subesp√©cie do urso negro americano e vive nas regi√µes da Costa Central e Norte da Col√∫mbia Brit√¢nica, Canad√°.
Afirma√ß√£o: Este animal vive na Am√©rica do Norte
Resposta:
```

Esta √© uma forma um pouco estranha de formular. Por que n√£o usar o seguinte prompt, que √© bem mais simples?

```text
Contexto: O urso Kermode, √†s vezes chamado de urso esp√≠rito (Ursus americanus kermodei), √© uma subesp√©cie do urso-preto americano e vive nas regi√µes da Costa Central e Norte da Col√∫mbia Brit√¢nica, Canad√°.
Pergunta: Esse animal vive na Am√©rica do Norte?
```

Bem, ao formular a quest√£o desta forma especial, podemos gerar prompts diferentes.
Nosso primeiro passo aqui ser√° transformar a afirma√ß√£o `Esse animal vive na Am√©rica do Norte` e reformat√°-la em diferentes perguntas, que basicamente est√£o perguntando a mesma coisa. Para isso, passaremos a afirma√ß√£o por prompts como os da imagem abaixo.

import ama_multi from '@site/docs/assets/reliability/AMA_multiprompting.webp';

<div style={{textAlign: 'center'}}>
  <LazyLoadImage src={ama_multi} style={{width: "800px"}} />
</div>

Isso pode gerar:
1. O animal estava vivendo na Am√©rica do Norte?
2. O animal vive na Am√©rica do Norte?
3. Onde o animal vive?

A ideia por tr√°s disso √© criar diferentes *vis√µes* da tarefa. Ent√£o, aplicamos cada uma ao contexto dado da seguinte forma:

```text
Contexto: O urso Kermode, √†s vezes chamado de urso esp√≠rito (Ursus americanus kermodei), √© uma subesp√©cie do urso-preto americano e vive nas regi√µes da Costa Central e Norte da Col√∫mbia Brit√¢nica, Canad√°.
Pergunta: O animal estava vivendo na Am√©rica do Norte?
```

Ent√£o, podemos gerar respostas para cada uma:

1. `Sim, ele estava`
2. `Sim, ele faz`
3. `Am√©rica do Norte`

Estas s√£o *respostas intermedi√°rias*. Precisamos mape√°-las para etiquetas de tarefa (por exemplo, Sim ou N√£o).

Podemos fazer isso passando as respostas intermedi√°rias por um prompt como o seguinte:

```text
Selecione a categoria correta.

"Categorias":
- Sim, Am√©rica do Norte
- N√£o, n√£o na Am√©rica do Norte

"Sim, ele estava" se encaixa na categoria:
```

Agora podemos obter nossas respostas de sa√≠da.

1. `Sim, Am√©rica do Norte`
2. `Sim, Am√©rica do Norte`
3. `Sim, Am√©rica do Norte`

Aqui, todos concordam, ent√£o podemos pegar a primeira resposta. No entanto, se eles discordassem, poder√≠amos usar o passo de agrega√ß√£o do AMA para obter uma resposta final.

### Agrega√ß√£o de respostas

A AMA usa uma estrat√©gia muito complicada para agregar respostas (mais do que a DiVeRSe) em vez de simplesmente considerar a resposta da maioria. Para entender por que a resposta da maioria pode ser uma escolha ruim, considere duas das perguntas que geramos antes:

1. O animal vivia na Am√©rica do Norte?
2. O animal vive na Am√©rica do Norte?

Eles s√£o extremamente similares, portanto provavelmente gerar√£o o mesmo resultado. Como as perguntas s√£o t√£o semelhantes, elas afetar√£o de forma significativa o resultado final. Para lidar com isso, a AMA conta com supervis√£o fraca e matem√°tica complexa para estimar as depend√™ncias entre os diferentes prompts que cria e, em seguida, usa isso para ponder√°-los adequadamente.

Portanto, para as tr√™s perguntas que geramos, ela pode atribuir pesos de 25%, 25% e 50%, j√° que as primeiras duas s√£o t√£o semelhantes.

Embora a estrat√©gia de agrega√ß√£o da AMA seja poderosa, ela √© t√£o complicada que n√£o a abordarei aqui. Leia a se√ß√£o 3.4 do artigo para obter mais detalhes (@arora2022ama).

### Resultados

- Com essa estrat√©gia de prompting, a AMA √© capaz de usar o GPT-J-6B (@wange2021gptj) para superar a performance do GPT-3.

- A AMA √© melhor em perguntas em que o contexto dado cont√©m a resposta.

## Takeaways

M√©todos de ensamblagem s√£o muito poderosos. Eles podem ser usados ‚Äã‚Äãpara melhorar o desempenho de qualquer modelo e tamb√©m podem ser usados ‚Äã‚Äãpara melhorar o desempenho de um modelo em uma tarefa espec√≠fica.

Na pr√°tica, a vota√ß√£o da maioria deve ser a sua estrat√©gia principal.