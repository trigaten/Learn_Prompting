---
sidebar_position: 2000
---

# üü¢ Outras Abordagens

Embora as abordagens anteriores possam ser muito robustas, algumas outras abordagens, utilizando um modelo diferente, incluindo ajuste fino, est√≠mulo suave e restri√ß√µes de comprimento, tamb√©m podem ser eficazes.

## Utilizando um Modelo Diferente

Modelos mais modernos, como o GPT-4, s√£o mais robustos contra a inje√ß√£o de prompt. Al√©m disso, modelos que n√£o foram ajustados para instru√ß√µes podem ser mais dif√≠ceis de serem manipulados com prompt injection.


## Ajuste Fino (Fine Tunning)

O ajuste fino do modelo √© uma defesa altamente eficaz (@goodside2021gpt), pois durante a infer√™ncia n√£o h√° prompt envolvido, exceto a entrada do usu√°rio. Essa √© provavelmente a defesa prefer√≠vel em qualquer situa√ß√£o que possua grande import√¢ncia, pois √© uma abordagem bastante robusta. No entanto, ela requer uma grande quantidade de dados e pode ser custosa, o que explica por que essa defesa n√£o √© implementada com frequ√™ncia.

## Est√≠mulo Suave (Soft Prompting)

O est√≠mulo suave tamb√©m pode ser eficaz, pois n√£o possui um prompt discretamente definido (al√©m da entrada do usu√°rio). O est√≠mulo suave requer efetivamente um ajuste fino, portanto, possui muitos dos mesmos benef√≠cios, mas provavelmente ser√° mais barato, em termos de processamento. No entanto, o est√≠mulo suave n√£o √© t√£o bem estudado quanto o ajuste fino, ent√£o n√£o est√° claro o qu√£o eficaz ele √©.


## Restri√ß√µes de Comprimento

Por fim, incluir restri√ß√µes de comprimento na entrada do usu√°rio (@selvi2022exploring) ou limitar o comprimento das conversas do chatbot, como o Bing faz, pode evitar alguns ataques, como prompts enormes no estilo DAN ou ataques de virtualiza√ß√£o, respectivamente.