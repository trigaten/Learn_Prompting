---
sidebar_position: 100
---

# 🟢 LLM 設定


import Temperature from '@site/docs/assets/basics/temperature.svg';

<div style={{textAlign: 'center'}}>
  <Temperature style={{width:"100%",height:"300px",verticalAlign:"top"}}/>
</div>

# はじめに

LLMの出力は、モデルの様々な側面、例えばどの程度「ランダム」であるかなどを制御する*構成ハイパーパラメータ*によって影響を受けることがあります。これらのハイパーパラメータを調整することで、より創造的で多様で興味深い出力を生成できます。このセクションでは、2 つの重要な構成ハイパーパラメータについて説明し、LLM の出力にどのように影響するかについて説明します。

:::note
[研究者向け] これらは、学習率、レイヤー数、隠れ層のサイズなどの通常のハイパーパラメータとは異なります。
:::

## Temperature

Temperature は言語モデルの出力のランダム性を制御する構成ハイパーパラメータです。Temperature を高い値に設定すると、より創造的で予測できない結果を生成しますが、低い値に設定すると、一般的で保守的な出力を生成します。たとえば、Temperature を 0.5 に設定すると、1.0 に設定するよりも、モデルは通常、予測可能で創造性の低いテキストを生成します。

## Top p

Top p は、言語モデルの出力のランダム性を制御するもう 1 つの構成ハイパーパラメータであり、確率の閾値を設定し、累積確率が閾値を超えるトップトークンを選択します。モデルは、このトークンの集合からランダムにサンプリングして出力を生成します。この方法は、ランダムに語彙全体からサンプリングする従来の方法よりも、より多様で興味深い出力を生成することができます。たとえば、Top p を 0.9 に設定すると、モデルは確率の 90% を占める最も可能性の高い単語のみを考慮します。

## その他の関連するハイパーパラメータ

頻度と存在ペナルティなど、言語モデルのパフォーマンスに影響を与える他の多くのハイパーパラメータがあります。ここでは取り扱いませんが、将来的には取り扱う可能性があります。

## これらのハイパーパラメータが出力に与える影響

Temperature と Top p は、生成されたテキストのランダム性と多様性を制御することで、言語モデルの出力に影響を与えます。高い Temperature または Top p 値は予測できない興味深い結果を生成する一方、エラーやナンセンスなテキストの可能性を高めます。低い Temperature または Top p 値は保守的で予測可能な結果を生成することができますが、繰り返しや興味深くないテキストを生成する可能性があります。

テキスト生成タスクでは、高い Temperature または Top p 値を使用することが望ましい場合があります。ただし、翻訳タスクや質問応答などの正確性が重要なタスクでは、正確性と事実の正確さを向上させるために、低い Temperature または Top p 値を使用する必要があります。

:::note
正確性が必要なタスクでも、[特別なプロンプティング技術](https://learnprompting.org/ja/docs/intermediate/self_consistency)と組み合わせることで、より多様性を持った出力が役立つ場合があります。
:::

## 結論

Temperature、Top p、およびその他のモデル構成ハイパーパラメータは、言語モデルを扱う際に考慮すべき重要な要因です。これらのハイパーパラメータとモデル出力の関係を理解することで、ユーザは特定のタスクやアプリケーションに最適なプロンプトを最適化することができます。

:::warning
ChatGPT など一部のモデルは、API を使用しない限りこれらの**構成ハイパーパラメータを調整することはできません**。
:::

By jackdickens382
