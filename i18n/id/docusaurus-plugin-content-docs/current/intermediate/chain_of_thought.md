---
sidebar_position: 3
locale: en-us
style: chicago
---

# ðŸŸ¢ Chain of Thought Prompting

Chain of Thought (CoT) prompting (@wei2022chain) adalah metode prompting yang baru dikembangkan, yang mendorong LLM untuk menjelaskan pemikirannya. Gambar di bawah ini menunjukkan prompt standar dari few shot prompt (kiri) dibandingkan dengan prompt chain of thought (kanan).


import CoTExample from '@site/docs/assets/basics/chain_of_thought_example.webp';

<div style={{textAlign: 'center'}}>
  <img src={CoTExample} style={{width: "750px"}}/>
</div>

<div style={{textAlign: 'center'}}>
Prompt Biasa vs CoT (Wei dkk.)
</div>

Ide utama CoT adalah dengan menunjukkan beberapa contoh few shot dimana proses pemikiran (reasoning) dijelaskan dalam contoh, LLM juga akan menunjukkan proses pemikiran tersebut saat menjawab prompt. Penjelasan pemikiran ini sering kali mengarah pada hasil yang lebih akurat.

## Contoh

Berikut beberapa contoh. Pertama menunjukkan GPT-3 (davinci-003) gagal menyelesaikan masalah kata sederhana. Yang kedua menunjukkan GPT-3 (davinci-003) berhasil menyelesaikan masalah yang sama dengan menggunakan CoT prompting.

#### Salah

<iframe
    src="https://embed.learnprompting.org/embed?config=eyJ0b3BQIjowLCJ0ZW1wZXJhdHVyZSI6MCwibWF4VG9rZW5zIjoyNTYsIm91dHB1dCI6Ik9wdGlvbiAxIGlzIGEgZmFzdGVyIHdheSB0byBnZXQgdG8gd29yay4iLCJwcm9tcHQiOiJXaGljaCBpcyBhIGZhc3RlciB3YXkgdG8gZ2V0IHRvIHdvcms%2FXG5PcHRpb24gMTogVGFrZSBhIDEwMDAgbWludXRlIGJ1cywgdGhlbiBhIGhhbGYgaG91ciB0cmFpbiwgYW5kIGZpbmFsbHkgYSAxMCBtaW51dGUgYmlrZSByaWRlLlxuT3B0aW9uIDI6IFRha2UgYW4gODAwIG1pbnV0ZSBidXMsIHRoZW4gYW4gaG91ciB0cmFpbiwgYW5kIGZpbmFsbHkgYSAzMCBtaW51dGUgYmlrZSByaWRlLiIsIm1vZGVsIjoidGV4dC1kYXZpbmNpLTAwMyJ9"
    style={{width:"100%", height:"500px", border:"0", borderRadius:"4px", overflow:"hidden"}}
    sandbox="allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"
></iframe>

#### Benar

<iframe
    src="https://embed.learnprompting.org/embed?config=eyJ0b3BQIjowLCJ0ZW1wZXJhdHVyZSI6MCwibWF4VG9rZW5zIjoyNTYsIm91dHB1dCI6Ik9wdGlvbiAxIHdpbGwgdGFrZSAxMDAwKzMwKzEwID0gMTA0MCBtaW51dGVzLlxuT3B0aW9uIDIgd2lsbCB0YWtlIDgwMCs2MCszMCA9IDg5MCBtaW51dGVzLlxuU2luY2UgT3B0aW9uIDIgdGFrZXMgODkwIG1pbnV0ZXMgYW5kIE9wdGlvbiAxIHRha2VzIDEwNDAgbWludXRlcywgT3B0aW9uIDIgaXMgZmFzdGVyLiIsInByb21wdCI6IldoaWNoIGlzIGEgZmFzdGVyIHdheSB0byBnZXQgaG9tZT9cbk9wdGlvbiAxOiBUYWtlIGFuIDEwIG1pbnV0ZXMgYnVzLCB0aGVuIGFuIDQwIG1pbnV0ZSBidXMsIGFuZCBmaW5hbGx5IGEgMTAgbWludXRlIHRyYWluLlxuT3B0aW9uIDI6IFRha2UgYSA5MCBtaW51dGVzIHRyYWluLCB0aGVuIGEgNDUgbWludXRlIGJpa2UgcmlkZSwgYW5kIGZpbmFsbHkgYSAxMCBtaW51dGUgYnVzLlxuT3B0aW9uIDEgd2lsbCB0YWtlIDEwKzQwKzEwID0gNjAgbWludXRlcy5cbk9wdGlvbiAyIHdpbGwgdGFrZSA5MCs0NSsxMD0xNDUgbWludXRlcy5cblNpbmNlIE9wdGlvbiAxIHRha2VzIDYwIG1pbnV0ZXMgYW5kIE9wdGlvbiAyIHRha2VzIDE0NSBtaW51dGVzLCBPcHRpb24gMSBpcyBmYXN0ZXIuXG5cbldoaWNoIGlzIGEgZmFzdGVyIHdheSB0byBnZXQgdG8gd29yaz9cbk9wdGlvbiAxOiBUYWtlIGEgMTAwMCBtaW51dGUgYnVzLCB0aGVuIGEgaGFsZiBob3VyIHRyYWluLCBhbmQgZmluYWxseSBhIDEwIG1pbnV0ZSBiaWtlIHJpZGUuXG5PcHRpb24gMjogVGFrZSBhbiA4MDAgbWludXRlIGJ1cywgdGhlbiBhbiBob3VyIHRyYWluLCBhbmQgZmluYWxseSBhIDMwIG1pbnV0ZSBiaWtlIHJpZGUuIiwibW9kZWwiOiJ0ZXh0LWRhdmluY2ktMDAzIn0%3D"
    style={{width:"100%", height:"500px", border:"0", borderRadius:"4px", overflow:"hidden"}}
    sandbox="allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"
></iframe>

## Hasil

CoT telah terbukti efektif dalam meningkatkan hasil dalam tugas-tugas seperti aritmatika, nalar umum, dan tugas penalaran simbolik (@wei2022chain). Secara khusus, PaLM 540B yang dipicu oleh (@chowdhery2022palm) mencapai akurasi tingkat 57% dalam menyelesaikan pada GSM8K (@cobbe2021training) (SOTA pada saat itu).

import PromptedPaLM from '@site/docs/assets/intermediate/prompted_palm.webp';

<div style={{textAlign: 'center'}}>
  <LazyLoadImage src={PromptedPaLM} style={{width: "300px"}} />
</div>

<div style={{textAlign: 'center'}}>
Perbandingan model pada benchmark GSM8K (Wei et al.)
</div>

## Batasan

Yang penting, menurut Wei et al., "CoT hanya menghasilkan peningkatan kinerja ketika digunakan dengan model sekitar 100 miliar parameter". Model-model yang lebih kecil menulis rantai pikiran yang tidak logis, yang mengakibatkan akurasi yang lebih buruk dibandingkan dengan permintaan standar. Model-model biasanya mendapatkan peningkatan performa dari CoT yang mempromosikan dengan cara yang sebanding dengan ukuran model.


## Catatan

Tidak ada model bahasa yang terluka dalam proses penulisan bab ini ðŸ˜Š.